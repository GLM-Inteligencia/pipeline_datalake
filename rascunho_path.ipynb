{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cloud_functions._1_fetch_data._1_13_fetch_items_promotions.main import fetch_promotions_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockRequest:\n",
    "    \n",
    "    def __init__(self, json_data):\n",
    "        self._json_data = json_data\n",
    "\n",
    "    def get_json(self):\n",
    "        return self._json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    " \"access_token\": None,\n",
    " \"client_id\": \"4959083987776428\",\n",
    " \"client_secret\": \"Hw9wWSydd8PMvMEJewWoMvKGYMAWyKEw\",\n",
    " \"seller_id\": 189643563,\n",
    " \"store_name\": \"hubsmarthome\"\n",
    "}\n",
    "\n",
    "mock_request = MockRequest(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.common.utils import batch_process, log_process, authenticate, fetch_items_from_storage\n",
    "from src.config import settings\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "semaphore = asyncio.Semaphore(100)  # Control the number of simultaneous requests\n",
    "\n",
    "async def main_async(request):\n",
    "    # Parsing request data\n",
    "    data = request.get_json()\n",
    "    client_id = data.get('client_id')\n",
    "    client_secret = data.get('client_secret')\n",
    "    store_name = data.get('store_name')\n",
    "    seller_id = data.get('seller_id')\n",
    "    access_token = data.get('access_token')\n",
    "    print('** Defining authentication... **')\n",
    "    \n",
    "    # Authenticate (assuming this is now centralized in utils.py or a similar file)\n",
    "    if not access_token:\n",
    "        access_token = authenticate(client_id, client_secret)  # You can add this to a common module\n",
    "    print('** Connecting to storage and BigQuery... **')\n",
    "\n",
    "    # Initialize storage and BigQuery\n",
    "    storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "    #bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "    \n",
    "    # Define paths and table names from the config\n",
    "    bucket_name = settings.BUCKET_STORES\n",
    "    table_management = settings.TABLE_MANAGEMENT\n",
    "    destiny_table = settings.TABLE_ITEM_PROMOTION\n",
    "    # Define today's date\n",
    "    today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Fetch item IDs from the storage bucket\n",
    "    blob_items_prefix = f'{store_name}/meli/api_response/item_detail/date={today_str}/'\n",
    "    items_id = fetch_items_from_storage(storage, settings.BUCKET_STORES, blob_items_prefix, 'id')\n",
    "    print(f'** Items found: {len(items_id)}**')\n",
    "    \n",
    "    print(f'** Cleaning blob **')\n",
    "    # Path for saving promotions details\n",
    "    # marketplace\n",
    "    blob_basic_path_marketplace = settings.BLOB_PROMOTIONS(store_name)\n",
    "    date_blob_path_marketplace = f'{blob_basic_path_marketplace}date={today_str}/'\n",
    "    \n",
    "    # mshops\n",
    "    blob_basic_path_mshops = settings.BLOB_PROMOTIONS_MSHOPS(store_name)\n",
    "    date_blob_path_mshops = f'{blob_basic_path_mshops}date={today_str}/'\n",
    "    \n",
    "    # Clean existing files in the storage bucket\n",
    "    storage.clean_blobs(bucket_name, date_blob_path_marketplace)\n",
    "    storage.clean_blobs(bucket_name, date_blob_path_mshops)\n",
    "    print(f'** Starting API requests for {len(items_id)} items**')\n",
    "    # URL function for API\n",
    "    url_marketplace = settings.URL_PROMOTIONS_MARKETPLACE\n",
    "    url_mshops = settings.URL_PROMOTIONS_MSHOPS\n",
    "    headers = {'Authorization': f'Bearer {access_token}'}\n",
    "    \n",
    "    # Batch processing the API requests\n",
    "    # PROMOTIONS MELI\n",
    "    try:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            await batch_process(session, items_id, url_marketplace, headers, bucket_name, date_blob_path_marketplace, storage,  sleep_time=15)\n",
    "    except aiohttp.ClientResponseError as e:\n",
    "        if e.status == 429:\n",
    "            retry_after = e.headers.get('Retry-After')\n",
    "            if retry_after:\n",
    "                wait_time = int(retry_after)\n",
    "                print(f\"Limite de taxa atingido. Aguardando {wait_time} segundos.\")\n",
    "                time.sleep(wait_time)\n",
    "                # Retry after timeout\n",
    "                await batch_process(session, items_id, url_marketplace, headers, bucket_name, date_blob_path_marketplace, storage, add_item_id = True)\n",
    "            else:\n",
    "                print(\"Limite de taxa atingido, mas nenhum cabeçalho Retry-After foi fornecido. Aguardando um tempo padrão.\")\n",
    "                time.sleep(10)  # Wait for default time if header is not present\n",
    "\n",
    "    #time.sleep(60)\n",
    "    \n",
    "    # Batch processing the API requests\n",
    "    # PROMOTIONS SHOPS\n",
    "    try:\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            await batch_process(session, items_id, url_mshops, headers, bucket_name, date_blob_path_mshops, storage,  sleep_time=15)\n",
    "    except aiohttp.ClientResponseError as e:\n",
    "        if e.status == 429:\n",
    "            retry_after = e.headers.get('Retry-After')\n",
    "            if retry_after:\n",
    "                wait_time = int(retry_after)\n",
    "                print(f\"Limite de taxa atingido. Aguardando {wait_time} segundos.\")\n",
    "                time.sleep(wait_time)\n",
    "                # Retry after timeout\n",
    "                await batch_process(session, items_id, url_marketplace, headers, bucket_name, date_blob_path_marketplace, storage, add_item_id = True)\n",
    "            else:\n",
    "                print(\"Limite de taxa atingido, mas nenhum cabeçalho Retry-After foi fornecido. Aguardando um tempo padrão.\")\n",
    "                time.sleep(10)  # Wait for default time if header is not present\n",
    "\n",
    "    \n",
    "    print('** Logging process in management table... **')\n",
    "    # Log the process in BigQuery\n",
    "    log_process(seller_id, destiny_table, today_str, table_management, processed_to_bq=False)\n",
    "\n",
    "    return ('Success', 200)\n",
    "\n",
    "def fetch_promotions_data(request):\n",
    "    return (main_async(request))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Defining authentication... **\n",
      "** Connecting to storage and BigQuery... **\n",
      "Using local credentials from: D:/bacar/Savvi/GLM/Desenvolvimento/service_account/service_account_datalakev2.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_0__process_time=2024-10-25T07:00:00.267180-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_10__process_time=2024-10-25T07:00:00.282616-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_1__process_time=2024-10-25T07:00:00.745113-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_2__process_time=2024-10-25T07:00:00.327130-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_3__process_time=2024-10-25T07:00:00.669467-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_4__process_time=2024-10-25T07:00:00.941750-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_5__process_time=2024-10-25T07:00:00.302061-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_6__process_time=2024-10-25T07:00:00.953454-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_7__process_time=2024-10-25T07:00:00.664089-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_8__process_time=2024-10-25T07:00:00.957316-03:00.json\n",
      "Reading file: hubsmarthome/meli/api_response/item_detail/date=2024-10-25/batch_9__process_time=2024-10-25T07:00:00.766708-03:00.json\n",
      "** Items found: 1030**\n",
      "** Cleaning blob **\n",
      "Deleting blob: hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_0__process_time=2024-10-25T12:00:00.486165-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_1__process_time=2024-10-25T12:01:01.857695-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_2__process_time=2024-10-25T12:01:01.408945-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_3__process_time=2024-10-25T12:01:01.300509-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_4__process_time=2024-10-25T12:02:02.196603-03:00.json\n",
      "All blobs with prefix hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/ have been deleted.\n",
      "All blobs with prefix hubsmarthome/meli/api_response/items_promotions_mshops/date=2024-10-25/ have been deleted.\n",
      "** Starting API requests for 1030 items**\n",
      "Error for item ID MLB4993136018: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB3865437251: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "File uploaded to hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_0__process_time=2024-10-25T12:13:13.552203-03:00.json.\n",
      "Error for item ID MLB5093870924: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB4969226826: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB3757108637: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "File uploaded to hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_1__process_time=2024-10-25T12:13:13.658562-03:00.json.\n",
      "Error for item ID MLB3400456361: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB5110281786: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB5094275672: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB5131990160: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "File uploaded to hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_2__process_time=2024-10-25T12:13:13.579597-03:00.json.\n",
      "Error for item ID MLB3643919241: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB3865441845: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB3844243083: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "File uploaded to hubsmarthome/meli/api_response/items_promotions/date=2024-10-25/batch_3__process_time=2024-10-25T12:14:14.407345-03:00.json.\n",
      "Error for item ID MLB3844267265: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB3757130093: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB4681850534: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n",
      "Error for item ID MLB4780739260: Status code 400, Response: {\"message\":\"Item status is not allowed (closed)\",\"error\":\"bad_request\",\"status\":400,\"cause\":[]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ClientConnectorError is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fetch_promotions_data(mock_request)\n",
      "Cell \u001b[1;32mIn[9], line 67\u001b[0m, in \u001b[0;36mmain_async\u001b[1;34m(request)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aiohttp\u001b[38;5;241m.\u001b[39mClientSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 67\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m batch_process(session, items_id, url_marketplace, headers, bucket_name, date_blob_path_marketplace, storage,  sleep_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m aiohttp\u001b[38;5;241m.\u001b[39mClientResponseError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n",
      "File \u001b[1;32md:\\bacar\\Savvi\\GLM\\Desenvolvimento\\pipeline_datalake\\src\\common\\utils.py:67\u001b[0m, in \u001b[0;36mbatch_process\u001b[1;34m(session, items, url_func_or_string, headers, bucket_name, date_blob_path, storage, url_with_two_fields, chunk_size, add_item_id, params, sleep_time)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Correctly pass params_chunk to process_chunk\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_number, (chunk, params_chunk) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(chunks, params_chunks)):\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m process_chunk(chunk, batch_number, params_chunk)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(sleep_time)\n",
      "File \u001b[1;32md:\\bacar\\Savvi\\GLM\\Desenvolvimento\\pipeline_datalake\\src\\common\\utils.py:63\u001b[0m, in \u001b[0;36mbatch_process.<locals>.process_chunk\u001b[1;34m(chunk, batch_number, params_chunk)\u001b[0m\n\u001b[0;32m     61\u001b[0m process_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%Y-%m-%dT%H:%M:%M.%f-03:00\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__process_time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 63\u001b[0m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_blob_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\bacar\\Savvi\\GLM\\Desenvolvimento\\pipeline_datalake\\src\\common\\cloud_storage_connector.py:48\u001b[0m, in \u001b[0;36mCloudStorage.upload_json\u001b[1;34m(self, bucket_name, destination_blob_name, data)\u001b[0m\n\u001b[0;32m     46\u001b[0m bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbucket(bucket_name)\n\u001b[0;32m     47\u001b[0m blob \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mblob(destination_blob_name)\n\u001b[1;32m---> 48\u001b[0m blob\u001b[38;5;241m.\u001b[39mupload_from_string(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, content_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile uploaded to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_blob_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bacar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[1;32mc:\\Users\\bacar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32mc:\\Users\\bacar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bacar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type ClientConnectorError is not JSON serializable"
     ]
    }
   ],
   "source": [
    "result = await fetch_promotions_data(mock_request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Success', 200)\n"
     ]
    }
   ],
   "source": [
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O arquivo existe.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.config.settings import *\n",
    "\n",
    "path_credentials = PATH_SERVICE_ACCOUNT\n",
    "\n",
    "if os.path.exists(path_credentials):\n",
    "    print(\"O arquivo existe.\")\n",
    "else:\n",
    "    print(\"O arquivo não foi encontrado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
