{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.common.utils import batch_process, log_process, authenticate, fetch_items_from_storage\n",
    "from src.config import settings\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = {\n",
    "  \"access_token\": None,\n",
    "  \"client_id\": \"4959083987776428\",\n",
    "  \"client_secret\": \"Hw9wWSydd8PMvMEJewWoMvKGYMAWyKEw\",\n",
    "  \"seller_id\": 189643563,\n",
    "  \"store_name\": \"hubsmarthome\"\n",
    "}\n",
    "\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = authenticate(json['client_id'], json['client_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery.run_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_item_id = 'MLB28887155'\n",
    "\n",
    "url = f\"https://api.mercadolibre.com/products/{catalog_item_id}/items\"\n",
    "\n",
    "# Cabeçalhos de autorização\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "# Fazendo a requisição GET\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = 'MLB4966133390'\n",
    "\n",
    "url = f\"https://api.mercadolibre.com/items/{item_id}/shipping\"\n",
    "\n",
    "# Cabeçalhos de autorização\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "# Fazendo a requisição GET\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = 'MLB4978023790'\n",
    "\n",
    "url = f\"https://api.mercadolibre.com/items/{item_id}/shipping\"\n",
    "\n",
    "# Cabeçalhos de autorização\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "# Fazendo a requisição GET\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_shipping(json_data):\n",
    "    try:\n",
    "        default_value = json_data.get('default')\n",
    "        channels = json_data.get('channels', [])\n",
    "        item_id = json_data.get('item_id')\n",
    "        dict_list = []\n",
    "        for channel in channels:\n",
    "            dict_content = {\n",
    "                'item_id': item_id,\n",
    "                'channel_id': channel.get('id'),\n",
    "                'mode': channel.get('mode'),\n",
    "                'logistic_type': channel.get('logistic_type'),\n",
    "                'local_pick_up': channel.get('local_pick_up'),\n",
    "                'free_shipping': channel.get('free_shipping'),\n",
    "                'store_pick_up': channel.get('store_pick_up'),\n",
    "                'default': default_value\n",
    "            }\n",
    "            dict_list.append(dict_content)\n",
    "        return dict_list\n",
    "    except Exception as e:\n",
    "        print(f'Error processing json: {json_data}, error: {e}')\n",
    "        return []\n",
    "import pandas as pd\n",
    "pd.DataFrame(process_shipping(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json\n",
    "client_id = data.get('client_id')\n",
    "client_secret = data.get('client_secret')\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "access_token = data.get('access_token')\n",
    "print('** Defining authentication... **')\n",
    "# Authenticate (assuming this is now centralized in utils.py or a similar file)\n",
    "if not access_token:\n",
    "    access_token = authenticate(client_id, client_secret)  # You can add this to a common module\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_FULLFILMENT\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch item IDs from the storage bucket\n",
    "blob_items_prefix = f'{store_name}/meli/api_response/catelog_details/date={today_str}/'\n",
    "items_id = fetch_items_from_storage(\n",
    "storage, \n",
    "bucket_name, \n",
    "blob_items_prefix, \n",
    "key_names='inventory_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.config import settings\n",
    "import json\n",
    "\n",
    "\n",
    "def insert_bq_competitors_prices(request):\n",
    "\n",
    "    data = request.get_json()\n",
    "    store_name = data.get('store_name')\n",
    "    seller_id = data.get('seller_id')\n",
    "\n",
    "    print('** Connecting to storage and BigQuery... **')\n",
    "    # Initialize storage and BigQuery\n",
    "    storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "    bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "\n",
    "    # Define paths and table names from the config\n",
    "    bucket_name = settings.BUCKET_STORES\n",
    "    table_management = settings.TABLE_MANAGEMENT\n",
    "    destiny_table = settings.TABLE_CATALOG_COMPETITORS\n",
    "    blob_shipping_cost = settings.BLOB_COMPETITORS_CATALOG(store_name)\n",
    "\n",
    "    # Define today's date\n",
    "    today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Get dates to treat\n",
    "    list_dates_to_process = bigquery.get_list_dates_to_process(seller_id, table_management, destiny_table)\n",
    "\n",
    "    print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process  ***')\n",
    "\n",
    "    df_processed_data = pd.DataFrame()\n",
    "\n",
    "    for date in list_dates_to_process:\n",
    "\n",
    "        # Transform date to string\n",
    "        date_to_process = date.strftime('%Y-%m-%d')\n",
    "        print(f'Processing date: {date_to_process}')\n",
    "        # Get blob with the date\n",
    "        blob_prefix = blob_shipping_cost + f'date={date_to_process}/'\n",
    "        # List all the files\n",
    "        blobs = storage.list_blobs(bucket_name, blob_prefix)\n",
    "\n",
    "        # Processing each blob\n",
    "        for blob in blobs:\n",
    "            print(f\"Reading file: {blob.name}\")\n",
    "            content = storage.download_json(bucket_name, blob.name)\n",
    "\n",
    "            for json in content:\n",
    "                processed_dict = process_prices(json)\n",
    "\n",
    "                if isinstance(processed_dict, list):\n",
    "                    df_processed_data = pd.concat([df_processed_data, pd.DataFrame(processed_dict)], ignore_index = True)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        df_processed_data['correspondent_date'] = pd.to_datetime(date_to_process)\n",
    "        df_processed_data['process_time'] = datetime.now()\n",
    "        df_processed_data['seller_id'] = seller_id\n",
    "\n",
    "        print(f'*** Finished treating all data. {df_processed_data.shape[0]} products ***')\n",
    "\n",
    "        print('** Deleting existing data **')\n",
    "        bigquery.delete_existing_data(destiny_table, seller_id, date_to_process)\n",
    "        \n",
    "        print('** Correct dataframe schema **')\n",
    "        bigquery.match_dataframe_schema(df_processed_data, destiny_table)\n",
    "\n",
    "        print('** Inserting data into BQ**')\n",
    "        bigquery.insert_dataframe(df_processed_data, destiny_table)\n",
    "\n",
    "        print('** Updating log table **')\n",
    "        bigquery.update_logs_table(seller_id, date_to_process, destiny_table, table_management)\n",
    "\n",
    "    return ('Success', 200)\n",
    "\n",
    "\n",
    "def process_prices(json):\n",
    "\n",
    "    try:\n",
    "        extracted_data = []\n",
    "        # Dicionário temporário para priorizar os preços por canal\n",
    "        price_by_channel = {}\n",
    "        for price in json['prices']:\n",
    "            channel = price['conditions']['context_restrictions']\n",
    "            if len(channel) == 1:\n",
    "                channel = channel[0]\n",
    "\n",
    "                # Se ainda não há preço para o canal ou se o preço atual é promoção, atualiza\n",
    "                if channel not in price_by_channel or price['type'] == 'promotion':\n",
    "                    price_by_channel[channel] = {\n",
    "                        'item_id': json.get('id'),\n",
    "                        'price_id': price.get('id'),\n",
    "                        'regular_amount': price.get('regular_amount'),\n",
    "                        'price': price.get('amount'),\n",
    "                        'channel': channel,\n",
    "                        'last_updated': price.get('last_updated')\n",
    "                    }\n",
    "        # Converte os valores armazenados para uma lista\n",
    "        extracted_data.extend(price_by_channel.values())\n",
    "\n",
    "        return extracted_data\n",
    "    \n",
    "    except:\n",
    "        print(f'Error processing json: {json}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = {\n",
    "  \"access_token\": None,\n",
    "  \"client_id\": \"4959083987776428\",\n",
    "  \"client_secret\": \"Hw9wWSydd8PMvMEJewWoMvKGYMAWyKEw\",\n",
    "  \"seller_id\": 189643563,\n",
    "  \"store_name\": \"hubsmarthome\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_CATALOG_COMPETITORS\n",
    "blob_shipping_cost = settings.BLOB_COMPETITORS_CATALOG(store_name)\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "# Get dates to treat\n",
    "list_dates_to_process = bigquery.get_list_dates_to_process(seller_id, table_management, destiny_table)\n",
    "print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process  ***')\n",
    "df_processed_data = pd.DataFrame()\n",
    "for date in list_dates_to_process:\n",
    "    # Transform date to string\n",
    "    date_to_process = date.strftime('%Y-%m-%d')\n",
    "    print(f'Processing date: {date_to_process}')\n",
    "    # Get blob with the date\n",
    "    blob_prefix = blob_shipping_cost + f'date={date_to_process}/'\n",
    "    # List all the files\n",
    "    blobs = storage.list_blobs(bucket_name, blob_prefix)\n",
    "    # Processing each blob\n",
    "    for blob in blobs:\n",
    "        print(f\"Reading file: {blob.name}\")\n",
    "        content = storage.download_json(bucket_name, blob.name)\n",
    "        for json in content:\n",
    "            processed_dict = process_competitors_catalog(json)\n",
    "            if isinstance(processed_dict, list):\n",
    "                df_processed_data = pd.concat([df_processed_data, pd.DataFrame(processed_dict)], ignore_index = True)\n",
    "            else:\n",
    "                continue\n",
    "    df_processed_data['correspondent_date'] = pd.to_datetime(date_to_process)\n",
    "    df_processed_data['process_time'] = datetime.now()\n",
    "    df_processed_data['seller_id'] = seller_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[0]['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = content[0]['results']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[0]['results'][0].get('category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_proc = process_competitors_catalog(content[0])\n",
    "pd.DataFrame(list_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_competitors_catalog(json):\n",
    "\n",
    "    catalog_id = json['item_id']\n",
    "    results_list = []  # Create an empty list to store the dictionaries\n",
    "\n",
    "    try:\n",
    "        for item in json['results']:\n",
    "            dict_content = {\n",
    "                'catalog_product_id': catalog_id, \n",
    "                'item_id' : item.get('item_id'),\n",
    "                'competitors_type': 'catalog',\n",
    "                'category_id': item.get('category_id'),\n",
    "                'official_store_id': item.get('official_store_id'),\n",
    "                'competitor_seller_id': item.get('seller_id'),\n",
    "                'listing_type_id': item.get('listing_type_id'),\n",
    "                'condition': item.get('condition'),\n",
    "            }\n",
    "            \n",
    "            results_list.append(dict_content)  # Append each dictionary to the list\n",
    "        \n",
    "        return results_list  # Return the full list after iterating through all items\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error processing json: {json}. Error: {str(e)}')\n",
    "        return None  # Optionally return None if there's an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve costs\n",
    "data = json = {\n",
    "  \"access_token\": None,\n",
    "  \"client_id\": \"4959083987776428\",\n",
    "  \"client_secret\": \"Hw9wWSydd8PMvMEJewWoMvKGYMAWyKEw\",\n",
    "  \"seller_id\": 189643563,\n",
    "  \"store_name\": \"hubsmarthome\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Defining authentication... **\n",
      "** Connecting to storage and BigQuery... **\n",
      "Using local credentials from: C:/Users/User/Documents/papa preco/service account/service_account_datalakev2.json\n",
      "Using local credentials from: C:/Users/User/Documents/papa preco/service account/service_account_datalakev2.json\n",
      "** Items found: 1976**\n",
      "** Cleaning blob **\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_0__process_time=2024-10-15T14:29:29.211919-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_10__process_time=2024-10-15T14:30:30.258868-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_11__process_time=2024-10-15T14:30:30.304502-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_12__process_time=2024-10-15T14:30:30.257919-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_13__process_time=2024-10-15T14:30:30.346773-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_14__process_time=2024-10-15T14:30:30.324928-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_15__process_time=2024-10-15T14:30:30.347416-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_16__process_time=2024-10-15T14:30:30.321203-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_17__process_time=2024-10-15T14:30:30.332866-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_18__process_time=2024-10-15T14:30:30.289572-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_19__process_time=2024-10-15T14:30:30.253756-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_1__process_time=2024-10-15T14:29:29.185833-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_2__process_time=2024-10-15T14:29:29.168446-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_3__process_time=2024-10-15T14:29:29.267054-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_4__process_time=2024-10-15T14:29:29.230719-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_5__process_time=2024-10-15T14:29:29.196177-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_6__process_time=2024-10-15T14:29:29.195237-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_7__process_time=2024-10-15T14:29:29.160314-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_8__process_time=2024-10-15T14:29:29.294263-03:00.json\n",
      "Deleting blob: hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_9__process_time=2024-10-15T14:29:29.277084-03:00.json\n",
      "All blobs with prefix hubsmarthome/meli/api_response/item_cost/date=2024-10-15/ have been deleted.\n",
      "** Starting API requests for 1976 items**\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_0__process_time=2024-10-15T14:32:32.859037-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_1__process_time=2024-10-15T14:32:32.868161-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_2__process_time=2024-10-15T14:32:32.833635-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_3__process_time=2024-10-15T14:32:32.793188-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_4__process_time=2024-10-15T14:32:32.788198-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_5__process_time=2024-10-15T14:32:32.825307-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_6__process_time=2024-10-15T14:32:32.801695-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_7__process_time=2024-10-15T14:32:32.771608-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_8__process_time=2024-10-15T14:32:32.716773-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_9__process_time=2024-10-15T14:32:32.711381-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_10__process_time=2024-10-15T14:32:32.712960-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_11__process_time=2024-10-15T14:33:33.669283-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_12__process_time=2024-10-15T14:33:33.746073-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_13__process_time=2024-10-15T14:33:33.727084-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_14__process_time=2024-10-15T14:33:33.684492-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_15__process_time=2024-10-15T14:33:33.689185-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_16__process_time=2024-10-15T14:33:33.737034-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_17__process_time=2024-10-15T14:33:33.761284-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_18__process_time=2024-10-15T14:33:33.721770-03:00.json.\n",
      "File uploaded to hubsmarthome/meli/api_response/item_cost/date=2024-10-15/batch_19__process_time=2024-10-15T14:33:33.589590-03:00.json.\n"
     ]
    }
   ],
   "source": [
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.common.utils import batch_process, log_process, authenticate, fetch_items_from_storage\n",
    "from src.config import settings\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "semaphore = asyncio.Semaphore(100)  # Control the number of simultaneous requests\n",
    "\n",
    "\n",
    "# Parsing request data\n",
    "# data = request.get_json()\n",
    "client_id = data.get('client_id')\n",
    "client_secret = data.get('client_secret')\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "access_token = data.get('access_token')\n",
    "print('** Defining authentication... **')\n",
    "# Authenticate (assuming this is now centralized in utils.py or a similar file)\n",
    "if not access_token:\n",
    "    access_token = authenticate(client_id, client_secret)  # You can add this to a common module\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_COSTS\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "# Getting params to see costs\n",
    "query = f'''\n",
    "    with items_details as (\n",
    "    select distinct\n",
    "        item_id,\n",
    "        listing_type,\n",
    "        category_id\n",
    "    from datalake-v2-424516.datalake_v2.items_details\n",
    "    where\n",
    "        1=1\n",
    "        and date(correspondent_date) = current_date()\n",
    "        and seller_id = {seller_id}\n",
    "    )\n",
    "    select \n",
    "    p.item_id as id,\n",
    "    d.listing_type as listing_type_id,\n",
    "    d.category_id,\n",
    "    p.price,\n",
    "    p.channel\n",
    "    from datalake-v2-424516.datalake_v2.items_prices p\n",
    "    inner join items_details d\n",
    "    on p.item_id = d.item_id\n",
    "    where \n",
    "        1=1\n",
    "        and date(p.correspondent_date) = current_date()\n",
    "        and channel is not null\n",
    "'''\n",
    "# blob_items_prefix = f'{store_name}/meli/api_response/item_detail/date={today_str}/'\n",
    "# items_id = fetch_items_from_storage(\n",
    "# storage, \n",
    "# bucket_name, \n",
    "# blob_items_prefix, \n",
    "# key_names=['id','price', 'category_id', 'listing_type_id']\n",
    "# )\n",
    "\n",
    "df_params = bigquery.run_query(query)\n",
    "# items = df_params[['id','channel']].to_dict(orient='records')\n",
    "df_params['channel'] = df_params['channel'].apply(lambda x : x.replace('channel_', '')).drop(columns = 'channel')\n",
    "items_id = df_params.to_dict(orient='records')\n",
    "\n",
    "print(f'** Items found: {len(items_id)}**')\n",
    "print(f'** Cleaning blob **')\n",
    "# Path for saving \n",
    "blob_basic_path = settings.BLOB_COSTS(store_name)\n",
    "date_blob_path = f'{blob_basic_path}date={today_str}/'\n",
    "# Clean existing files in the storage bucket\n",
    "storage.clean_blobs(bucket_name, date_blob_path)\n",
    "print(f'** Starting API requests for {len(items_id)} items**')\n",
    "# URL function for API\n",
    "url = settings.URL_COST\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "# Batch processing the API requests\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    await batch_process(session, items_id, url, headers, \n",
    "                        bucket_name, date_blob_path, storage, \n",
    "                        params = items_id, add_item_id = True)\n",
    "    \n",
    "log_process(seller_id, destiny_table, today_str, table_management, processed_to_bq=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_process(seller_id, destiny_table, today_str, table_management, processed_to_bq=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
