{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.common.utils import batch_process, log_process, authenticate, fetch_items_from_storage\n",
    "from src.config import settings\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = {\n",
    "  \"access_token\": \"APP_USR-2951712600123976-110203-ce78f9cdf280fab258ac0894a9286af2-569119547\",\n",
    "  \"client_id\": \"2951712600123976\",\n",
    "  \"client_secret\": \"QprAIl8ydXzcxFVHjnIHT6fUQ8KpzADV\",\n",
    "  \"seller_id\": 569119547,\n",
    "  \"store_name\": \"gw shop\"\n",
    "}\n",
    "\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Function to extract sku\n",
    "def extract_seller_sku(attributes):\n",
    "    for attribute in attributes:\n",
    "        if attribute.get('id') == 'SELLER_SKU':\n",
    "            return attribute.get('value_name')\n",
    "    return None  \n",
    "\n",
    "# Functions to get relations \n",
    "get_item_relations = lambda x: x.get('item_relations', [])[0].get('id') if len(x.get('item_relations', [])) > 0 else None  \n",
    "get_variation_id_relations = lambda x: x.get('item_relations', [])[0].get('variation_id') if len(x.get('item_relations', [])) > 0 else None  \n",
    "get_stock_relations = lambda x: x.get('item_relations', [])[0].get('stock_relation') if len(x.get('item_relations', [])) > 0 else None  \n",
    "\n",
    "def process_details(content_details, content_variations):  \n",
    "\n",
    "    df_product = pd.DataFrame()\n",
    "\n",
    "        # Checking if item has variations\n",
    "    for item in content_details:\n",
    "\n",
    "        if extract_seller_sku(item.get('attributes', [])):\n",
    "            has_variation = False\n",
    "        else:\n",
    "            has_variation = True \n",
    "\n",
    "        # get channels information\n",
    "        channel = item.get('channels')\n",
    "        flag_marketplace = 'marketplace' in item.get('channels',[])\n",
    "        flag_mshops = 'mshops' in item.get('channels',[])  \n",
    "\n",
    "        # get general information\n",
    "        product_details_general = {\n",
    "            'item_id': item.get('id'),\n",
    "            'item_name': item.get('title'),\n",
    "            'seller_id': item.get('seller_id'),\n",
    "            'category_id': item.get('category_id'),\n",
    "            'official_store_id': item.get('official_store_id'),\n",
    "            'price': item.get('price'),\n",
    "            'base_price': item.get('base_price'),\n",
    "            'original_price': item.get('original_price'),\n",
    "            'initial_quantity': item.get('initial_quantity'),\n",
    "            'status': item.get('status'),\n",
    "            'listing_type': item.get('listing_type_id'),\n",
    "            'url': item.get('permalink'),\n",
    "            'free_shipping': item.get('shipping',{}).get('free_shipping'),\n",
    "            'logistic_type': item.get('shipping',{}).get('logistic_type'),\n",
    "            'catalog_id' : item.get('catalog_product_id'),\n",
    "            'picture_url': item.get('pictures', [{}])[0].get('url'),\n",
    "            'catalog_listing': item.get('catalog_listing', ''),\n",
    "            'item_health': item.get('health',''),\n",
    "            'fg_marketplace': flag_marketplace,\n",
    "            'fg_mshops': flag_mshops,\n",
    "        }  \n",
    "\n",
    "        # If product does not have variations\n",
    "        if not has_variation:\n",
    "            product_detail_variation = {\n",
    "                'inventory_id': item.get('inventory_id'),\n",
    "                'currency_id': item.get('currency_id'),\n",
    "                'stock': item.get('available_quantity'),\n",
    "                'sold_quantity': item.get('sold_quantity'),\n",
    "                'seller_sku': extract_seller_sku(item.get('attributes', [])),\n",
    "                'variation_id': np.nan,\n",
    "                'item_relations': get_item_relations(item),\n",
    "                'stock_relations': get_stock_relations(item),\n",
    "                'variation_id_relations':get_variation_id_relations(item)\n",
    "            }\n",
    "\n",
    "            product_details_general.update(product_detail_variation)\n",
    "            df_ = pd.DataFrame([product_details_general])\n",
    "            df_product = pd.concat([df_product, df_], ignore_index=True)\n",
    "\n",
    "        # If product has variations\n",
    "        else:\n",
    "            for var in item.get('variations', []):\n",
    "                variation_id = var['id']\n",
    "                variation = [variation for variation in content_variations if variation['id'] == variation_id][0]\n",
    "                variation_id = var['id']\n",
    "                product_detail_variation = {\n",
    "                    'inventory_id': variation.get('inventory_id'),\n",
    "                    'currency_id': variation.get('currency_id'),\n",
    "                    'stock': variation.get('available_quantity'),\n",
    "                    'sold_quantity': variation.get('sold_quantity'),\n",
    "                    'seller_sku': extract_seller_sku(variation.get('attributes', [])),\n",
    "                    'variation_id': variation_id,\n",
    "                    'item_relations': get_item_relations(item),\n",
    "                    'stock_relations': get_stock_relations(item),\n",
    "                    'variation_id_relations':get_variation_id_relations(item)\n",
    "                }\n",
    "                product_details_general.update(product_detail_variation)\n",
    "                df_ = pd.DataFrame([product_details_general])\n",
    "                df_product = pd.concat([df_product, df_], ignore_index=True)\n",
    "\n",
    "    return df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = json\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_DETAILS\n",
    "blob_details = settings.BLOB_ITEMS_DETAILS(store_name)\n",
    "blob_variations = settings.BLOB_VARIATIONS(store_name)\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "# Get dates to treat\n",
    "list_dates_to_process = bigquery.get_list_dates_to_process(seller_id, table_management, destiny_table)\n",
    "print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process  ***')\n",
    "df_processed_data = pd.DataFrame()\n",
    "for date in list_dates_to_process:\n",
    "    # Transform date to string\n",
    "    date_to_process = date.strftime('%Y-%m-%d')\n",
    "    print(f'Processing date: {date_to_process}')\n",
    "    # Get blob with the date\n",
    "    blob_prefix_details = blob_details + f'date={date_to_process}/'\n",
    "    blob_prefix_variations = blob_variations + f'date={date_to_process}/'\n",
    "    # List all the files\n",
    "    blobs_details = storage.list_blobs(bucket_name, blob_prefix_details)\n",
    "    blobs_variations = storage.list_blobs(bucket_name, blob_prefix_variations)\n",
    "    \n",
    "    # Empty variables\n",
    "    df_processed_data = pd.DataFrame()\n",
    "    content_details=[]\n",
    "    content_variations=[]\n",
    "    # Getting details data\n",
    "    for blob_det in blobs_details:\n",
    "        # Get content information for details and variations\n",
    "        print(f\"Reading file: {blob_det.name}\")\n",
    "        content_details += storage.download_json(bucket_name, blob_det.name)\n",
    "    # Getting variation data\n",
    "    for blob_var in blobs_variations:\n",
    "        print(f\"Reading file: {blob_var.name}\")\n",
    "        content_variations += storage.download_json(bucket_name, blob_var.name)\n",
    "    df_processed_data = process_details(content_details, content_variations)\n",
    "    df_processed_data['correspondent_date'] = pd.to_datetime(date_to_process)\n",
    "    df_processed_data['process_time'] = datetime.now()\n",
    "    df_processed_data['seller_id'] = seller_id\n",
    "    print(f'*** Finished treating all data. {df_processed_data.shape[0]} products ***')\n",
    "    # print('** Deleting existing data **')\n",
    "    # bigquery.delete_existing_data(destiny_table, seller_id, date_to_process)\n",
    "    \n",
    "    # print('** Correct dataframe schema **')\n",
    "    # bigquery.match_dataframe_schema(df_processed_data, destiny_table)\n",
    "    # print('** Inserting data into BQ**')\n",
    "    # bigquery.insert_dataframe(df_processed_data, destiny_table)\n",
    "    # print('** Updating log table **')\n",
    "    # bigquery.update_logs_table(seller_id, date_to_process, destiny_table, table_management)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = authenticate(json['client_id'], json['client_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery.run_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "seller_id = '189643563'\n",
    "url = f\"https://api.mercadolibre.com/users/{seller_id}\"\n",
    "response = requests.get(url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_id = '2000009607285924'\n",
    "\n",
    "order_url = f'https://api.mercadolibre.com/orders/{order_id}'\n",
    "costs_url = f'https://api.mercadolibre.com/orders/{order_id}/costs'\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.get(order_url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_item_id = 'MLB28017126'\n",
    "\n",
    "url = f\"https://api.mercadolibre.com/products/{catalog_item_id}/items\"\n",
    "\n",
    "# Cabeçalhos de autorização\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "# Fazendo a requisição GET\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = 'MLB4966133390'\n",
    "\n",
    "url = f\"https://api.mercadolibre.com/items/{item_id}/shipping\"\n",
    "\n",
    "# Cabeçalhos de autorização\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "# Fazendo a requisição GET\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = 'MLB4978023790'\n",
    "\n",
    "url = f\"https://api.mercadolibre.com/items/{item_id}/shipping\"\n",
    "\n",
    "# Cabeçalhos de autorização\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "# Fazendo a requisição GET\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_shipping(json_data):\n",
    "    try:\n",
    "        default_value = json_data.get('default')\n",
    "        channels = json_data.get('channels', [])\n",
    "        item_id = json_data.get('item_id')\n",
    "        dict_list = []\n",
    "        for channel in channels:\n",
    "            dict_content = {\n",
    "                'item_id': item_id,\n",
    "                'channel_id': channel.get('id'),\n",
    "                'mode': channel.get('mode'),\n",
    "                'logistic_type': channel.get('logistic_type'),\n",
    "                'local_pick_up': channel.get('local_pick_up'),\n",
    "                'free_shipping': channel.get('free_shipping'),\n",
    "                'store_pick_up': channel.get('store_pick_up'),\n",
    "                'default': default_value\n",
    "            }\n",
    "            dict_list.append(dict_content)\n",
    "        return dict_list\n",
    "    except Exception as e:\n",
    "        print(f'Error processing json: {json_data}, error: {e}')\n",
    "        return []\n",
    "import pandas as pd\n",
    "pd.DataFrame(process_shipping(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json\n",
    "client_id = data.get('client_id')\n",
    "client_secret = data.get('client_secret')\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "access_token = data.get('access_token')\n",
    "print('** Defining authentication... **')\n",
    "# Authenticate (assuming this is now centralized in utils.py or a similar file)\n",
    "if not access_token:\n",
    "    access_token = authenticate(client_id, client_secret)  # You can add this to a common module\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_FULLFILMENT\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch item IDs from the storage bucket\n",
    "blob_items_prefix = f'{store_name}/meli/api_response/catelog_details/date={today_str}/'\n",
    "items_id = fetch_items_from_storage(\n",
    "storage, \n",
    "bucket_name, \n",
    "blob_items_prefix, \n",
    "key_names='inventory_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.config import settings\n",
    "import json\n",
    "\n",
    "\n",
    "def insert_bq_competitors_prices(request):\n",
    "\n",
    "    data = request.get_json()\n",
    "    store_name = data.get('store_name')\n",
    "    seller_id = data.get('seller_id')\n",
    "\n",
    "    print('** Connecting to storage and BigQuery... **')\n",
    "    # Initialize storage and BigQuery\n",
    "    storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "    bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "\n",
    "    # Define paths and table names from the config\n",
    "    bucket_name = settings.BUCKET_STORES\n",
    "    table_management = settings.TABLE_MANAGEMENT\n",
    "    destiny_table = settings.TABLE_CATALOG_COMPETITORS\n",
    "    blob_shipping_cost = settings.BLOB_COMPETITORS_CATALOG(store_name)\n",
    "\n",
    "    # Define today's date\n",
    "    today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Get dates to treat\n",
    "    list_dates_to_process = bigquery.get_list_dates_to_process(seller_id, table_management, destiny_table)\n",
    "\n",
    "    print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process  ***')\n",
    "\n",
    "    df_processed_data = pd.DataFrame()\n",
    "\n",
    "    for date in list_dates_to_process:\n",
    "\n",
    "        # Transform date to string\n",
    "        date_to_process = date.strftime('%Y-%m-%d')\n",
    "        print(f'Processing date: {date_to_process}')\n",
    "        # Get blob with the date\n",
    "        blob_prefix = blob_shipping_cost + f'date={date_to_process}/'\n",
    "        # List all the files\n",
    "        blobs = storage.list_blobs(bucket_name, blob_prefix)\n",
    "\n",
    "        # Processing each blob\n",
    "        for blob in blobs:\n",
    "            print(f\"Reading file: {blob.name}\")\n",
    "            content = storage.download_json(bucket_name, blob.name)\n",
    "\n",
    "            for json in content:\n",
    "                processed_dict = process_prices(json)\n",
    "\n",
    "                if isinstance(processed_dict, list):\n",
    "                    df_processed_data = pd.concat([df_processed_data, pd.DataFrame(processed_dict)], ignore_index = True)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        df_processed_data['correspondent_date'] = pd.to_datetime(date_to_process)\n",
    "        df_processed_data['process_time'] = datetime.now()\n",
    "        df_processed_data['seller_id'] = seller_id\n",
    "\n",
    "        print(f'*** Finished treating all data. {df_processed_data.shape[0]} products ***')\n",
    "\n",
    "        print('** Deleting existing data **')\n",
    "        bigquery.delete_existing_data(destiny_table, seller_id, date_to_process)\n",
    "        \n",
    "        print('** Correct dataframe schema **')\n",
    "        bigquery.match_dataframe_schema(df_processed_data, destiny_table)\n",
    "\n",
    "        print('** Inserting data into BQ**')\n",
    "        bigquery.insert_dataframe(df_processed_data, destiny_table)\n",
    "\n",
    "        print('** Updating log table **')\n",
    "        bigquery.update_logs_table(seller_id, date_to_process, destiny_table, table_management)\n",
    "\n",
    "    return ('Success', 200)\n",
    "\n",
    "\n",
    "def process_prices(json):\n",
    "\n",
    "    try:\n",
    "        extracted_data = []\n",
    "        # Dicionário temporário para priorizar os preços por canal\n",
    "        price_by_channel = {}\n",
    "        for price in json['prices']:\n",
    "            channel = price['conditions']['context_restrictions']\n",
    "            if len(channel) == 1:\n",
    "                channel = channel[0]\n",
    "\n",
    "                # Se ainda não há preço para o canal ou se o preço atual é promoção, atualiza\n",
    "                if channel not in price_by_channel or price['type'] == 'promotion':\n",
    "                    price_by_channel[channel] = {\n",
    "                        'item_id': json.get('id'),\n",
    "                        'price_id': price.get('id'),\n",
    "                        'regular_amount': price.get('regular_amount'),\n",
    "                        'price': price.get('amount'),\n",
    "                        'channel': channel,\n",
    "                        'last_updated': price.get('last_updated')\n",
    "                    }\n",
    "        # Converte os valores armazenados para uma lista\n",
    "        extracted_data.extend(price_by_channel.values())\n",
    "\n",
    "        return extracted_data\n",
    "    \n",
    "    except:\n",
    "        print(f'Error processing json: {json}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = {\n",
    "  \"access_token\": None,\n",
    "  \"client_id\": \"4959083987776428\",\n",
    "  \"client_secret\": \"Hw9wWSydd8PMvMEJewWoMvKGYMAWyKEw\",\n",
    "  \"seller_id\": 189643563,\n",
    "  \"store_name\": \"hubsmarthome\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_CATALOG_COMPETITORS\n",
    "blob_shipping_cost = settings.BLOB_COMPETITORS_CATALOG(store_name)\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "# Get dates to treat\n",
    "list_dates_to_process = bigquery.get_list_dates_to_process(seller_id, table_management, destiny_table)\n",
    "print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process  ***')\n",
    "df_processed_data = pd.DataFrame()\n",
    "for date in list_dates_to_process:\n",
    "    # Transform date to string\n",
    "    date_to_process = date.strftime('%Y-%m-%d')\n",
    "    print(f'Processing date: {date_to_process}')\n",
    "    # Get blob with the date\n",
    "    blob_prefix = blob_shipping_cost + f'date={date_to_process}/'\n",
    "    # List all the files\n",
    "    blobs = storage.list_blobs(bucket_name, blob_prefix)\n",
    "    # Processing each blob\n",
    "    for blob in blobs:\n",
    "        print(f\"Reading file: {blob.name}\")\n",
    "        content = storage.download_json(bucket_name, blob.name)\n",
    "        for json in content:\n",
    "            processed_dict = process_competitors_catalog(json)\n",
    "            if isinstance(processed_dict, list):\n",
    "                df_processed_data = pd.concat([df_processed_data, pd.DataFrame(processed_dict)], ignore_index = True)\n",
    "            else:\n",
    "                continue\n",
    "    df_processed_data['correspondent_date'] = pd.to_datetime(date_to_process)\n",
    "    df_processed_data['process_time'] = datetime.now()\n",
    "    df_processed_data['seller_id'] = seller_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[0]['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = content[0]['results']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content[0]['results'][0].get('category_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_proc = process_competitors_catalog(content[0])\n",
    "pd.DataFrame(list_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_competitors_catalog(json):\n",
    "\n",
    "    catalog_id = json['item_id']\n",
    "    results_list = []  # Create an empty list to store the dictionaries\n",
    "\n",
    "    try:\n",
    "        for item in json['results']:\n",
    "            dict_content = {\n",
    "                'catalog_product_id': catalog_id, \n",
    "                'item_id' : item.get('item_id'),\n",
    "                'competitors_type': 'catalog',\n",
    "                'category_id': item.get('category_id'),\n",
    "                'official_store_id': item.get('official_store_id'),\n",
    "                'competitor_seller_id': item.get('seller_id'),\n",
    "                'listing_type_id': item.get('listing_type_id'),\n",
    "                'condition': item.get('condition'),\n",
    "            }\n",
    "            \n",
    "            results_list.append(dict_content)  # Append each dictionary to the list\n",
    "        \n",
    "        return results_list  # Return the full list after iterating through all items\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error processing json: {json}. Error: {str(e)}')\n",
    "        return None  # Optionally return None if there's an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve costs\n",
    "data = json = {\n",
    "  \"access_token\": None,\n",
    "  \"client_id\": \"4959083987776428\",\n",
    "  \"client_secret\": \"Hw9wWSydd8PMvMEJewWoMvKGYMAWyKEw\",\n",
    "  \"seller_id\": 189643563,\n",
    "  \"store_name\": \"hubsmarthome\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.common.utils import batch_process, log_process, authenticate, fetch_items_from_storage\n",
    "from src.config import settings\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "semaphore = asyncio.Semaphore(100)  # Control the number of simultaneous requests\n",
    "\n",
    "\n",
    "# Parsing request data\n",
    "# data = request.get_json()\n",
    "client_id = data.get('client_id')\n",
    "client_secret = data.get('client_secret')\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "access_token = data.get('access_token')\n",
    "print('** Defining authentication... **')\n",
    "# Authenticate (assuming this is now centralized in utils.py or a similar file)\n",
    "if not access_token:\n",
    "    access_token = authenticate(client_id, client_secret)  # You can add this to a common module\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_COSTS\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "# Getting params to see costs\n",
    "query = f'''\n",
    "    with items_details as (\n",
    "    select distinct\n",
    "        item_id,\n",
    "        listing_type,\n",
    "        category_id\n",
    "    from datalake-v2-424516.datalake_v2.items_details\n",
    "    where\n",
    "        1=1\n",
    "        and date(correspondent_date) = current_date()\n",
    "        and seller_id = {seller_id}\n",
    "    )\n",
    "    select \n",
    "    p.item_id as id,\n",
    "    d.listing_type as listing_type_id,\n",
    "    d.category_id,\n",
    "    p.price,\n",
    "    p.channel\n",
    "    from datalake-v2-424516.datalake_v2.items_prices p\n",
    "    inner join items_details d\n",
    "    on p.item_id = d.item_id\n",
    "    where \n",
    "        1=1\n",
    "        and date(p.correspondent_date) = current_date()\n",
    "        and channel is not null\n",
    "'''\n",
    "# blob_items_prefix = f'{store_name}/meli/api_response/item_detail/date={today_str}/'\n",
    "# items_id = fetch_items_from_storage(\n",
    "# storage, \n",
    "# bucket_name, \n",
    "# blob_items_prefix, \n",
    "# key_names=['id','price', 'category_id', 'listing_type_id']\n",
    "# )\n",
    "\n",
    "df_params = bigquery.run_query(query)\n",
    "# items = df_params[['id','channel']].to_dict(orient='records')\n",
    "df_params['channel'] = df_params['channel'].apply(lambda x : x.replace('channel_', '')).drop(columns = 'channel')\n",
    "items_id = df_params.to_dict(orient='records')\n",
    "\n",
    "print(f'** Items found: {len(items_id)}**')\n",
    "print(f'** Cleaning blob **')\n",
    "# Path for saving \n",
    "blob_basic_path = settings.BLOB_COSTS(store_name)\n",
    "date_blob_path = f'{blob_basic_path}date={today_str}/'\n",
    "# Clean existing files in the storage bucket\n",
    "storage.clean_blobs(bucket_name, date_blob_path)\n",
    "print(f'** Starting API requests for {len(items_id)} items**')\n",
    "# URL function for API\n",
    "url = settings.URL_COST\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "# Batch processing the API requests\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    await batch_process(session, items_id, url, headers, \n",
    "                        bucket_name, date_blob_path, storage, \n",
    "                        params = items_id, add_item_id = True)\n",
    "    \n",
    "log_process(seller_id, destiny_table, today_str, table_management, processed_to_bq=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_process(seller_id, destiny_table, today_str, table_management, processed_to_bq=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.common.utils import batch_process, log_process, authenticate, fetch_items_from_storage\n",
    "from src.config import settings\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime\n",
    "\n",
    "semaphore = asyncio.Semaphore(100)  # Control the number of simultaneous requests\n",
    "\n",
    "async def main_async(request):\n",
    "    # Parsing request data\n",
    "    data = request.get_json()\n",
    "    client_id = data.get('client_id')\n",
    "    client_secret = data.get('client_secret')\n",
    "    store_name = data.get('store_name')\n",
    "    seller_id = data.get('seller_id')\n",
    "    access_token = data.get('access_token')\n",
    "\n",
    "    print('** Defining authentication... **')\n",
    "    # Authenticate (assuming this is now centralized in utils.py or a similar file)\n",
    "    if not access_token:\n",
    "        access_token = authenticate(client_id, client_secret)  # You can add this to a common module\n",
    "\n",
    "    print('** Connecting to storage and BigQuery... **')\n",
    "    # Initialize storage and BigQuery\n",
    "    storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "    bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "\n",
    "    # Define paths and table names from the config\n",
    "    bucket_name = settings.BUCKET_STORES\n",
    "    table_management = settings.TABLE_MANAGEMENT\n",
    "    destiny_table = settings.TABLE_VISITS\n",
    "\n",
    "    # Define today's date\n",
    "    today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Fetch item IDs from the storage bucket\n",
    "    blob_items_prefix = f'{store_name}/meli/api_response/items/date={today_str}/'\n",
    "    items_id = fetch_items_from_storage(\n",
    "    storage, \n",
    "    bucket_name, \n",
    "    blob_items_prefix, \n",
    "    key_names='results'\n",
    "    )\n",
    "\n",
    "    print(f'** Items found: {len(items_id)}**')\n",
    "\n",
    "    print(f'** Cleaning blob **')\n",
    "    # Path for saving \n",
    "    blob_basic_path = settings.BLOB_VISITS(store_name)\n",
    "    date_blob_path = f'{blob_basic_path}date={today_str}/'\n",
    "\n",
    "    # Clean existing files in the storage bucket\n",
    "    storage.clean_blobs(bucket_name, date_blob_path)\n",
    "\n",
    "    print(f'** Starting API requests for {len(items_id)} items**')\n",
    "    # URL function for API\n",
    "    url = settings.URL_ITEM_DETAIL\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "  \"access_token\": None,\n",
    "  \"client_id\": \"4959083987776428\",\n",
    "  \"client_secret\": \"Hw9wWSydd8PMvMEJewWoMvKGYMAWyKEw\",\n",
    "  \"seller_id\": 189643563,\n",
    "  \"store_name\": \"hubsmarthome\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = args\n",
    "client_id = data.get('client_id')\n",
    "client_secret = data.get('client_secret')\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "access_token = data.get('access_token')\n",
    "print('** Defining authentication... **')\n",
    "# Authenticate (assuming this is now centralized in utils.py or a similar file)\n",
    "if not access_token:\n",
    "    access_token = authenticate(client_id, client_secret)  # You can add this to a common module\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_VISITS\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch item IDs from the storage bucket\n",
    "blob_items_prefix = f'{store_name}/meli/api_response/items/date={today_str}/'\n",
    "items_id = fetch_items_from_storage(\n",
    "storage, \n",
    "bucket_name, \n",
    "blob_items_prefix, \n",
    "key_names='results'\n",
    ")\n",
    "print(f'** Items found: {len(items_id)}**')\n",
    "print(f'** Cleaning blob **')\n",
    "# Path for saving \n",
    "blob_basic_path = settings.BLOB_VISITS(store_name)\n",
    "date_blob_path = f'{blob_basic_path}date={today_str}/'\n",
    "# Clean existing files in the storage bucket\n",
    "storage.clean_blobs(bucket_name, date_blob_path)\n",
    "print(f'** Starting API requests for {len(items_id)} items**')\n",
    "# URL function for API\n",
    "url = settings.URL_ITEM_DETAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visits_to_dataframe(json_visit):\n",
    "    # Initialize lists to store the extracted data\n",
    "    \n",
    "    item_id = json_visit['item_id']\n",
    "    visits_data = json_visit['results']\n",
    "    dates = []\n",
    "    total_visits = []\n",
    "    companies = []\n",
    "\n",
    "    # Iterate through the data\n",
    "    for visit in visits_data:\n",
    "        dates.append(visit['date'])\n",
    "        total_visits.append(visit['total'])\n",
    "        company_list = [detail['company'] for detail in visit['visits_detail']]\n",
    "        companies.append(\", \".join(company_list))  # Join company names if there are multiple\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'item_id':item_id,\n",
    "        'date': dates,\n",
    "        'total_visits': total_visits,\n",
    "        'companies': companies\n",
    "    })\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = lambda item_id : f'https://api.mercadolibre.com/items/{item_id}/visits/time_window?last=1&unit=day'\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "item = 'MLB3326162963'\n",
    "response = requests.get(url(item), headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_basic_path = settings.BLOB_VISITS(store_name)\n",
    "bool_first_time = storage.blob_exists(bucket_name, blob_basic_path)\n",
    "bool_first_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# access_token = authenticate(client_id, client_secret)\n",
    "\n",
    "url = lambda item_id : f'https://api.mercadolibre.com/items/{item_id}/visits/time_window?last=150&unit=day&ending=2024-09-07'\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "df_visitas = pd.DataFrame()\n",
    "\n",
    "for i, item in tqdm(enumerate(items_id)):\n",
    "    \n",
    "    response = requests.get(url(item), headers=headers)\n",
    "    print(response.status_code)\n",
    "    daily_visits = response.json()\n",
    "    \n",
    "    df_ = visits_to_dataframe(daily_visits)\n",
    "    \n",
    "    df_visitas = pd.concat([df_visitas, df_], ignore_index=True)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print('Pause')\n",
    "        time.sleep(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.config import settings\n",
    "import json\n",
    "\n",
    "\n",
    "def insert_bq_visits(request):\n",
    "\n",
    "    data = request.get_json()\n",
    "    store_name = data.get('store_name')\n",
    "    seller_id = data.get('seller_id')\n",
    "\n",
    "    print('** Connecting to storage and BigQuery... **')\n",
    "    # Initialize storage and BigQuery\n",
    "    storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "    bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "\n",
    "    # Define paths and table names from the config\n",
    "    bucket_name = settings.BUCKET_STORES\n",
    "    table_management = settings.TABLE_MANAGEMENT\n",
    "    destiny_table = settings.TABLE_VISITS\n",
    "    blob_shipping_cost = settings.BLOB_VISITS(store_name)\n",
    "\n",
    "    # Define today's date\n",
    "    today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Get dates to treat\n",
    "    list_dates_to_process = bigquery.get_list_dates_to_process(seller_id, table_management, destiny_table)\n",
    "\n",
    "    print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process  ***')\n",
    "\n",
    "    df_processed_data = pd.DataFrame()\n",
    "\n",
    "    for date in list_dates_to_process:\n",
    "\n",
    "        # Transform date to string\n",
    "        date_to_process = date.strftime('%Y-%m-%d')\n",
    "        print(f'Processing date: {date_to_process}')\n",
    "        # Get blob with the date\n",
    "        blob_prefix = blob_shipping_cost + f'date={date_to_process}/'\n",
    "        # List all the files\n",
    "        blobs = storage.list_blobs(bucket_name, blob_prefix)\n",
    "\n",
    "        # Processing each blob\n",
    "        for blob in blobs:\n",
    "            print(f\"Reading file: {blob.name}\")\n",
    "            content = storage.download_json(bucket_name, blob.name)\n",
    "\n",
    "            for json in content:\n",
    "                processed_dict = process_shipping(json)\n",
    "\n",
    "                if isinstance(processed_dict, list):\n",
    "                    df_processed_data = pd.concat([df_processed_data, pd.DataFrame(processed_dict)], ignore_index = True)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        df_processed_data['correspondent_date'] = pd.to_datetime(date_to_process)\n",
    "        df_processed_data['process_time'] = datetime.now()\n",
    "        df_processed_data['seller_id'] = seller_id\n",
    "\n",
    "        print(f'*** Finished treating all data. {df_processed_data.shape[0]} products ***')\n",
    "\n",
    "        print('** Deleting existing data **')\n",
    "        bigquery.delete_existing_data(destiny_table, seller_id, date_to_process)\n",
    "        \n",
    "        print('** Correct dataframe schema **')\n",
    "        bigquery.match_dataframe_schema(df_processed_data, destiny_table)\n",
    "\n",
    "        print('** Inserting data into BQ**')\n",
    "        bigquery.insert_dataframe(df_processed_data, destiny_table)\n",
    "\n",
    "        print('** Updating log table **')\n",
    "        bigquery.update_logs_table(seller_id, date_to_process, destiny_table, table_management)\n",
    "\n",
    "    return ('Success', 200)\n",
    "\n",
    "def process_shipping(json_data):\n",
    "    try:\n",
    "        default_value = json_data.get('default')\n",
    "        channels = json_data.get('channels', [])\n",
    "        item_id = json_data.get('item_id')\n",
    "        dict_list = []\n",
    "        for channel in channels:\n",
    "            dict_content = {\n",
    "                'item_id': item_id,\n",
    "                'channel_id': channel.get('id'),\n",
    "                'mode': channel.get('mode'),\n",
    "                'logistic_type': channel.get('logistic_type'),\n",
    "                'local_pick_up': channel.get('local_pick_up'),\n",
    "                'free_shipping': channel.get('free_shipping'),\n",
    "                'store_pick_up': channel.get('store_pick_up'),\n",
    "                'default_shipping': default_value\n",
    "            }\n",
    "            dict_list.append(dict_content)\n",
    "        return dict_list\n",
    "    except Exception as e:\n",
    "        print(f'Error processing json: {json_data}, error: {e}')\n",
    "        return []\n",
    "\n",
    "        \n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=args\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_VISITS\n",
    "blob_shipping_cost = settings.BLOB_VISITS(store_name)\n",
    "# Define today's date\n",
    "today_str = datetime.today().strftime('%Y-%m-%d')\n",
    "# Get dates to treat\n",
    "list_dates_to_process = bigquery.get_list_dates_to_process(seller_id, table_management, destiny_table)\n",
    "print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process  ***')\n",
    "df_processed_data = pd.DataFrame()\n",
    "for date in list_dates_to_process:\n",
    "    # Transform date to string\n",
    "    date_to_process = date.strftime('%Y-%m-%d')\n",
    "    print(f'Processing date: {date_to_process}')\n",
    "    # Get blob with the date\n",
    "    blob_prefix = blob_shipping_cost + f'date={date_to_process}/'\n",
    "    # List all the files\n",
    "    blobs = storage.list_blobs(bucket_name, blob_prefix)\n",
    "    # Processing each blob\n",
    "    for blob in blobs:\n",
    "        print(f\"Reading file: {blob.name}\")\n",
    "        content = storage.download_json(bucket_name, blob.name)\n",
    "        for json in content:\n",
    "            processed_dict = process_visits(json)\n",
    "            if isinstance(processed_dict, list):\n",
    "                df_processed_data = pd.concat([df_processed_data, pd.DataFrame(processed_dict)], ignore_index = True)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    df_processed_data['correspondent_date'] = pd.to_datetime(date_to_process)\n",
    "    df_processed_data['process_time'] = datetime.now()\n",
    "    df_processed_data['seller_id'] = seller_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = content[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_visits(json_data):\n",
    "\n",
    "    try:\n",
    "        item_id = json_data.get(\"item_id\")\n",
    "        list_visits = []\n",
    "        for visits_per_date in json_data.get('results',[]):\n",
    "\n",
    "            dict_content = {\n",
    "                \"item_id\": item_id,\n",
    "                \"num_visits\": visits_per_date.get('total'),\n",
    "                \"date\": visits_per_date.get('date')\n",
    "            }\n",
    "\n",
    "            list_visits.append(dict_content)\n",
    "\n",
    "        return list_visits\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error processing json: {json_data}, error: {e}')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.firestore_connector import FirestoreManager\n",
    "from src.config import settings\n",
    "firestore = FirestoreManager(credentials_path=settings.PATH_SERVICE_ACCOUNT, project_id='datalake-meli-dev')\n",
    "\n",
    "firestore.clean_cache('query_cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.config import settings\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def main_fetch_sellers_information():\n",
    "\n",
    "    bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "    table_id = settings.TABLE_SELLER_INFORMATION\n",
    "\n",
    "    # Getting list of sellers to update\n",
    "    query = \"\"\"\n",
    "    WITH sellers_ids AS (\n",
    "        SELECT DISTINCT competitor_seller_id\n",
    "        FROM `datalake-v2-424516.datalake_v2.items_competitors_catalog`\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT DISTINCT competitor_seller_id\n",
    "        FROM `datalake-v2-424516.datalake_v2.items_competitors_details`\n",
    "    )\n",
    "\n",
    "    SELECT DISTINCT si.competitor_seller_id\n",
    "    FROM sellers_ids si \n",
    "    LEFT JOIN `datalake-v2-424516.datalake_v2.sellers_competitors_details` sc\n",
    "    ON CAST(sc.competitor_seller_id AS INT64) = si.competitor_seller_id\n",
    "    WHERE sc.competitor_seller_id IS NULL\n",
    "    \"\"\"\n",
    "\n",
    "    sellers_df = bigquery.run_query(query)\n",
    "    sellers_list = sellers_df['competitor_seller_id'].to_list()\n",
    "\n",
    "    if len(sellers_list) == 0:\n",
    "        print('Zero novos sellers para processar')\n",
    "    \n",
    "    else:\n",
    "        seller_details_list = []\n",
    "        for seller_id in sellers_list:\n",
    "            details = fetch_seller_details(seller_id)\n",
    "            seller_details_list.append(details)\n",
    "\n",
    "        # Creates a dataframe with all the information\n",
    "        print('Creating dataframe')\n",
    "        df_to_save = product_to_save(seller_details_list)\n",
    "\n",
    "        print(f'{df_to_save.shape[0]} sellers encontrados')\n",
    "\n",
    "        # Saving dataframe\n",
    "        print('Match schema dataframe')\n",
    "        df_to_save = bigquery.match_dataframe_schema(df_to_save, table_id)\n",
    "\n",
    "        print('Inserting dataframe')\n",
    "        bigquery.insert_dataframe(df_to_save, table_id)\n",
    "\n",
    "\n",
    "\n",
    "def fetch_seller_details(seller_id):\n",
    "\n",
    "    url = f\"https://api.mercadolibre.com/users/{seller_id}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    seller_data = response.json()\n",
    "\n",
    "    return seller_data\n",
    "    \n",
    "\n",
    "def product_to_save(product_details_list):\n",
    "    competitor_seller_list = []\n",
    "    process_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    for product_data in product_details_list:\n",
    "        if product_data:  \n",
    "\n",
    "            seller_reputation = product_data.get(\"seller_reputation\", {})\n",
    "            transactions = seller_reputation.get(\"transactions\", {})\n",
    "            site_status = product_data.get(\"status\",{})\n",
    "\n",
    "            product_dict = {\n",
    "                'process_time': process_time,\n",
    "                \"competitor_seller_id\": product_data.get(\"id\"),\n",
    "                \"competitor_seller_nickname\": product_data.get(\"nickname\"),\n",
    "                \"competitor_seller_level_id\": seller_reputation.get(\"level_id\", \"\"),\n",
    "                \"competitor_power_seller_status\": seller_reputation.get(\"power_seller_status\", \"\"),\n",
    "                \"competitor_transactions_period\": transactions.get(\"period\", \"\"),\n",
    "                \"competitor_transactions_total\": transactions.get(\"total\", 0),\n",
    "                \"competitor_site_status\": site_status.get(\"site_status\", \"\"), \n",
    "                \"competitor_permalink\": product_data.get(\"permalink\")\n",
    "            }\n",
    "            competitor_seller_list.append(product_dict)\n",
    "\n",
    "    return pd.DataFrame(competitor_seller_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "table_id = settings.TABLE_SELLER_INFORMATION\n",
    "# Getting list of sellers to update\n",
    "query = \"\"\"\n",
    "WITH sellers_ids AS (\n",
    "    SELECT DISTINCT competitor_seller_id\n",
    "    FROM `datalake-v2-424516.datalake_v2.items_competitors_catalog`\n",
    "    UNION ALL\n",
    "    SELECT DISTINCT competitor_seller_id\n",
    "    FROM `datalake-v2-424516.datalake_v2.items_competitors_details`\n",
    ")\n",
    "SELECT DISTINCT si.competitor_seller_id\n",
    "FROM sellers_ids si \n",
    "LEFT JOIN `datalake-v2-424516.datalake_v2.sellers_competitors_details` sc\n",
    "ON CAST(sc.competitor_seller_id AS INT64) = si.competitor_seller_id\n",
    "WHERE sc.competitor_seller_id IS NULL\n",
    "\"\"\"\n",
    "sellers_df = bigquery.run_query(query)\n",
    "sellers_list = sellers_df['competitor_seller_id'].to_list()\n",
    "if len(sellers_list) == 0:\n",
    "    print('Zero novos sellers para processar')\n",
    "\n",
    "else:\n",
    "    seller_details_list = []\n",
    "    for seller_id in sellers_list[:5]:\n",
    "        details = fetch_seller_details(seller_id)\n",
    "        seller_details_list.append(details)\n",
    "    # Creates a dataframe with all the information\n",
    "    print('Creating dataframe')\n",
    "    df_to_save = product_to_save(seller_details_list)\n",
    "    print(f'{df_to_save.shape[0]} sellers encontrados')\n",
    "    # Saving dataframe\n",
    "    print('Match schema dataframe')\n",
    "    df_to_save = bigquery.match_dataframe_schema(df_to_save, table_id)\n",
    "    print('Inserting dataframe')\n",
    "    bigquery.insert_dataframe(df_to_save, table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_seller_id_and_store_name(client_id, client_secret, access_token):\n",
    "    \n",
    "    if not access_token:\n",
    "        print(\"Getting access_token\")\n",
    "        token_url = 'https://api.mercadolibre.com/oauth/token'\n",
    "\n",
    "        token_data = {\n",
    "            'grant_type': 'client_credentials',\n",
    "            'client_id': client_id,\n",
    "            'client_secret': client_secret\n",
    "        }\n",
    "\n",
    "        response = requests.post(token_url, data=token_data)\n",
    "        token_info = response.json()\n",
    "        access_token = token_info['access_token']\n",
    "    \n",
    "    # Step 2: Retrieve User Information\n",
    "    user_info_url = 'https://api.mercadolibre.com/users/me'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    \n",
    "    user_response = requests.get(user_info_url, headers=headers)\n",
    "    user_info = user_response.json()\n",
    "    \n",
    "    # Extract seller ID and store name\n",
    "    seller_id = user_info['id']\n",
    "    store_name = user_info.get('nickname', 'N/A').split('.')[0]  # Using 'nickname' as store name\n",
    "\n",
    "    return store_name, seller_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access_token = 'TG-673604f2cda3960001605660-1904654004'\n",
    "client_id = '2951712600123976'\n",
    "client_secret = 'QprAIl8ydXzcxFVHjnIHT6fUQ8KpzADV'\n",
    "\n",
    "get_seller_id_and_store_name(client_id, client_secret, access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.mercadolibre.com/oauth/token\"\n",
    "\n",
    "payload = {\n",
    "    \"grant_type\": \"refresh_token\",\n",
    "    \"client_id\": f\"{client_id}\",\n",
    "    \"client_secret\": f\"{client_secret}\",\n",
    "    \"refresh_token\": f\"{access_token}\"\n",
    "}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "}\n",
    "response = requests.post(url, data=payload, headers=headers)\n",
    "tokens = response.json()\n",
    "access_token = tokens.get(\"access_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.config import settings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local credentials from: C:/Users/User/Documents/papa preco/service account/service_account_datalakev2.json\n"
     ]
    }
   ],
   "source": [
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.types import String, Integer, Float, DateTime\n",
    "import numpy as np\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = quote_plus('Glm@mysql24')  # Your actual password\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f'mysql+pymysql://geraldo-papa:{password}@34.123.250.92/glm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'item_id' updated successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# Database connection\n",
    "password = quote_plus('Glm@mysql24')\n",
    "engine = create_engine(f'mysql+pymysql://geraldo-papa:{password}@34.123.250.92/glm')\n",
    "\n",
    "# Increase VARCHAR size or set it to TEXT\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"ALTER TABLE suggested_items MODIFY COLUMN item_id TEXT;\"))\n",
    "\n",
    "print(\"Column 'item_id' updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela: competitors / Tamanho em memória: 122.72 MB\n",
      "Tempo decorrido: 133.28 segundos\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# tables_list = ['competitor', 'general', 'performance_table', 'stock_seller', 'suggested_items']\n",
    "\n",
    "tables_list = ['competitor']\n",
    "\n",
    "for table_name in tables_list:\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(f\"TRUNCATE TABLE {table_name};\"))\n",
    "\n",
    "    if table_name == 'competitor':\n",
    "        table_name = 'competitors'\n",
    "        \n",
    "    df= bigquery.run_query(f'select * from datalake-v2-424516.tables_frontend.{table_name}')\n",
    "    df['created_at'] = datetime.now()\n",
    "    df['updated_at'] = datetime.now()\n",
    "\n",
    "    memory_usage = df.memory_usage(deep=True).sum()/ (1024 ** 2)\n",
    "    print(f\"Tabela: {table_name} / Tamanho em memória: {memory_usage:.2f} MB\" )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    df.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            if_exists='append',\n",
    "            index=False,\n",
    "            chunksize=1000,\n",
    "            method='multi',\n",
    "            # dtype=data_types  # Specify data types\n",
    "        )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Tempo decorrido: {elapsed_time:.2f} segundos\")\n",
    "    print('-----------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tables_list = ['competitors', 'general', 'performance_table', 'stock_seller', 'suggested_items']\n",
    "tables_list = ['competitors']\n",
    "index_list = {\n",
    "    'competitors': ['channel', 'glm_id', 'seller_id', 'seller_sku'],\n",
    "    'general': ['glm_id', 'seller_id', 'seller_sku', 'item_id'],\n",
    "    'performance_table': ['channel', 'seller_id', 'item_id'],\n",
    "    'stock_seller': ['glm_id', 'seller_id', 'seller_sku'],\n",
    "    'suggested_items': ['seller_sku'],\n",
    "}\n",
    "\n",
    "for table in tables_list:\n",
    "    \n",
    "    df= bigquery.run_query(f'select * from datalake-v2-424516.tables_frontend.{table}')\n",
    "    df['created_at'] = datetime.now()\n",
    "    df['updated_at'] = datetime.now()\n",
    "    memory_usage = df.memory_usage(deep=True).sum()/ (1024 ** 2)\n",
    "    print(f\"Tabela: {table} / Tamanho em memória: {memory_usage:.2f} MB\" )\n",
    "\n",
    "    start_time = time.time()\n",
    "    upload_data_to_mysql(df, table_name= f'{table}', index_list= index_list[table])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Tempo decorrido: {elapsed_time:.2f} segundos\")\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= bigquery.run_query(f'select * from datalake-v2-424516.tables_frontend.{table_name}')\n",
    "df['created_at'] = datetime.now()\n",
    "df['updated_at'] = datetime.now()\n",
    "\n",
    "df.head(15).to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        chunksize=1000,\n",
    "        method='multi',\n",
    "        # dtype=data_types  # Specify data types\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.types import String, Integer, Float, DateTime\n",
    "import numpy as np\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "def upload_data_to_mysql(df, table_name, index_list=None):\n",
    "    # Replace pandas.NA and np.nan with None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    \n",
    "    password = quote_plus('Glm@mysql24')  # Your actual password\n",
    "\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine(f'mysql+pymysql://geraldo-papa:{password}@34.123.250.92/glm')\n",
    "\n",
    "    # Define data types for columns\n",
    "    data_types = {}\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            data_types[col] = String(255)  # Set VARCHAR(255) for object columns\n",
    "        elif pd.api.types.is_integer_dtype(df[col].dtype):\n",
    "            data_types[col] = Integer()\n",
    "        elif pd.api.types.is_float_dtype(df[col].dtype):\n",
    "            data_types[col] = Float()\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col].dtype):\n",
    "            data_types[col] = DateTime()\n",
    "\n",
    "    # Upload the data to MySQL with specified data types\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        chunksize=1000,\n",
    "        method='multi',\n",
    "        dtype=data_types  # Specify data types\n",
    "    )\n",
    "\n",
    "    # # Add indexes to specified columns\n",
    "    # if index_list:\n",
    "    #     with engine.connect() as conn:\n",
    "    #         for index_column in index_list:\n",
    "    #             if index_column in df.columns and df[index_column].dtype == object:\n",
    "    #                 # Specify a key length for VARCHAR/TEXT columns\n",
    "    #                 conn.execute(\n",
    "    #                     text(f'CREATE INDEX idx_{index_column} ON {table_name} ({index_column}(255));')\n",
    "    #                 )\n",
    "    #             else:\n",
    "    #                 # Create index for other types without key length\n",
    "    #                 conn.execute(\n",
    "    #                     text(f'CREATE INDEX idx_{index_column} ON {table_name} ({index_column});')\n",
    "    #                 )\n",
    "\n",
    "    print(\"Data uploaded and indexes added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tables_list = ['competitors', 'general', 'performance_table', 'stock_seller', 'suggested_items']\n",
    "tables_list = ['general']\n",
    "index_list = {\n",
    "    'competitors': ['channel', 'glm_id', 'seller_id', 'seller_sku'],\n",
    "    'general': ['glm_id', 'seller_id', 'seller_sku', 'item_id'],\n",
    "    'performance_table': ['channel', 'seller_id', 'item_id'],\n",
    "    'stock_seller': ['glm_id', 'seller_id', 'seller_sku'],\n",
    "    'suggested_items': ['seller_sku'],\n",
    "}\n",
    "\n",
    "for table in tables_list:\n",
    "    \n",
    "    df= bigquery.run_query(f'select * from datalake-v2-424516.tables_frontend.{table}')\n",
    "    df['created_at'] = datetime.now()\n",
    "    df['updated_at'] = datetime.now()\n",
    "    memory_usage = df.memory_usage(deep=True).sum()/ (1024 ** 2)\n",
    "    print(f\"Tabela: {table} / Tamanho em memória: {memory_usage:.2f} MB\" )\n",
    "\n",
    "    start_time = time.time()\n",
    "    upload_data_to_mysql(df, table_name= f'{table}', index_list= index_list[table])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Tempo decorrido: {elapsed_time:.2f} segundos\")\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def recreate_table(df):\n",
    "    # Map pandas dtypes to MySQL data types\n",
    "    dtype_mapping = {\n",
    "        'int64': 'BIGINT',\n",
    "        'float64': 'DOUBLE',\n",
    "        'object': 'TEXT',\n",
    "        'datetime64[ns]': 'DATETIME',\n",
    "        'bool': 'BOOLEAN'\n",
    "    }\n",
    "\n",
    "    # Build the CREATE TABLE statement\n",
    "    columns = df.columns.tolist()\n",
    "    sql_types = []\n",
    "    for col in columns:\n",
    "        dtype = str(df[col].dtype)\n",
    "        sql_type = dtype_mapping.get(dtype, 'TEXT')  # Default to TEXT if dtype not found\n",
    "        sql_types.append(f\"`{col}` {sql_type}\")\n",
    "\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS test_general (\n",
    "        {', '.join(sql_types)}\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to MySQL\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"34.123.250.92\",\n",
    "        user=\"geraldo-papa\",\n",
    "        password=\"Glm@mysql24\",\n",
    "        database=\"test_general_table\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Drop the table if it exists\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS test_general;\")\n",
    "        print(\"Existing table dropped.\")\n",
    "\n",
    "        # Create the new table\n",
    "        cursor.execute(create_table_query)\n",
    "        print(\"New table created with the following schema:\")\n",
    "        print(create_table_query)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Error: {}\".format(err))\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "def upload_data_to_mysql(df):\n",
    "    # Replace pandas.NA and np.nan with None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    columns = df.columns.tolist()\n",
    "\n",
    "    # Connect to MySQL with the specified database\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"34.123.250.92\",\n",
    "        user=\"geraldo-papa\",\n",
    "        password=\"Glm@mysql24\",\n",
    "        database=\"test_general_table\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Prepare the INSERT query\n",
    "    insert_query = (\n",
    "        \"INSERT INTO test_general (\" +\n",
    "        \", \".join(f\"`{col}`\" for col in columns) +\n",
    "        \") VALUES (\" +\n",
    "        \", \".join([\"%s\"] * len(columns)) +\n",
    "        \")\"\n",
    "    )\n",
    "\n",
    "    # Convert DataFrame rows to list of tuples\n",
    "    data_to_insert = []\n",
    "    for _, row in df.iterrows():\n",
    "        row_values = []\n",
    "        for col in columns:\n",
    "            value = row[col]\n",
    "            if pd.isna(value):\n",
    "                value = None\n",
    "            row_values.append(value)\n",
    "        data_to_insert.append(tuple(row_values))\n",
    "\n",
    "    try:\n",
    "        # Insert data into MySQL\n",
    "        cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "        conn.commit()  # Execute commit after all insertions\n",
    "        print(\"Data uploaded successfully to MySQL.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Error: {}\".format(err))\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Usage\n",
    "recreate_table(df)\n",
    "upload_data_to_mysql(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_data_to_mysql(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.trigger_cloud_function import TriggerCloudFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "\n",
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.common.trigger_cloud_function import TriggerCloudFunction\n",
    "\n",
    "from src.common.utils import authenticate, fetch_sales_for_day, log_process\n",
    "from src.config import settings\n",
    "from datetime import datetime, timedelta\n",
    "from flask import jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"access_token\": \"APP_USR-2951712600123976-112403-2daaae6d069355aea298d9f75a5000ff-354359142\",\n",
    "  \"client_id\": \"2951712600123976\",\n",
    "  \"client_secret\": \"QprAIl8ydXzcxFVHjnIHT6fUQ8KpzADV\",\n",
    "  \"seller_id\": 354359142,\n",
    "  \"store_name\": \"lojamercadoobra\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local credentials from: C:/Users/User/Documents/papa preco/service account/service_account_datalakev2.json\n"
     ]
    }
   ],
   "source": [
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "\n",
    "store_name = 'avelar_shop'\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "blob_basic_path = settings.BLOB_ORDERS(store_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_first_time = storage.blob_exists(bucket_name, blob_basic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local credentials from: C:/Users/User/Documents/papa preco/service account/service_account_datalakev2.json\n",
      "Bad response for function: HTTPSConnectionPool(host='southamerica-east1-datalake-v2-424516.cloudfunctions.net', port=443): Max retries exceeded with url: /fetch_historic_orders (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)')))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trigger_functions = TriggerCloudFunction(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "trigger_functions.trigger_function(function_url='https://southamerica-east1-datalake-v2-424516.cloudfunctions.net/fetch_historic_orders',\n",
    "                                           params= data) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela: general / Tamanho em memória: 37.63 MB\n",
      "Tempo decorrido: 78.35 segundos\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "tables_list = ['general']  #performance_table, suggested_items\n",
    "# Database connection\n",
    "password = quote_plus('Glm@mysql24')\n",
    "engine = create_engine(f'mysql+pymysql://geraldo-papa:{password}@34.123.250.92/glm')\n",
    "for table_name in tables_list:\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(f\"TRUNCATE TABLE {table_name};\"))\n",
    "    if table_name == 'competitor':\n",
    "        table_name = 'competitors'\n",
    "        \n",
    "    df= bigquery.run_query(f'select * from datalake-v2-424516.tables_frontend.{table_name}')\n",
    "    df['created_at'] = datetime.now()\n",
    "    df['updated_at'] = datetime.now()\n",
    "    memory_usage = df.memory_usage(deep=True).sum()/ (1024 ** 2)\n",
    "    print(f\"Tabela: {table_name} / Tamanho em memória: {memory_usage:.2f} MB\" )\n",
    "    if table_name == 'competitors':\n",
    "        table_name = 'competitor'\n",
    "        \n",
    "    start_time = time.time()\n",
    "    df.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            if_exists='append',\n",
    "            index=False,\n",
    "            chunksize=1000,\n",
    "            method='multi',\n",
    "            # dtype=data_types  # Specify data types\n",
    "        )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Tempo decorrido: {elapsed_time:.2f} segundos\")\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_aventure = {\n",
    "  \"access_token\": \"TG-673604cb0656130001f7240a-548409917\",\n",
    "  \"client_id\": \"2951712600123976\",\n",
    "  \"client_secret\": \"QprAIl8ydXzcxFVHjnIHT6fUQ8KpzADV\",\n",
    "  \"seller_id\": 1904654004,\n",
    "  \"store_name\": \"avelar_shop\"\n",
    "}\n",
    "\n",
    "\n",
    "args_avelar = {\n",
    "  \"access_token\": \"TG-673604f2cda3960001605660-1904654004\",\n",
    "  \"client_id\": \"2951712600123976\",\n",
    "  \"client_secret\": \"QprAIl8ydXzcxFVHjnIHT6fUQ8KpzADV\",\n",
    "  \"seller_id\": 1904654004,\n",
    "  \"store_name\": \"avelar_shop\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.mercadolibre.com/oauth/token\"\n",
    "\n",
    "payload = {\n",
    "    \"grant_type\": \"refresh_token\",\n",
    "    \"client_id\": f\"{args_avelar['client_id']}\",\n",
    "    \"client_secret\": f\"{args_avelar['client_secret']}\",\n",
    "    \"refresh_token\": f\"{args_avelar['access_token']}\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, data=payload, headers=headers)\n",
    "tokens = response.json()\n",
    "access_token = tokens.get(\"access_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access_token': 'APP_USR-2951712600123976-120410-8892b015182934a37d9355d27b3ac095-1904654004',\n",
       " 'token_type': 'Bearer',\n",
       " 'expires_in': 21600,\n",
       " 'scope': 'offline_access read',\n",
       " 'user_id': 1904654004,\n",
       " 'refresh_token': 'TG-67506e54202d530001723375-1904654004'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'APP_USR-4959083987776428-120510-845986165e780d9dbf7e1ef261163cfa-189643563'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_secret = 'Hw9wWSydd8PMvMEJewWoMvKGYMAWyKEw'\n",
    "client_id = '4959083987776428'\n",
    "\n",
    "def authenticate(client_id, client_secret):\n",
    "  url = \"https://api.mercadolibre.com/oauth/token\"\n",
    "  payload = {\n",
    "      'grant_type': 'client_credentials',\n",
    "      'client_id': client_id,\n",
    "      'client_secret': client_secret\n",
    "  }\n",
    "  response = requests.post(url, data=payload)\n",
    "  if response.status_code == 200:\n",
    "    return response.json()['access_token']\n",
    "  else:\n",
    "    raise Exception(\"Authentication failed\")\n",
    "  \n",
    "access_token= authenticate(client_id, client_secret)\n",
    "\n",
    "access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'P-MLB14345076',\n",
       " 'type': 'MARKETPLACE_CAMPAIGN',\n",
       " 'status': 'finished',\n",
       " 'start_date': '2024-11-01T03:00:00Z',\n",
       " 'finish_date': '2024-11-18T02:00:00Z',\n",
       " 'deadline_date': '2024-11-18T01:00:00Z',\n",
       " 'name': 'VENDA+ PRODUTOS POR ATÉ R$200',\n",
       " 'benefits': {'type': 'REBATE', 'meli_percent': 6, 'seller_percent': 13}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "promotion_id = 'P-MLB14345076'\n",
    "url = f'https://api.mercadolibre.com/seller-promotions/promotions/{promotion_id}?promotion_type=MARKETPLACE_CAMPAIGN&app_version=v2'\n",
    "\n",
    "requests.get(url, headers=headers).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix insert orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import concurrent.futures\n",
    "import os\n",
    "from src.common.cloud_storage_connector import CloudStorage\n",
    "from src.common.bigquery_connector import BigQueryManager\n",
    "from src.config import settings\n",
    "import json\n",
    "\n",
    "def insert_bq_orders(request):\n",
    "    return asyncio.run(main_async(request))\n",
    "\n",
    "async def main_async(request):\n",
    "    data = request.get_json()\n",
    "    store_name = data.get('store_name')\n",
    "    seller_id = data.get('seller_id')\n",
    "\n",
    "    print('** Connecting to storage and BigQuery... **')\n",
    "    # Initialize storage and BigQuery\n",
    "    storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "    bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "\n",
    "    # Define paths and table names from the config\n",
    "    bucket_name = settings.BUCKET_STORES\n",
    "    table_management = settings.TABLE_MANAGEMENT\n",
    "    destiny_table = settings.TABLE_ORDERS\n",
    "    blob_shipping_cost = settings.BLOB_ORDERS(store_name)\n",
    "\n",
    "    # Get dates to process\n",
    "    loop = asyncio.get_event_loop()\n",
    "    list_dates_to_process = await loop.run_in_executor(\n",
    "        None,\n",
    "        bigquery.get_list_dates_to_process,\n",
    "        seller_id,\n",
    "        table_management,\n",
    "        destiny_table\n",
    "    )\n",
    "\n",
    "    list_dates_to_process = [date.strftime('%Y-%m-%d') for date in list_dates_to_process]\n",
    "\n",
    "    print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process ***')\n",
    "\n",
    "    # Create a semaphore to limit concurrency\n",
    "    semaphore = asyncio.Semaphore(20)  # Adjust the value as needed\n",
    "    if len(list_dates_to_process) != 0:\n",
    "        # Use asyncio.gather to process dates asynchronously\n",
    "        tasks = [process_date(date, storage, bucket_name, blob_shipping_cost, semaphore) for date in list_dates_to_process]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        # Combine all DataFrames\n",
    "        df_all_processed_data = pd.concat(results, ignore_index=True)\n",
    "\n",
    "        print(f'*** Finished processing all dates. Total sales: {df_all_processed_data.shape[0]} ***')\n",
    "    \n",
    "    else:\n",
    "        print('** 0 dates to process**')\n",
    "        return ('Success', 200)\n",
    "\n",
    "    # The following steps are synchronous and don't need to be async\n",
    "    print('** Deleting existing data **')\n",
    "    bigquery.delete_existing_data(destiny_table, seller_id, list_dates_to_process, 'processed_json')\n",
    "\n",
    "    print('** Correcting dataframe schema **')\n",
    "    bigquery.match_dataframe_schema(df_all_processed_data, destiny_table)\n",
    "\n",
    "    print('** Inserting data into BigQuery **')\n",
    "    bigquery.insert_dataframe(df_all_processed_data, destiny_table)\n",
    "\n",
    "    print('** Updating log table **')\n",
    "    bigquery.update_logs_table(seller_id, list_dates_to_process, destiny_table, table_management)\n",
    "\n",
    "    return ('Success', 200)\n",
    "\n",
    "async def process_date(date, storage, bucket_name, blob_shipping_cost, semaphore):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            print(f'Processing date: {date}')\n",
    "            blob_prefix = blob_shipping_cost + f'date={date}/'\n",
    "\n",
    "            loop = asyncio.get_event_loop()\n",
    "            blobs = await loop.run_in_executor(None, storage.list_blobs, bucket_name, blob_prefix)\n",
    "\n",
    "            # Create a semaphore for blob processing\n",
    "            blob_semaphore = asyncio.Semaphore(25)  # Adjust as needed\n",
    "\n",
    "            tasks = [process_blob(blob, storage, bucket_name, blob_semaphore) for blob in blobs]\n",
    "            results = await asyncio.gather(*tasks)\n",
    "            df_processed_data = pd.concat(results, ignore_index=True)\n",
    "\n",
    "            if not df_processed_data.empty:\n",
    "                df_processed_data['processed_json'] = pd.to_datetime(df_processed_data['date_created'])\n",
    "                df_processed_data['process_time'] = datetime.now()\n",
    "\n",
    "            print(f'*** Finished processing all data for date {date}. {df_processed_data.shape[0]} sales ***')\n",
    "\n",
    "            return df_processed_data\n",
    "        except Exception as e:\n",
    "            print(f'Error processing date {date}: {e}')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "async def process_blob(blob, storage, bucket_name, semaphore):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            print(f\"Reading file: {blob.name}\")\n",
    "            loop = asyncio.get_event_loop()\n",
    "            content = await loop.run_in_executor(None, storage.download_json, bucket_name, blob.name)\n",
    "\n",
    "            # Use ThreadPoolExecutor for compatibility in async context\n",
    "            with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "                df_list = list(executor.map(process_orders_sync, [json_content['results'] for json_content in content]))\n",
    "\n",
    "            df_blob = pd.concat(df_list, ignore_index=True)\n",
    "            return df_blob\n",
    "        except Exception as e:\n",
    "            print(f'Error processing blob {blob.name}: {e}')\n",
    "            return pd.DataFrame()\n",
    "\n",
    "def process_orders_sync(json_data):\n",
    "    try:\n",
    "        structured_sales = []  # List to collect all structured_sale dictionaries\n",
    "        for sale in json_data:\n",
    "            structured_sale = {\n",
    "                'reason': sale['payments'][0].get('reason'),\n",
    "                'status_code': sale['payments'][0].get('status_code'),\n",
    "                'total_paid_amount': sale['payments'][0].get('total_paid_amount'),\n",
    "                'operation_type': sale['payments'][0].get('operation_type'),\n",
    "                'transaction_amount': sale['payments'][0].get('transaction_amount'),\n",
    "                'transaction_amount_refunded': sale['payments'][0].get('transaction_amount_refunded'),\n",
    "                'date_approved': sale['payments'][0].get('date_approved'),\n",
    "                'collector_id': sale['payments'][0].get('collector', {}).get('id'),\n",
    "                'coupon_id': sale['payments'][0].get('coupon_id'),\n",
    "                'installments': sale['payments'][0].get('installments'),\n",
    "                'authorization_code': sale['payments'][0].get('authorization_code'),\n",
    "                'taxes_amount': sale['payments'][0].get('taxes_amount'),\n",
    "                'payment_id': sale['payments'][0].get('id'),\n",
    "                'date_last_modified': sale['payments'][0].get('date_last_modified'),\n",
    "                'coupon_amount': sale['payments'][0].get('coupon_amount'),\n",
    "                'installment_amount': sale['payments'][0].get('installment_amount'),\n",
    "                'activation_uri': sale['payments'][0].get('activation_uri'),\n",
    "                'overpaid_amount': sale['payments'][0].get('overpaid_amount'),\n",
    "                'card_id': sale['payments'][0].get('card_id'),\n",
    "                'issuer_id': sale['payments'][0].get('issuer_id'),\n",
    "                'payment_method_id': sale['payments'][0].get('payment_method_id'),\n",
    "                'payment_type': sale['payments'][0].get('payment_type'),\n",
    "                'deferred_period': sale['payments'][0].get('deferred_period'),\n",
    "                'atm_transfer_reference_transaction_id': sale['payments'][0].get('atm_transfer_reference', {}).get('transaction_id'),\n",
    "                'atm_transfer_reference_company_id': sale['payments'][0].get('atm_transfer_reference', {}).get('company_id'),\n",
    "                'site_id': sale['payments'][0].get('site_id'),\n",
    "                'payer_id': sale['payments'][0].get('payer_id'),\n",
    "                'order_id': sale['payments'][0].get('order_id'),\n",
    "                'currency_id': sale['payments'][0].get('currency_id'),\n",
    "                'payment_status': sale['payments'][0].get('status'),\n",
    "                'shipping_id': sale.get('shipping', {}).get('id'),\n",
    "                'fulfilled': sale.get('fulfilled'),\n",
    "                'seller_id': sale.get('seller', {}).get('id'),\n",
    "                'buyer_id': sale.get('buyer', {}).get('id'),\n",
    "                'item_id': sale['order_items'][0]['item'].get('id'),\n",
    "                'item_title': sale['order_items'][0]['item'].get('title'),\n",
    "                'item_category_id': sale['order_items'][0]['item'].get('category_id'),\n",
    "                'item_variation_id': sale['order_items'][0]['item'].get('variation_id'),\n",
    "                'seller_custom_field': sale['order_items'][0]['item'].get('seller_custom_field'),\n",
    "                'global_price': sale['order_items'][0]['item'].get('global_price'),\n",
    "                'net_weight': sale['order_items'][0]['item'].get('net_weight'),\n",
    "                'warranty': sale['order_items'][0]['item'].get('warranty'),\n",
    "                'condition': sale['order_items'][0]['item'].get('condition'),\n",
    "                'seller_sku': sale['order_items'][0]['item'].get('seller_sku'),\n",
    "                'quantity': sale['order_items'][0].get('quantity'),\n",
    "                'unit_price': sale['order_items'][0].get('unit_price'),\n",
    "                'full_unit_price': sale['order_items'][0].get('full_unit_price'),\n",
    "                'manufacturing_days': sale['order_items'][0].get('manufacturing_days'),\n",
    "                'requested_quantity_measure': sale['order_items'][0].get('requested_quantity', {}).get('measure'),\n",
    "                'requested_quantity_value': sale['order_items'][0].get('requested_quantity', {}).get('value'),\n",
    "                'sale_fee': sale['order_items'][0].get('sale_fee'),\n",
    "                'listing_type_id': sale['order_items'][0].get('listing_type_id'),\n",
    "                'base_exchange_rate': sale['order_items'][0].get('base_exchange_rate'),\n",
    "                'base_currency_id': sale['order_items'][0].get('base_currency_id'),\n",
    "                'bundle': sale['order_items'][0].get('bundle'),\n",
    "                'element_id': sale['order_items'][0].get('element_id'),\n",
    "                'date_created': sale.get('date_created'),\n",
    "                'date_closed': sale.get('date_closed'),\n",
    "                'status': sale.get('status'),\n",
    "                'expiration_date': sale.get('expiration_date'),\n",
    "                'date_last_updated': sale.get('date_last_updated'),\n",
    "                'last_updated': sale.get('last_updated'),\n",
    "                'comment': sale.get('comment'),\n",
    "                'pack_id': sale.get('pack_id'),\n",
    "                'coupon_amount': sale.get('coupon', {}).get('amount'),\n",
    "                'coupon_id': sale.get('coupon', {}).get('id'),\n",
    "                'shipping_cost': sale.get('shipping_cost'),\n",
    "                'pickup_id': sale.get('pickup_id'),\n",
    "                'status_detail': sale.get('status_detail'),\n",
    "                'total_amount': sale.get('total_amount'),\n",
    "                'paid_amount': sale.get('paid_amount'),\n",
    "                'context_application': sale.get('context', {}).get('application'),\n",
    "                'context_product_id': sale.get('context', {}).get('product_id'),\n",
    "                'context_channel': sale.get('context', {}).get('channel'),\n",
    "                'context_site': sale.get('context', {}).get('site'),\n",
    "            }\n",
    "            structured_sales.append(structured_sale)  # Collect dictionaries\n",
    "        df_ = pd.DataFrame(structured_sales)  # Create DataFrame once\n",
    "        return df_\n",
    "    except Exception as e:\n",
    "        print(f'Error processing JSON data: {e}')\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "  \"access_token\": \"APP_USR-2951712600123976-120903-c4f3b4500e982e36eecbbc5fb1abc349-110658630\",\n",
    "  \"client_id\": \"2951712600123976\",\n",
    "  \"client_secret\": \"QprAIl8ydXzcxFVHjnIHT6fUQ8KpzADV\",\n",
    "  \"seller_id\": 189643563,\n",
    "  \"store_name\": \"xela malhas\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Connecting to storage and BigQuery... **\n",
      "Using local credentials from: C:/Users/User/Documents/papa preco/service account/service_account_datalakev2.json\n",
      "Using local credentials from: C:/Users/User/Documents/papa preco/service account/service_account_datalakev2.json\n",
      "*** Starting to process dates: 445 dates to process ***\n",
      "Processing date: 2023-10-22\n",
      "Processing date: 2024-10-21\n",
      "Processing date: 2024-04-10\n",
      "Processing date: 2024-06-11\n",
      "Processing date: 2024-01-18\n",
      "Processing date: 2023-11-19\n",
      "Processing date: 2024-04-29\n",
      "Processing date: 2024-01-01\n",
      "Processing date: 2024-11-21\n",
      "Processing date: 2024-03-23\n",
      "Processing date: 2024-07-28\n",
      "Processing date: 2023-09-28\n",
      "Processing date: 2023-11-23\n",
      "Processing date: 2024-05-24\n",
      "Processing date: 2024-10-15\n",
      "Processing date: 2024-10-28\n",
      "Processing date: 2024-03-31\n",
      "Processing date: 2023-10-17\n",
      "Processing date: 2024-03-03\n",
      "Processing date: 2024-04-27\n",
      "Error processing date 2023-10-22: No objects to concatenate\n",
      "Processing date: 2024-06-25\n",
      "Error processing date 2023-11-19: No objects to concatenate\n",
      "Processing date: 2024-03-26\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-23/total_sales=7__data=2024-03-23__processing-time=2024-12-05T07:00:00.799493-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-21/total_sales=30__data=2024-11-21__processing-time=2024-12-05T07:01:01.376148-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-10/total_sales=26__data=2024-04-10__processing-time=2024-12-05T07:00:00.533958-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-29/total_sales=15__data=2024-04-29__processing-time=2024-12-05T07:00:00.274630-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-21/total_sales=16__data=2024-10-21__processing-time=2024-12-05T07:00:00.696946-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-28/total_sales=26__data=2024-07-28__processing-time=2024-12-05T07:00:00.475681-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-11/total_sales=69__data=2024-06-11__processing-time=2024-12-05T07:00:00.620938-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-18/total_sales=14__data=2024-01-18__processing-time=2024-12-05T07:00:00.244557-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-01/total_sales=4__data=2024-01-01__processing-time=2024-12-05T07:00:00.901468-03:00.json\n",
      "Error processing date 2023-09-28: No objects to concatenate\n",
      "Processing date: 2024-07-26\n",
      "Error processing date 2023-11-23: No objects to concatenate\n",
      "Processing date: 2024-02-13\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-24/total_sales=27__data=2024-05-24__processing-time=2024-12-05T07:00:00.619476-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-28/total_sales=18__data=2024-10-28__processing-time=2024-12-05T07:00:00.106481-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-31/total_sales=13__data=2024-03-31__processing-time=2024-12-05T07:00:00.563736-03:00.json\n",
      "Error processing date 2023-10-17: No objects to concatenate\n",
      "Processing date: 2024-11-11\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-03/total_sales=17__data=2024-03-03__processing-time=2024-12-05T07:00:00.090798-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-27/total_sales=14__data=2024-04-27__processing-time=2024-12-05T07:00:00.913113-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-15/total_sales=25__data=2024-10-15__processing-time=2024-12-05T07:00:00.814126-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-25/total_sales=56__data=2024-06-25__processing-time=2024-12-05T07:00:00.702744-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-26/total_sales=17__data=2024-03-26__processing-time=2024-12-05T07:00:00.198978-03:00.json\n",
      "*** Finished processing all data for date 2024-03-23. 7 sales ***\n",
      "Processing date: 2024-12-02\n",
      "*** Finished processing all data for date 2024-11-21. 30 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-13/total_sales=14__data=2024-02-13__processing-time=2024-12-05T07:00:00.382726-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-26/total_sales=27__data=2024-07-26__processing-time=2024-12-05T07:00:00.260918-03:00.json\n",
      "Processing date: 2024-07-07\n",
      "*** Finished processing all data for date 2024-01-01. 4 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-11/total_sales=45__data=2024-11-11__processing-time=2024-12-05T07:00:00.382186-03:00.json\n",
      "Processing date: 2024-06-18\n",
      "*** Finished processing all data for date 2024-01-18. 14 sales ***\n",
      "Processing date: 2024-05-15\n",
      "*** Finished processing all data for date 2024-04-29. 15 sales ***\n",
      "Processing date: 2023-10-27\n",
      "*** Finished processing all data for date 2024-10-21. 16 sales ***\n",
      "Processing date: 2023-10-01\n",
      "*** Finished processing all data for date 2024-10-28. 18 sales ***\n",
      "Processing date: 2024-08-25\n",
      "*** Finished processing all data for date 2024-03-31. 13 sales ***\n",
      "Processing date: 2023-12-12\n",
      "*** Finished processing all data for date 2024-07-28. 26 sales ***\n",
      "Processing date: 2024-11-01\n",
      "*** Finished processing all data for date 2024-04-10. 26 sales ***\n",
      "Processing date: 2024-12-05\n",
      "*** Finished processing all data for date 2024-05-24. 27 sales ***\n",
      "Processing date: 2024-09-02\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-12-02/total_sales=45__data=2024-12-02__processing-time=2024-12-05T07:01:01.297812-03:00.json\n",
      "*** Finished processing all data for date 2024-03-03. 17 sales ***\n",
      "Processing date: 2023-11-20\n",
      "*** Finished processing all data for date 2024-04-27. 14 sales ***\n",
      "Processing date: 2024-06-09\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-07/total_sales=62__data=2024-07-07__processing-time=2024-12-05T07:00:00.040314-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-18/total_sales=73__data=2024-06-18__processing-time=2024-12-05T07:00:00.073627-03:00.json\n",
      "Error processing date 2023-10-27: No objects to concatenate\n",
      "Processing date: 2024-01-31\n",
      "*** Finished processing all data for date 2024-06-11. 69 sales ***\n",
      "Processing date: 2024-05-13\n",
      "Error processing date 2023-10-01: No objects to concatenate\n",
      "Processing date: 2024-07-24\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-12-05/total_sales=49__data=2024-12-05__processing-time=2024-12-06T07:00:00.677399-03:00.json\n",
      "*** Finished processing all data for date 2024-02-13. 14 sales ***\n",
      "Processing date: 2023-11-04\n",
      "*** Finished processing all data for date 2024-03-26. 17 sales ***\n",
      "Processing date: 2024-02-01\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-09/total_sales=55__data=2024-06-09__processing-time=2024-12-05T07:00:00.542189-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-15/total_sales=24__data=2024-05-15__processing-time=2024-12-05T07:00:00.589781-03:00.json\n",
      "Error processing date 2023-11-20: No objects to concatenate\n",
      "Processing date: 2024-03-05\n",
      "*** Finished processing all data for date 2024-06-25. 56 sales ***\n",
      "Processing date: 2024-08-04\n",
      "*** Finished processing all data for date 2024-10-15. 25 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-25/total_sales=24__data=2024-08-25__processing-time=2024-12-05T07:00:00.037983-03:00.json\n",
      "Processing date: 2024-08-24\n",
      "*** Finished processing all data for date 2024-07-26. 27 sales ***\n",
      "Processing date: 2023-12-26\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-12/total_sales=15__data=2023-12-12__processing-time=2024-12-05T07:00:00.378763-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-01/total_sales=11__data=2024-11-01__processing-time=2024-12-05T07:00:00.584943-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-13/total_sales=18__data=2024-05-13__processing-time=2024-12-05T07:00:00.471894-03:00.json\n",
      "*** Finished processing all data for date 2024-11-11. 45 sales ***\n",
      "Processing date: 2024-09-28\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-02/total_sales=35__data=2024-09-02__processing-time=2024-12-05T07:00:00.073176-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-24/total_sales=40__data=2024-07-24__processing-time=2024-12-05T07:00:00.071872-03:00.json\n",
      "Error processing date 2023-11-04: No objects to concatenate\n",
      "Processing date: 2023-10-02\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-01/total_sales=9__data=2024-02-01__processing-time=2024-12-05T07:00:00.543803-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-05/total_sales=18__data=2024-03-05__processing-time=2024-12-05T07:00:00.511954-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-04/total_sales=22__data=2024-08-04__processing-time=2024-12-05T07:00:00.073690-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-31/total_sales=11__data=2024-01-31__processing-time=2024-12-05T07:00:00.535795-03:00.json\n",
      "*** Finished processing all data for date 2024-12-05. 49 sales ***\n",
      "Processing date: 2024-06-01\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-24/total_sales=26__data=2024-08-24__processing-time=2024-12-05T07:00:00.018867-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-26/total_sales=34__data=2023-12-26__processing-time=2024-12-05T07:00:00.522748-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-28/total_sales=27__data=2024-09-28__processing-time=2024-12-05T07:00:00.296323-03:00.json\n",
      "*** Finished processing all data for date 2024-06-18. 73 sales ***\n",
      "Processing date: 2024-01-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Finished processing all data for date 2024-06-09. 55 sales ***\n",
      "Processing date: 2023-09-25\n",
      "*** Finished processing all data for date 2024-12-02. 45 sales ***\n",
      "Processing date: 2024-09-20\n",
      "*** Finished processing all data for date 2024-05-13. 18 sales ***\n",
      "Processing date: 2024-10-29\n",
      "*** Finished processing all data for date 2024-11-01. 11 sales ***\n",
      "Processing date: 2024-11-19\n",
      "*** Finished processing all data for date 2024-05-15. 24 sales ***\n",
      "Processing date: 2023-10-21\n",
      "*** Finished processing all data for date 2024-02-01. 9 sales ***\n",
      "Processing date: 2024-09-23\n",
      "*** Finished processing all data for date 2024-07-07. 62 sales ***\n",
      "Processing date: 2023-11-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Finished processing all data for date 2024-08-25. 24 sales ***\n",
      "Processing date: 2024-06-29\n",
      "*** Finished processing all data for date 2023-12-12. 15 sales ***\n",
      "Processing date: 2023-11-02\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-01/total_sales=46__data=2024-06-01__processing-time=2024-12-05T07:00:00.080638-03:00.json\n",
      "Error processing date 2023-10-02: No objects to concatenate\n",
      "Processing date: 2024-02-16\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-30/total_sales=13__data=2024-01-30__processing-time=2024-12-05T07:00:00.522677-03:00.json\n",
      "Error processing date 2023-09-25: No objects to concatenate\n",
      "Processing date: 2023-10-19\n",
      "*** Finished processing all data for date 2024-09-02. 35 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-29/total_sales=26__data=2024-10-29__processing-time=2024-12-05T07:00:00.121887-03:00.json\n",
      "Processing date: 2024-03-29\n",
      "*** Finished processing all data for date 2024-03-05. 18 sales ***\n",
      "Processing date: 2024-03-16\n",
      "*** Finished processing all data for date 2024-01-31. 11 sales ***\n",
      "Processing date: 2024-09-22\n",
      "*** Finished processing all data for date 2024-08-04. 22 sales ***\n",
      "Processing date: 2024-01-13\n",
      "*** Finished processing all data for date 2024-07-24. 40 sales ***\n",
      "Processing date: 2024-06-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-23/total_sales=26__data=2024-09-23__processing-time=2024-12-05T07:00:00.898534-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-29/total_sales=40__data=2024-06-29__processing-time=2024-12-05T07:00:00.719762-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-16/total_sales=9__data=2024-02-16__processing-time=2024-12-05T07:00:00.738459-03:00.json\n",
      "Error processing date 2023-11-02: No objects to concatenate\n",
      "Processing date: 2023-12-05\n",
      "*** Finished processing all data for date 2024-08-24. 26 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-20/total_sales=26__data=2024-09-20__processing-time=2024-12-05T07:00:00.503570-03:00.json\n",
      "Processing date: 2024-06-23\n",
      "*** Finished processing all data for date 2024-09-28. 27 sales ***\n",
      "Processing date: 2024-02-29\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-19/total_sales=31__data=2024-11-19__processing-time=2024-12-05T07:00:00.948528-03:00.json\n",
      "Error processing date 2023-10-21: No objects to concatenate\n",
      "Processing date: 2024-06-20\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-16/total_sales=10__data=2024-03-16__processing-time=2024-12-05T07:00:00.274491-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-22/total_sales=18__data=2024-09-22__processing-time=2024-12-05T07:00:00.844803-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-13/total_sales=13__data=2024-01-13__processing-time=2024-12-05T07:00:00.996717-03:00.json\n",
      "Error processing date 2023-11-08: No objects to concatenate\n",
      "Processing date: 2024-06-05\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-07/total_sales=46__data=2024-06-07__processing-time=2024-12-05T07:00:00.707999-03:00.json\n",
      "*** Finished processing all data for date 2023-12-26. 34 sales ***\n",
      "Processing date: 2023-09-30\n",
      "Error processing date 2023-10-19: No objects to concatenate\n",
      "Processing date: 2023-10-25\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-29/total_sales=6__data=2024-03-29__processing-time=2024-12-05T07:00:00.185359-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-29/total_sales=8__data=2024-02-29__processing-time=2024-12-05T07:00:00.038775-03:00.json\n",
      "*** Finished processing all data for date 2024-06-01. 46 sales ***\n",
      "Processing date: 2024-09-05\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-20/total_sales=53__data=2024-06-20__processing-time=2024-12-05T07:00:00.033171-03:00.json\n",
      "*** Finished processing all data for date 2024-01-30. 13 sales ***\n",
      "Processing date: 2024-03-28\n",
      "Error processing date 2023-12-05: No objects to concatenate\n",
      "Processing date: 2023-11-27\n",
      "*** Finished processing all data for date 2024-09-23. 26 sales ***\n",
      "Processing date: 2024-06-16\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-23/total_sales=33__data=2024-06-23__processing-time=2024-12-05T07:00:00.252570-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-05/total_sales=58__data=2024-06-05__processing-time=2024-12-05T07:00:00.933296-03:00.json\n",
      "*** Finished processing all data for date 2024-09-20. 26 sales ***\n",
      "Processing date: 2023-09-22\n",
      "Error processing date 2023-09-30: No objects to concatenate\n",
      "Processing date: 2024-09-03\n",
      "*** Finished processing all data for date 2024-02-16. 9 sales ***\n",
      "Processing date: 2024-07-11\n",
      "*** Finished processing all data for date 2024-10-29. 26 sales ***\n",
      "Processing date: 2023-10-08\n",
      "Error processing date 2023-10-25: No objects to concatenate\n",
      "Processing date: 2024-11-25\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-28/total_sales=10__data=2024-03-28__processing-time=2024-12-05T07:00:00.216504-03:00.json\n",
      "*** Finished processing all data for date 2024-09-22. 18 sales ***\n",
      "*** Finished processing all data for date 2024-11-19. 31 sales ***\n",
      "Processing date: 2024-07-04\n",
      "Processing date: 2024-10-23\n",
      "*** Finished processing all data for date 2024-02-29. 8 sales ***\n",
      "Processing date: 2024-06-24\n",
      "*** Finished processing all data for date 2024-03-16. 10 sales ***\n",
      "Processing date: 2023-09-21\n",
      "*** Finished processing all data for date 2024-06-29. 40 sales ***\n",
      "Processing date: 2024-09-29\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-03/total_sales=38__data=2024-09-03__processing-time=2024-12-05T07:00:00.058104-03:00.json\n",
      "*** Finished processing all data for date 2024-01-13. 13 sales ***\n",
      "Processing date: 2024-05-08\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-11/total_sales=46__data=2024-07-11__processing-time=2024-12-05T07:00:00.549299-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-05/total_sales=28__data=2024-09-05__processing-time=2024-12-05T07:00:00.086005-03:00.json\n",
      "Error processing date 2023-11-27: No objects to concatenate\n",
      "Processing date: 2024-06-04\n",
      "*** Finished processing all data for date 2024-06-07. 46 sales ***\n",
      "Processing date: 2023-12-31\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-25/total_sales=36__data=2024-11-25__processing-time=2024-12-05T07:01:01.709071-03:00.json\n",
      "*** Finished processing all data for date 2024-03-29. 6 sales ***\n",
      "Processing date: 2024-02-07\n",
      "Error processing date 2023-09-22: No objects to concatenate\n",
      "Processing date: 2024-09-15\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-04/total_sales=57__data=2024-07-04__processing-time=2024-12-05T07:00:00.078087-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-16/total_sales=51__data=2024-06-16__processing-time=2024-12-05T07:00:00.319477-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-23/total_sales=17__data=2024-10-23__processing-time=2024-12-05T07:00:00.710886-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-24/total_sales=50__data=2024-06-24__processing-time=2024-12-05T07:00:00.261895-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-29/total_sales=18__data=2024-09-29__processing-time=2024-12-05T07:00:00.277140-03:00.json\n",
      "*** Finished processing all data for date 2024-06-20. 53 sales ***\n",
      "Processing date: 2024-09-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Finished processing all data for date 2024-06-23. 33 sales ***\n",
      "Processing date: 2023-11-09\n",
      "*** Finished processing all data for date 2024-06-05. 58 sales ***\n",
      "Processing date: 2023-12-15\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-07/total_sales=15__data=2024-02-07__processing-time=2024-12-05T07:00:00.017285-03:00.json\n",
      "Error processing date 2023-10-08: No objects to concatenate\n",
      "Processing date: 2024-06-06\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-15/total_sales=31__data=2024-09-15__processing-time=2024-12-05T07:00:00.937952-03:00.json\n",
      "Error processing date 2023-09-21: No objects to concatenate\n",
      "Processing date: 2024-08-23\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-08/total_sales=19__data=2024-05-08__processing-time=2024-12-05T07:00:00.851068-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-04/total_sales=88__data=2024-06-04__processing-time=2024-12-05T07:00:00.948779-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-31/total_sales=5__data=2023-12-31__processing-time=2024-12-05T07:00:00.903859-03:00.json\n",
      "*** Finished processing all data for date 2024-03-28. 10 sales ***\n",
      "Processing date: 2024-05-01\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-04/total_sales=36__data=2024-09-04__processing-time=2024-12-05T07:00:00.047531-03:00.json\n",
      "Error processing date 2023-11-09: No objects to concatenate\n",
      "Processing date: 2024-10-01\n",
      "*** Finished processing all data for date 2024-07-11. 46 sales ***\n",
      "Processing date: 2024-06-28\n",
      "*** Finished processing all data for date 2024-11-25. 36 sales ***\n",
      "Processing date: 2024-06-15\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-15/total_sales=22__data=2023-12-15__processing-time=2024-12-05T07:00:00.042947-03:00.json\n",
      "*** Finished processing all data for date 2024-09-03. 38 sales ***\n",
      "Processing date: 2024-05-27\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-23/total_sales=26__data=2024-08-23__processing-time=2024-12-05T07:00:00.988810-03:00.json\n",
      "*** Finished processing all data for date 2024-09-05. 28 sales ***\n",
      "Processing date: 2023-12-21\n",
      "*** Finished processing all data for date 2024-09-29. 18 sales ***\n",
      "Processing date: 2024-07-25\n",
      "*** Finished processing all data for date 2024-06-16. 51 sales ***\n",
      "Processing date: 2024-11-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-01/total_sales=24__data=2024-05-01__processing-time=2024-12-05T07:00:00.293986-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-01/total_sales=24__data=2024-10-01__processing-time=2024-12-05T07:00:00.909766-03:00.json\n",
      "*** Finished processing all data for date 2024-06-24. 50 sales ***\n",
      "Processing date: 2023-12-24\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-06/total_sales=74__data=2024-06-06__processing-time=2024-12-05T07:00:00.896238-03:00.json\n",
      "*** Finished processing all data for date 2024-10-23. 17 sales ***\n",
      "Processing date: 2023-11-03\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-27/total_sales=48__data=2024-05-27__processing-time=2024-12-05T07:00:00.673542-03:00.json\n",
      "*** Finished processing all data for date 2024-09-15. 31 sales ***\n",
      "Processing date: 2024-10-10\n",
      "*** Finished processing all data for date 2024-07-04. 57 sales ***\n",
      "Processing date: 2023-12-17\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-25/total_sales=43__data=2024-07-25__processing-time=2024-12-05T07:00:00.114928-03:00.json\n",
      "*** Finished processing all data for date 2023-12-31. 5 sales ***\n",
      "Processing date: 2024-03-14\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-12/total_sales=32__data=2024-11-12__processing-time=2024-12-05T07:00:00.403356-03:00.json\n",
      "*** Finished processing all data for date 2024-02-07. 15 sales ***\n",
      "Processing date: 2024-05-20\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-28/total_sales=45__data=2024-06-28__processing-time=2024-12-05T07:00:00.690013-03:00.json\n",
      "*** Finished processing all data for date 2024-06-04. 88 sales ***\n",
      "Processing date: 2023-12-14\n",
      "*** Finished processing all data for date 2024-05-08. 19 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-15/total_sales=33__data=2024-06-15__processing-time=2024-12-05T07:00:00.042047-03:00.json\n",
      "Processing date: 2024-07-15\n",
      "*** Finished processing all data for date 2024-09-04. 36 sales ***\n",
      "Processing date: 2024-05-29\n",
      "*** Finished processing all data for date 2023-12-15. 22 sales ***\n",
      "Processing date: 2024-03-12\n",
      "Error processing date 2023-11-03: No objects to concatenate\n",
      "Processing date: 2024-02-11\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-17/total_sales=35__data=2023-12-17__processing-time=2024-12-05T07:00:00.135300-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-10/total_sales=25__data=2024-10-10__processing-time=2024-12-05T07:00:00.405269-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-21/total_sales=40__data=2023-12-21__processing-time=2024-12-05T07:00:00.105261-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-14/total_sales=18__data=2024-03-14__processing-time=2024-12-05T07:00:00.951847-03:00.json\n",
      "*** Finished processing all data for date 2024-08-23. 26 sales ***\n",
      "Processing date: 2023-12-04\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-14/total_sales=11__data=2023-12-14__processing-time=2024-12-05T07:00:00.009193-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-15/total_sales=39__data=2024-07-15__processing-time=2024-12-05T07:00:00.944833-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-24/total_sales=29__data=2023-12-24__processing-time=2024-12-05T07:00:00.115804-03:00.json\n",
      "*** Finished processing all data for date 2024-10-01. 24 sales ***\n",
      "Processing date: 2024-11-30\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-11/total_sales=6__data=2024-02-11__processing-time=2024-12-05T07:00:00.388462-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-20/total_sales=12__data=2024-05-20__processing-time=2024-12-05T07:00:00.234190-03:00.json\n",
      "*** Finished processing all data for date 2024-06-06. 74 sales ***\n",
      "Processing date: 2024-09-30\n",
      "*** Finished processing all data for date 2024-07-25. 43 sales ***\n",
      "Processing date: 2024-02-15\n",
      "*** Finished processing all data for date 2024-05-27. 48 sales ***\n",
      "Processing date: 2024-03-08\n",
      "*** Finished processing all data for date 2024-05-01. 24 sales ***\n",
      "Processing date: 2024-02-24\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-29/total_sales=46__data=2024-05-29__processing-time=2024-12-05T07:00:00.015403-03:00.json\n",
      "Error processing date 2023-12-04: No objects to concatenate\n",
      "Processing date: 2024-06-19\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-12/total_sales=17__data=2024-03-12__processing-time=2024-12-05T07:00:00.907986-03:00.json\n",
      "*** Finished processing all data for date 2023-12-17. 35 sales ***\n",
      "Processing date: 2024-10-04\n",
      "*** Finished processing all data for date 2023-12-14. 11 sales ***\n",
      "Processing date: 2024-07-16\n",
      "*** Finished processing all data for date 2024-02-11. 6 sales ***\n",
      "Processing date: 2023-12-08\n",
      "*** Finished processing all data for date 2024-11-12. 32 sales ***\n",
      "Processing date: 2023-10-29\n",
      "*** Finished processing all data for date 2024-03-14. 18 sales ***\n",
      "Processing date: 2024-04-13\n",
      "*** Finished processing all data for date 2024-06-15. 33 sales ***\n",
      "Processing date: 2023-10-12\n",
      "*** Finished processing all data for date 2024-06-28. 45 sales ***\n",
      "Processing date: 2024-09-27\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-08/total_sales=13__data=2024-03-08__processing-time=2024-12-05T07:00:00.530643-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-24/total_sales=5__data=2024-02-24__processing-time=2024-12-05T07:00:00.665437-03:00.json\n",
      "*** Finished processing all data for date 2023-12-21. 40 sales ***\n",
      "Processing date: 2024-03-13\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-30/total_sales=24__data=2024-09-30__processing-time=2024-12-05T07:00:00.286350-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-19/total_sales=58__data=2024-06-19__processing-time=2024-12-05T07:00:00.216070-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-30/total_sales=36__data=2024-11-30__processing-time=2024-12-05T07:01:01.281201-03:00.json\n",
      "*** Finished processing all data for date 2024-07-15. 39 sales ***\n",
      "Processing date: 2024-08-08\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-16/total_sales=67__data=2024-07-16__processing-time=2024-12-05T07:00:00.214533-03:00.json\n",
      "*** Finished processing all data for date 2023-12-24. 29 sales ***\n",
      "Processing date: 2023-09-27\n",
      "*** Finished processing all data for date 2024-05-20. 12 sales ***\n",
      "Processing date: 2024-01-08\n",
      "*** Finished processing all data for date 2024-10-10. 25 sales ***\n",
      "Processing date: 2023-11-29\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-13/total_sales=12__data=2024-04-13__processing-time=2024-12-05T07:00:00.564060-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-15/total_sales=7__data=2024-02-15__processing-time=2024-12-05T07:00:00.760820-03:00.json\n",
      "Error processing date 2023-10-12: No objects to concatenate\n",
      "Processing date: 2024-10-31\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-13/total_sales=18__data=2024-03-13__processing-time=2024-12-05T07:00:00.923901-03:00.json\n",
      "*** Finished processing all data for date 2024-02-24. 5 sales ***\n",
      "Processing date: 2024-10-17\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-08/total_sales=2__data=2023-12-08__processing-time=2024-12-05T07:00:00.114182-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-04/total_sales=19__data=2024-10-04__processing-time=2024-12-05T07:00:00.889675-03:00.json\n",
      "*** Finished processing all data for date 2024-03-08. 13 sales ***\n",
      "Processing date: 2024-10-05\n",
      "Error processing date 2023-10-29: No objects to concatenate\n",
      "Processing date: 2024-05-04\n",
      "*** Finished processing all data for date 2024-05-29. 46 sales ***\n",
      "Processing date: 2024-10-24\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-08/total_sales=10__data=2024-01-08__processing-time=2024-12-05T07:00:00.433851-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-27/total_sales=55__data=2024-09-27__processing-time=2024-12-05T07:00:00.427992-03:00.json\n",
      "Error processing date 2023-09-27: No objects to concatenate\n",
      "Processing date: 2024-01-05\n",
      "Error processing date 2023-11-29: No objects to concatenate\n",
      "Processing date: 2023-09-23\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-08/total_sales=15__data=2024-08-08__processing-time=2024-12-05T07:00:00.483842-03:00.json\n",
      "*** Finished processing all data for date 2024-03-12. 17 sales ***\n",
      "Processing date: 2024-10-18\n",
      "*** Finished processing all data for date 2024-02-15. 7 sales ***\n",
      "Processing date: 2024-07-23\n",
      "*** Finished processing all data for date 2024-04-13. 12 sales ***\n",
      "Processing date: 2023-12-16\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-05/total_sales=18__data=2024-10-05__processing-time=2024-12-05T07:00:00.901050-03:00.json\n",
      "*** Finished processing all data for date 2024-06-19. 58 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-17/total_sales=21__data=2024-10-17__processing-time=2024-12-05T07:00:00.320674-03:00.json\n",
      "Processing date: 2024-06-21\n",
      "*** Finished processing all data for date 2024-09-30. 24 sales ***\n",
      "Processing date: 2024-04-23\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-31/total_sales=20__data=2024-10-31__processing-time=2024-12-05T07:00:00.601084-03:00.json\n",
      "*** Finished processing all data for date 2024-03-13. 18 sales ***\n",
      "Processing date: 2024-08-31\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-04/total_sales=10__data=2024-05-04__processing-time=2024-12-05T07:00:00.826002-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-05/total_sales=18__data=2024-01-05__processing-time=2024-12-05T07:00:00.427469-03:00.json\n",
      "*** Finished processing all data for date 2024-07-16. 67 sales ***\n",
      "Processing date: 2024-11-16\n",
      "*** Finished processing all data for date 2023-12-08. 2 sales ***\n",
      "Processing date: 2024-11-13\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-24/total_sales=19__data=2024-10-24__processing-time=2024-12-05T07:00:00.716468-03:00.json\n",
      "*** Finished processing all data for date 2024-08-08. 15 sales ***\n",
      "Processing date: 2024-03-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-21/total_sales=38__data=2024-06-21__processing-time=2024-12-05T07:00:00.837967-03:00.json\n",
      "Error processing date 2023-09-23: No objects to concatenate\n",
      "Processing date: 2024-07-14\n",
      "*** Finished processing all data for date 2024-11-30. 36 sales ***\n",
      "Processing date: 2024-05-16\n",
      "*** Finished processing all data for date 2024-09-27. 55 sales ***\n",
      "Processing date: 2024-08-17\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-18/total_sales=12__data=2024-10-18__processing-time=2024-12-05T07:00:00.289076-03:00.json\n",
      "*** Finished processing all data for date 2024-01-08. 10 sales ***\n",
      "Processing date: 2024-11-06\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-31/total_sales=23__data=2024-08-31__processing-time=2024-12-05T07:00:00.460201-03:00.json\n",
      "*** Finished processing all data for date 2024-10-04. 19 sales ***\n",
      "Processing date: 2024-02-25\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-23/total_sales=39__data=2024-07-23__processing-time=2024-12-05T07:00:00.088437-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-16/total_sales=22__data=2024-11-16__processing-time=2024-12-05T07:00:00.956854-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-16/total_sales=23__data=2023-12-16__processing-time=2024-12-05T07:00:00.072325-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-13/total_sales=32__data=2024-11-13__processing-time=2024-12-05T07:00:00.417669-03:00.json\n",
      "*** Finished processing all data for date 2024-10-17. 21 sales ***\n",
      "Processing date: 2024-05-06\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-16/total_sales=15__data=2024-05-16__processing-time=2024-12-05T07:00:00.597872-03:00.json\n",
      "*** Finished processing all data for date 2024-05-04. 10 sales ***\n",
      "Processing date: 2024-05-17\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-23/total_sales=23__data=2024-04-23__processing-time=2024-12-05T07:00:00.662337-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-25/total_sales=12__data=2024-02-25__processing-time=2024-12-05T07:00:00.674866-03:00.json\n",
      "*** Finished processing all data for date 2024-10-18. 12 sales ***\n",
      "Processing date: 2023-11-24\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-14/total_sales=39__data=2024-07-14__processing-time=2024-12-05T07:00:00.913586-03:00.json\n",
      "*** Finished processing all data for date 2024-10-05. 18 sales ***\n",
      "Processing date: 2023-11-21\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-17/total_sales=20__data=2024-08-17__processing-time=2024-12-05T07:00:00.587343-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-07/total_sales=18__data=2024-03-07__processing-time=2024-12-05T07:00:00.505777-03:00.json\n",
      "*** Finished processing all data for date 2024-06-21. 38 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-06/total_sales=22__data=2024-11-06__processing-time=2024-12-05T07:00:00.976134-03:00.json\n",
      "Processing date: 2024-03-21\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-06/total_sales=21__data=2024-05-06__processing-time=2024-12-05T07:00:00.843823-03:00.json\n",
      "*** Finished processing all data for date 2024-10-31. 20 sales ***\n",
      "Processing date: 2024-02-05\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-17/total_sales=11__data=2024-05-17__processing-time=2024-12-05T07:00:00.632538-03:00.json\n",
      "Error processing date 2023-11-24: No objects to concatenate\n",
      "Processing date: 2024-04-01\n",
      "*** Finished processing all data for date 2024-10-24. 19 sales ***\n",
      "Processing date: 2024-01-14\n",
      "*** Finished processing all data for date 2024-01-05. 18 sales ***\n",
      "Processing date: 2024-01-06\n",
      "*** Finished processing all data for date 2024-08-31. 23 sales ***\n",
      "Processing date: 2024-08-27\n",
      "*** Finished processing all data for date 2024-05-16. 15 sales ***\n",
      "Processing date: 2024-04-21\n",
      "*** Finished processing all data for date 2023-12-16. 23 sales ***\n",
      "Processing date: 2024-10-26\n",
      "*** Finished processing all data for date 2024-11-16. 22 sales ***\n",
      "Processing date: 2024-05-12\n",
      "*** Finished processing all data for date 2024-11-13. 32 sales ***\n",
      "Processing date: 2023-10-09\n",
      "*** Finished processing all data for date 2024-04-23. 23 sales ***\n",
      "Processing date: 2024-04-24\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-21/total_sales=20__data=2024-03-21__processing-time=2024-12-05T07:00:00.793240-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-05/total_sales=12__data=2024-02-05__processing-time=2024-12-05T07:00:00.989669-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-01/total_sales=18__data=2024-04-01__processing-time=2024-12-05T07:00:00.579085-03:00.json\n",
      "Error processing date 2023-11-21: No objects to concatenate\n",
      "Processing date: 2024-09-11\n",
      "*** Finished processing all data for date 2024-08-17. 20 sales ***\n",
      "Processing date: 2024-04-30\n",
      "*** Finished processing all data for date 2024-03-07. 18 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-21/total_sales=16__data=2024-04-21__processing-time=2024-12-05T07:00:00.528191-03:00.json\n",
      "Processing date: 2024-01-09\n",
      "*** Finished processing all data for date 2024-07-23. 39 sales ***\n",
      "Processing date: 2024-08-10\n",
      "*** Finished processing all data for date 2024-02-25. 12 sales ***\n",
      "Processing date: 2024-08-20\n",
      "*** Finished processing all data for date 2024-11-06. 22 sales ***\n",
      "Processing date: 2024-04-04\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-26/total_sales=10__data=2024-10-26__processing-time=2024-12-05T07:00:00.056268-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-12/total_sales=9__data=2024-05-12__processing-time=2024-12-05T07:00:00.246685-03:00.json\n",
      "*** Finished processing all data for date 2024-05-17. 11 sales ***\n",
      "Processing date: 2024-06-27\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-24/total_sales=20__data=2024-04-24__processing-time=2024-12-05T07:00:00.888618-03:00.json\n",
      "*** Finished processing all data for date 2024-05-06. 21 sales ***\n",
      "Processing date: 2024-02-08\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-14/total_sales=12__data=2024-01-14__processing-time=2024-12-05T07:00:00.823060-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-09/total_sales=17__data=2024-01-09__processing-time=2024-12-05T07:00:00.442595-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-06/total_sales=12__data=2024-01-06__processing-time=2024-12-05T07:00:00.422170-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-30/total_sales=16__data=2024-04-30__processing-time=2024-12-05T07:00:00.268143-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-27/total_sales=53__data=2024-08-27__processing-time=2024-12-05T07:00:00.596896-03:00.json\n",
      "*** Finished processing all data for date 2024-07-14. 39 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-10/total_sales=28__data=2024-08-10__processing-time=2024-12-05T07:00:00.514185-03:00.json\n",
      "Processing date: 2024-07-12\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-04/total_sales=7__data=2024-04-04__processing-time=2024-12-05T07:00:00.144600-03:00.json\n",
      "*** Finished processing all data for date 2024-02-05. 12 sales ***\n",
      "Processing date: 2024-09-01\n",
      "Error processing date 2023-10-09: No objects to concatenate\n",
      "Processing date: 2023-12-23\n",
      "*** Finished processing all data for date 2024-03-21. 20 sales ***\n",
      "Processing date: 2024-12-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-11/total_sales=32__data=2024-09-11__processing-time=2024-12-05T07:00:00.885516-03:00.json\n",
      "*** Finished processing all data for date 2024-05-12. 9 sales ***\n",
      "Processing date: 2024-08-13\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-20/total_sales=27__data=2024-08-20__processing-time=2024-12-05T07:00:00.600455-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-27/total_sales=56__data=2024-06-27__processing-time=2024-12-05T07:00:00.813535-03:00.json\n",
      "*** Finished processing all data for date 2024-04-24. 20 sales ***\n",
      "Processing date: 2024-09-17\n",
      "*** Finished processing all data for date 2024-01-14. 12 sales ***\n",
      "Processing date: 2024-10-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-08/total_sales=13__data=2024-02-08__processing-time=2024-12-05T07:00:00.994037-03:00.json\n",
      "*** Finished processing all data for date 2024-01-06. 12 sales ***\n",
      "Processing date: 2023-11-16\n",
      "*** Finished processing all data for date 2024-04-01. 18 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-12/total_sales=25__data=2024-07-12__processing-time=2024-12-05T07:00:00.531542-03:00.json\n",
      "Processing date: 2024-09-24\n",
      "*** Finished processing all data for date 2024-10-26. 10 sales ***\n",
      "Processing date: 2023-12-09\n",
      "*** Finished processing all data for date 2024-01-09. 17 sales ***\n",
      "Processing date: 2024-11-17\n",
      "*** Finished processing all data for date 2024-04-21. 16 sales ***\n",
      "Processing date: 2024-07-01\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-23/total_sales=27__data=2023-12-23__processing-time=2024-12-05T07:00:00.122981-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-01/total_sales=42__data=2024-09-01__processing-time=2024-12-05T07:00:00.094585-03:00.json\n",
      "*** Finished processing all data for date 2024-04-30. 16 sales ***\n",
      "Processing date: 2024-02-18\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-17/total_sales=38__data=2024-09-17__processing-time=2024-12-05T07:00:00.454551-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-12-07/total_sales=49__data=2024-12-07__processing-time=2024-12-08T07:00:00.685331-03:00.json\n",
      "*** Finished processing all data for date 2024-04-04. 7 sales ***\n",
      "Processing date: 2024-02-22\n",
      "Error processing date 2023-11-16: No objects to concatenate\n",
      "Processing date: 2023-10-03\n",
      "*** Finished processing all data for date 2024-08-10. 28 sales ***\n",
      "Processing date: 2024-01-26\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-13/total_sales=67__data=2024-08-13__processing-time=2024-12-05T07:00:00.145159-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-01/total_sales=98__data=2024-07-01__processing-time=2024-12-05T07:00:00.334428-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-09/total_sales=5__data=2023-12-09__processing-time=2024-12-05T07:00:00.119108-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-07/total_sales=29__data=2024-10-07__processing-time=2024-12-05T07:00:00.320437-03:00.json\n",
      "*** Finished processing all data for date 2024-08-27. 53 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-24/total_sales=30__data=2024-09-24__processing-time=2024-12-05T07:00:00.882419-03:00.json\n",
      "Processing date: 2024-12-03\n",
      "*** Finished processing all data for date 2024-08-20. 27 sales ***\n",
      "Processing date: 2024-02-10\n",
      "*** Finished processing all data for date 2024-09-11. 32 sales ***\n",
      "Processing date: 2024-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-22/total_sales=15__data=2024-02-22__processing-time=2024-12-05T07:00:00.330304-03:00.json\n",
      "Error processing date 2023-10-03: No objects to concatenate\n",
      "Processing date: 2024-01-27\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-17/total_sales=34__data=2024-11-17__processing-time=2024-12-05T07:00:00.962989-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-26/total_sales=5__data=2024-01-26__processing-time=2024-12-05T07:00:00.171682-03:00.json\n",
      "*** Finished processing all data for date 2024-06-27. 56 sales ***\n",
      "Processing date: 2024-02-02\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-18/total_sales=13__data=2024-02-18__processing-time=2024-12-05T07:00:00.798715-03:00.json\n",
      "*** Finished processing all data for date 2024-02-08. 13 sales ***\n",
      "Processing date: 2024-10-02\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-10/total_sales=11__data=2024-02-10__processing-time=2024-12-05T07:00:00.375639-03:00.json\n",
      "*** Finished processing all data for date 2023-12-09. 5 sales ***\n",
      "Processing date: 2024-08-26\n",
      "*** Finished processing all data for date 2023-12-23. 27 sales ***\n",
      "Processing date: 2024-03-04\n",
      "*** Finished processing all data for date 2024-07-12. 25 sales ***\n",
      "Processing date: 2024-11-04\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-12-03/total_sales=65__data=2024-12-03__processing-time=2024-12-05T07:01:01.453772-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-27/total_sales=8__data=2024-01-27__processing-time=2024-12-05T07:00:00.199092-03:00.json\n",
      "*** Finished processing all data for date 2024-09-17. 38 sales ***\n",
      "Processing date: 2024-07-20\n",
      "*** Finished processing all data for date 2024-12-07. 49 sales ***\n",
      "Processing date: 2024-02-14\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-02/total_sales=20__data=2024-10-02__processing-time=2024-12-05T07:00:00.929095-03:00.json\n",
      "*** Finished processing all data for date 2024-09-24. 30 sales ***\n",
      "Processing date: 2024-01-03\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-31/total_sales=15__data=2024-07-31__processing-time=2024-12-05T07:00:00.613868-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-26/total_sales=42__data=2024-08-26__processing-time=2024-12-05T07:00:00.072267-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-04/total_sales=18__data=2024-03-04__processing-time=2024-12-05T07:00:00.085032-03:00.json\n",
      "*** Finished processing all data for date 2024-09-01. 42 sales ***\n",
      "Processing date: 2024-06-17\n",
      "*** Finished processing all data for date 2024-01-26. 5 sales ***\n",
      "Processing date: 2023-10-28\n",
      "*** Finished processing all data for date 2024-02-18. 13 sales ***\n",
      "Processing date: 2024-03-17\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-20/total_sales=23__data=2024-07-20__processing-time=2024-12-05T07:00:00.739734-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-02/total_sales=12__data=2024-02-02__processing-time=2024-12-05T07:00:00.568783-03:00.json\n",
      "*** Finished processing all data for date 2024-02-22. 15 sales ***\n",
      "Processing date: 2023-10-07\n",
      "*** Finished processing all data for date 2024-10-07. 29 sales ***\n",
      "Processing date: 2024-10-13\n",
      "*** Finished processing all data for date 2024-11-17. 34 sales ***\n",
      "Processing date: 2023-11-10\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-03/total_sales=19__data=2024-01-03__processing-time=2024-12-05T07:00:00.956326-03:00.json\n",
      "*** Finished processing all data for date 2024-08-13. 67 sales ***\n",
      "Processing date: 2024-07-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-14/total_sales=18__data=2024-02-14__processing-time=2024-12-05T07:00:00.877023-03:00.json\n",
      "*** Finished processing all data for date 2024-07-01. 98 sales ***\n",
      "Processing date: 2024-01-28\n",
      "Error processing date 2023-10-28: No objects to concatenate\n",
      "Processing date: 2024-03-09\n",
      "*** Finished processing all data for date 2024-01-27. 8 sales ***\n",
      "Processing date: 2024-02-23\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-04/total_sales=17__data=2024-11-04__processing-time=2024-12-05T07:00:00.614034-03:00.json\n",
      "*** Finished processing all data for date 2024-02-10. 11 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-13/total_sales=17__data=2024-10-13__processing-time=2024-12-05T07:00:00.703450-03:00.json\n",
      "Processing date: 2024-02-20\n",
      "Error processing date 2023-10-07: No objects to concatenate\n",
      "Processing date: 2024-01-22\n",
      "*** Finished processing all data for date 2024-07-31. 15 sales ***\n",
      "Processing date: 2024-06-12\n",
      "Error processing date 2023-11-10: No objects to concatenate\n",
      "Processing date: 2024-04-18\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-17/total_sales=14__data=2024-03-17__processing-time=2024-12-05T07:00:00.309334-03:00.json\n",
      "*** Finished processing all data for date 2024-03-04. 18 sales ***\n",
      "Processing date: 2024-05-18\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-17/total_sales=67__data=2024-06-17__processing-time=2024-12-05T07:00:00.235130-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-23/total_sales=11__data=2024-02-23__processing-time=2024-12-05T07:00:00.296717-03:00.json\n",
      "*** Finished processing all data for date 2024-08-26. 42 sales ***\n",
      "Processing date: 2024-04-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-09/total_sales=14__data=2024-03-09__processing-time=2024-12-05T07:00:00.519643-03:00.json\n",
      "*** Finished processing all data for date 2024-07-20. 23 sales ***\n",
      "Processing date: 2024-04-06\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-20/total_sales=13__data=2024-02-20__processing-time=2024-12-05T07:00:00.308753-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-08/total_sales=77__data=2024-07-08__processing-time=2024-12-05T07:00:00.624181-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-12/total_sales=67__data=2024-06-12__processing-time=2024-12-05T07:00:00.595633-03:00.json\n",
      "*** Finished processing all data for date 2024-10-02. 20 sales ***\n",
      "Processing date: 2023-10-13\n",
      "*** Finished processing all data for date 2024-12-03. 65 sales ***\n",
      "Processing date: 2024-12-01\n",
      "*** Finished processing all data for date 2024-02-14. 18 sales ***\n",
      "Processing date: 2024-08-02\n",
      "*** Finished processing all data for date 2024-02-02. 12 sales ***\n",
      "Processing date: 2024-08-11\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-28/total_sales=6__data=2024-01-28__processing-time=2024-12-05T07:00:00.176088-03:00.json\n",
      "*** Finished processing all data for date 2024-11-04. 17 sales ***\n",
      "Processing date: 2024-10-11\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-07/total_sales=17__data=2024-04-07__processing-time=2024-12-05T07:00:00.193776-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-06/total_sales=8__data=2024-04-06__processing-time=2024-12-05T07:00:00.147639-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-22/total_sales=13__data=2024-01-22__processing-time=2024-12-05T07:00:00.811649-03:00.json\n",
      "*** Finished processing all data for date 2024-01-03. 19 sales ***\n",
      "Processing date: 2023-10-23\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-18/total_sales=16__data=2024-04-18__processing-time=2024-12-05T07:00:00.108588-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-18/total_sales=10__data=2024-05-18__processing-time=2024-12-05T07:00:00.823930-03:00.json\n",
      "Error processing date 2023-10-13: No objects to concatenate\n",
      "Processing date: 2024-04-08\n",
      "*** Finished processing all data for date 2024-02-23. 11 sales ***\n",
      "Processing date: 2024-04-16\n",
      "*** Finished processing all data for date 2024-03-17. 14 sales ***\n",
      "Processing date: 2024-07-02\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-12-01/total_sales=52__data=2024-12-01__processing-time=2024-12-05T07:01:01.500601-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-02/total_sales=17__data=2024-08-02__processing-time=2024-12-05T07:00:00.055970-03:00.json\n",
      "*** Finished processing all data for date 2024-03-09. 14 sales ***\n",
      "Processing date: 2024-11-27\n",
      "*** Finished processing all data for date 2024-02-20. 13 sales ***\n",
      "Processing date: 2024-09-09\n",
      "*** Finished processing all data for date 2024-10-13. 17 sales ***\n",
      "Processing date: 2024-12-04\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-11/total_sales=21__data=2024-10-11__processing-time=2024-12-05T07:00:00.678161-03:00.json\n",
      "Error processing date 2023-10-23: No objects to concatenate\n",
      "Processing date: 2024-06-13\n",
      "*** Finished processing all data for date 2024-06-17. 67 sales ***\n",
      "Processing date: 2024-01-24\n",
      "*** Finished processing all data for date 2024-01-28. 6 sales ***\n",
      "Processing date: 2024-03-20\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-02/total_sales=89__data=2024-07-02__processing-time=2024-12-05T07:00:00.311545-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-11/total_sales=27__data=2024-08-11__processing-time=2024-12-05T07:00:00.501172-03:00.json\n",
      "*** Finished processing all data for date 2024-04-07. 17 sales ***\n",
      "Processing date: 2024-06-22\n",
      "*** Finished processing all data for date 2024-05-18. 10 sales ***\n",
      "Processing date: 2024-06-10\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-27/total_sales=47__data=2024-11-27__processing-time=2024-12-05T07:01:01.806359-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-08/total_sales=18__data=2024-04-08__processing-time=2024-12-05T07:00:00.158207-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-09/total_sales=30__data=2024-09-09__processing-time=2024-12-05T07:00:00.534467-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-16/total_sales=11__data=2024-04-16__processing-time=2024-12-05T07:00:00.938732-03:00.json\n",
      "*** Finished processing all data for date 2024-04-06. 8 sales ***\n",
      "Processing date: 2024-03-25\n",
      "*** Finished processing all data for date 2024-04-18. 16 sales ***\n",
      "Processing date: 2024-11-08\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-12-04/total_sales=56__data=2024-12-04__processing-time=2024-12-05T07:01:01.482585-03:00.json\n",
      "*** Finished processing all data for date 2024-01-22. 13 sales ***\n",
      "Processing date: 2023-11-28\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-13/total_sales=55__data=2024-06-13__processing-time=2024-12-05T07:00:00.701593-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-20/total_sales=26__data=2024-03-20__processing-time=2024-12-05T07:00:00.815677-03:00.json\n",
      "*** Finished processing all data for date 2024-06-12. 67 sales ***\n",
      "Processing date: 2023-12-22\n",
      "*** Finished processing all data for date 2024-07-08. 77 sales ***\n",
      "Processing date: 2024-06-30\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-10/total_sales=71__data=2024-06-10__processing-time=2024-12-05T07:00:00.576415-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-24/total_sales=13__data=2024-01-24__processing-time=2024-12-05T07:00:00.822764-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-22/total_sales=25__data=2024-06-22__processing-time=2024-12-05T07:00:00.827118-03:00.json\n",
      "*** Finished processing all data for date 2024-12-01. 52 sales ***\n",
      "Processing date: 2023-12-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-08/total_sales=19__data=2024-11-08__processing-time=2024-12-05T07:00:00.007550-03:00.json\n",
      "*** Finished processing all data for date 2024-08-02. 17 sales ***\n",
      "Processing date: 2024-06-14\n",
      "*** Finished processing all data for date 2024-04-16. 11 sales ***\n",
      "Processing date: 2024-03-24\n",
      "Error processing date 2023-11-28: No objects to concatenate\n",
      "Processing date: 2024-11-15\n",
      "*** Finished processing all data for date 2024-08-11. 27 sales ***\n",
      "Processing date: 2024-07-17\n",
      "*** Finished processing all data for date 2024-10-11. 21 sales ***\n",
      "Processing date: 2023-11-01\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-25/total_sales=15__data=2024-03-25__processing-time=2024-12-05T07:00:00.180318-03:00.json\n",
      "*** Finished processing all data for date 2024-09-09. 30 sales ***\n",
      "Processing date: 2024-02-17\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-22/total_sales=38__data=2023-12-22__processing-time=2024-12-05T07:00:00.216062-03:00.json\n",
      "*** Finished processing all data for date 2024-07-02. 89 sales ***\n",
      "Processing date: 2023-12-25\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-20/total_sales=50__data=2023-12-20__processing-time=2024-12-05T07:00:00.486173-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-14/total_sales=44__data=2024-06-14__processing-time=2024-12-05T07:00:00.979397-03:00.json\n",
      "*** Finished processing all data for date 2024-04-08. 18 sales ***\n",
      "Processing date: 2024-11-09\n",
      "*** Finished processing all data for date 2024-11-27. 47 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-30/total_sales=51__data=2024-06-30__processing-time=2024-12-05T07:00:00.087638-03:00.json\n",
      "Processing date: 2023-11-13\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-17/total_sales=40__data=2024-07-17__processing-time=2024-12-05T07:00:00.141968-03:00.json\n",
      "*** Finished processing all data for date 2024-01-24. 13 sales ***\n",
      "Processing date: 2024-11-28\n",
      "*** Finished processing all data for date 2024-03-20. 26 sales ***\n",
      "Processing date: 2023-10-04\n",
      "Error processing date 2023-11-01: No objects to concatenate\n",
      "Processing date: 2024-08-12\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-25/total_sales=21__data=2023-12-25__processing-time=2024-12-05T07:00:00.208660-03:00.json\n",
      "*** Finished processing all data for date 2024-06-22. 25 sales ***\n",
      "Processing date: 2024-01-10\n",
      "*** Finished processing all data for date 2024-12-04. 56 sales ***\n",
      "Processing date: 2024-06-03\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-17/total_sales=11__data=2024-02-17__processing-time=2024-12-05T07:00:00.765426-03:00.json\n",
      "*** Finished processing all data for date 2024-06-10. 71 sales ***\n",
      "Processing date: 2024-07-29\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-09/total_sales=13__data=2024-11-09__processing-time=2024-12-05T07:00:00.015145-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-24/total_sales=14__data=2024-03-24__processing-time=2024-12-05T07:00:00.784857-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-15/total_sales=22__data=2024-11-15__processing-time=2024-12-05T07:00:00.932653-03:00.json\n",
      "Error processing date 2023-10-04: No objects to concatenate\n",
      "Processing date: 2024-05-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-12/total_sales=45__data=2024-08-12__processing-time=2024-12-05T07:00:00.863235-03:00.json\n",
      "*** Finished processing all data for date 2024-03-25. 15 sales ***\n",
      "Processing date: 2024-02-06\n",
      "*** Finished processing all data for date 2024-11-08. 19 sales ***\n",
      "Processing date: 2023-11-05\n",
      "*** Finished processing all data for date 2024-06-13. 55 sales ***\n",
      "Processing date: 2023-10-20\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-03/total_sales=61__data=2024-06-03__processing-time=2024-12-05T07:00:00.916915-03:00.json\n",
      "Error processing date 2023-11-13: No objects to concatenate\n",
      "Processing date: 2024-05-28\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-29/total_sales=28__data=2024-07-29__processing-time=2024-12-05T07:00:00.592478-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-28/total_sales=40__data=2024-11-28__processing-time=2024-12-05T07:01:01.850832-03:00.json\n",
      "*** Finished processing all data for date 2024-02-17. 11 sales ***\n",
      "Processing date: 2024-09-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Finished processing all data for date 2024-06-30. 51 sales ***\n",
      "Processing date: 2024-10-20\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-07/total_sales=18__data=2024-05-07__processing-time=2024-12-05T07:00:00.833027-03:00.json\n",
      "*** Finished processing all data for date 2024-07-17. 40 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-10/total_sales=11__data=2024-01-10__processing-time=2024-12-05T07:00:00.806553-03:00.json\n",
      "Processing date: 2024-04-17\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-06/total_sales=20__data=2024-02-06__processing-time=2024-12-05T07:00:00.997430-03:00.json\n",
      "*** Finished processing all data for date 2023-12-22. 38 sales ***\n",
      "Processing date: 2023-12-01\n",
      "Error processing date 2023-10-20: No objects to concatenate\n",
      "Processing date: 2023-12-03\n",
      "*** Finished processing all data for date 2023-12-20. 50 sales ***\n",
      "Processing date: 2024-07-06\n",
      "*** Finished processing all data for date 2024-03-24. 14 sales ***\n",
      "Processing date: 2024-09-07\n",
      "*** Finished processing all data for date 2024-06-14. 44 sales ***\n",
      "Processing date: 2024-04-28\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-16/total_sales=33__data=2024-09-16__processing-time=2024-12-05T07:00:00.442898-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-20/total_sales=17__data=2024-10-20__processing-time=2024-12-05T07:00:00.295979-03:00.json\n",
      "*** Finished processing all data for date 2023-12-25. 21 sales ***\n",
      "Processing date: 2023-12-02\n",
      "*** Finished processing all data for date 2024-11-09. 13 sales ***\n",
      "Processing date: 2024-02-28\n",
      "Error processing date 2023-11-05: No objects to concatenate\n",
      "Processing date: 2023-11-14\n",
      "Error processing date 2023-12-01: No objects to concatenate\n",
      "Processing date: 2024-08-01\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-28/total_sales=35__data=2024-05-28__processing-time=2024-12-05T07:00:00.692194-03:00.json\n",
      "Error processing date 2023-12-03: No objects to concatenate\n",
      "Processing date: 2024-11-24\n",
      "*** Finished processing all data for date 2024-11-15. 22 sales ***\n",
      "Processing date: 2024-11-22\n",
      "*** Finished processing all data for date 2024-07-29. 28 sales ***\n",
      "Processing date: 2024-01-21\n",
      "*** Finished processing all data for date 2024-08-12. 45 sales ***\n",
      "Processing date: 2024-09-25\n",
      "*** Finished processing all data for date 2024-06-03. 61 sales ***\n",
      "Processing date: 2024-08-06\n",
      "*** Finished processing all data for date 2024-05-07. 18 sales ***\n",
      "Processing date: 2024-10-25\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-17/total_sales=20__data=2024-04-17__processing-time=2024-12-05T07:00:00.942527-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-06/total_sales=37__data=2024-07-06__processing-time=2024-12-05T07:00:00.873420-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-28/total_sales=10__data=2024-04-28__processing-time=2024-12-05T07:00:00.047648-03:00.json\n",
      "*** Finished processing all data for date 2024-01-10. 11 sales ***\n",
      "Processing date: 2024-02-12\n",
      "*** Finished processing all data for date 2024-11-28. 40 sales ***\n",
      "Processing date: 2024-07-13\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-07/total_sales=16__data=2024-09-07__processing-time=2024-12-05T07:00:00.528738-03:00.json\n",
      "*** Finished processing all data for date 2024-10-20. 17 sales ***\n",
      "Processing date: 2024-05-31\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-25/total_sales=24__data=2024-09-25__processing-time=2024-12-05T07:00:00.906486-03:00.json\n",
      "Error processing date 2023-12-02: No objects to concatenate\n",
      "Processing date: 2024-03-27\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-28/total_sales=7__data=2024-02-28__processing-time=2024-12-05T07:00:00.691006-03:00.json\n",
      "Error processing date 2023-11-14: No objects to concatenate\n",
      "Processing date: 2024-07-21\n",
      "*** Finished processing all data for date 2024-02-06. 20 sales ***\n",
      "Processing date: 2024-10-03\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-01/total_sales=23__data=2024-08-01__processing-time=2024-12-05T07:00:00.636133-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-12/total_sales=6__data=2024-02-12__processing-time=2024-12-05T07:00:00.379627-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-13/total_sales=28__data=2024-07-13__processing-time=2024-12-05T07:00:00.888552-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-24/total_sales=27__data=2024-11-24__processing-time=2024-12-05T07:01:01.357615-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-22/total_sales=31__data=2024-11-22__processing-time=2024-12-05T07:01:01.390009-03:00.json\n",
      "*** Finished processing all data for date 2024-09-16. 33 sales ***\n",
      "Processing date: 2023-10-31\n",
      "*** Finished processing all data for date 2024-04-28. 10 sales ***\n",
      "Processing date: 2023-12-28\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-21/total_sales=8__data=2024-01-21__processing-time=2024-12-05T07:00:00.792204-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-25/total_sales=11__data=2024-10-25__processing-time=2024-12-05T07:00:00.780675-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-06/total_sales=26__data=2024-08-06__processing-time=2024-12-05T07:00:00.080881-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-27/total_sales=13__data=2024-03-27__processing-time=2024-12-05T07:00:00.190295-03:00.json\n",
      "*** Finished processing all data for date 2024-04-17. 20 sales ***\n",
      "Processing date: 2024-11-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-03/total_sales=30__data=2024-10-03__processing-time=2024-12-05T07:00:00.918023-03:00.json\n",
      "*** Finished processing all data for date 2024-07-06. 37 sales ***\n",
      "Processing date: 2023-12-30\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-21/total_sales=27__data=2024-07-21__processing-time=2024-12-05T07:00:00.665219-03:00.json\n",
      "*** Finished processing all data for date 2024-02-28. 7 sales ***\n",
      "Processing date: 2024-05-11\n",
      "*** Finished processing all data for date 2024-02-12. 6 sales ***\n",
      "Processing date: 2024-01-16\n",
      "Error processing date 2023-10-31: No objects to concatenate\n",
      "Processing date: 2024-07-09\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-31/total_sales=34__data=2024-05-31__processing-time=2024-12-05T07:00:00.045616-03:00.json\n",
      "*** Finished processing all data for date 2024-05-28. 35 sales ***\n",
      "Processing date: 2024-08-05\n",
      "*** Finished processing all data for date 2024-09-25. 24 sales ***\n",
      "Processing date: 2024-08-28\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-07/total_sales=27__data=2024-11-07__processing-time=2024-12-05T07:00:00.996448-03:00.json\n",
      "*** Finished processing all data for date 2024-08-01. 23 sales ***\n",
      "Processing date: 2023-09-29\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-28/total_sales=13__data=2023-12-28__processing-time=2024-12-05T07:00:00.554539-03:00.json\n",
      "*** Finished processing all data for date 2024-09-07. 16 sales ***\n",
      "Processing date: 2024-08-15\n",
      "*** Finished processing all data for date 2024-11-24. 27 sales ***\n",
      "Processing date: 2024-04-03\n",
      "*** Finished processing all data for date 2024-03-27. 13 sales ***\n",
      "Processing date: 2023-11-06\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-16/total_sales=16__data=2024-01-16__processing-time=2024-12-05T07:00:00.203832-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-09/total_sales=80__data=2024-07-09__processing-time=2024-12-05T07:00:00.468439-03:00.json\n",
      "*** Finished processing all data for date 2024-01-21. 8 sales ***\n",
      "Processing date: 2024-07-19\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-11/total_sales=10__data=2024-05-11__processing-time=2024-12-05T07:00:00.226513-03:00.json\n",
      "*** Finished processing all data for date 2024-10-25. 11 sales ***\n",
      "Processing date: 2024-05-25\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-30/total_sales=2__data=2023-12-30__processing-time=2024-12-05T07:00:00.597983-03:00.json\n",
      "*** Finished processing all data for date 2024-07-13. 28 sales ***\n",
      "Processing date: 2024-01-17\n",
      "*** Finished processing all data for date 2024-10-03. 30 sales ***\n",
      "Processing date: 2024-07-27\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-15/total_sales=31__data=2024-08-15__processing-time=2024-12-05T07:00:00.909202-03:00.json\n",
      "*** Finished processing all data for date 2024-11-22. 31 sales ***\n",
      "Processing date: 2023-10-06\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-03/total_sales=16__data=2024-04-03__processing-time=2024-12-05T07:00:00.726894-03:00.json\n",
      "*** Finished processing all data for date 2024-07-21. 27 sales ***\n",
      "Processing date: 2023-10-10\n",
      "Error processing date 2023-11-06: No objects to concatenate\n",
      "Processing date: 2024-09-10\n",
      "Error processing date 2023-09-29: No objects to concatenate\n",
      "Processing date: 2024-08-14\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-05/total_sales=23__data=2024-08-05__processing-time=2024-12-05T07:00:00.091374-03:00.json\n",
      "*** Finished processing all data for date 2024-08-06. 26 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-28/total_sales=52__data=2024-08-28__processing-time=2024-12-05T07:00:00.583421-03:00.json\n",
      "Processing date: 2024-03-02\n",
      "*** Finished processing all data for date 2023-12-28. 13 sales ***\n",
      "Processing date: 2024-05-19\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-25/total_sales=15__data=2024-05-25__processing-time=2024-12-05T07:00:00.606427-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-17/total_sales=14__data=2024-01-17__processing-time=2024-12-05T07:00:00.221599-03:00.json\n",
      "*** Finished processing all data for date 2024-11-07. 27 sales ***\n",
      "Processing date: 2024-11-03\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-27/total_sales=8__data=2024-07-27__processing-time=2024-12-05T07:00:00.252893-03:00.json\n",
      "Error processing date 2023-10-06: No objects to concatenate\n",
      "Processing date: 2024-05-05\n",
      "*** Finished processing all data for date 2024-05-31. 34 sales ***\n",
      "Processing date: 2024-05-22\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-10/total_sales=32__data=2024-09-10__processing-time=2024-12-05T07:00:00.517401-03:00.json\n",
      "*** Finished processing all data for date 2023-12-30. 2 sales ***\n",
      "Processing date: 2024-05-02\n",
      "*** Finished processing all data for date 2024-05-11. 10 sales ***\n",
      "Processing date: 2024-11-10\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-19/total_sales=27__data=2024-07-19__processing-time=2024-12-05T07:00:00.885279-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-19/total_sales=13__data=2024-05-19__processing-time=2024-12-05T07:00:00.246475-03:00.json\n",
      "Error processing date 2023-10-10: No objects to concatenate\n",
      "Processing date: 2023-12-18\n",
      "*** Finished processing all data for date 2024-07-09. 80 sales ***\n",
      "*** Finished processing all data for date 2024-08-15. 31 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-14/total_sales=49__data=2024-08-14__processing-time=2024-12-05T07:00:00.055957-03:00.json\n",
      "Processing date: 2024-10-19\n",
      "Processing date: 2024-06-02\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-02/total_sales=18__data=2024-03-02__processing-time=2024-12-05T07:00:00.046957-03:00.json\n",
      "*** Finished processing all data for date 2024-01-16. 16 sales ***\n",
      "Processing date: 2024-01-15\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-22/total_sales=21__data=2024-05-22__processing-time=2024-12-05T07:00:00.274884-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-05/total_sales=20__data=2024-05-05__processing-time=2024-12-05T07:00:00.863025-03:00.json\n",
      "*** Finished processing all data for date 2024-05-25. 15 sales ***\n",
      "Processing date: 2024-01-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-10/total_sales=26__data=2024-11-10__processing-time=2024-12-05T07:00:00.356949-03:00.json\n",
      "*** Finished processing all data for date 2024-01-17. 14 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-02/total_sales=16__data=2024-05-02__processing-time=2024-12-05T07:00:00.279419-03:00.json\n",
      "Processing date: 2024-11-29\n",
      "*** Finished processing all data for date 2024-08-28. 52 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-03/total_sales=20__data=2024-11-03__processing-time=2024-12-05T07:00:00.607188-03:00.json\n",
      "Processing date: 2024-04-26\n",
      "*** Finished processing all data for date 2024-07-27. 8 sales ***\n",
      "Processing date: 2024-07-22\n",
      "*** Finished processing all data for date 2024-04-03. 16 sales ***\n",
      "Processing date: 2024-08-30\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-18/total_sales=50__data=2023-12-18__processing-time=2024-12-05T07:00:00.470698-03:00.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Finished processing all data for date 2024-08-05. 23 sales ***\n",
      "Processing date: 2023-10-24\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-15/total_sales=24__data=2024-01-15__processing-time=2024-12-05T07:00:00.168854-03:00.json\n",
      "*** Finished processing all data for date 2024-09-10. 32 sales ***\n",
      "Processing date: 2024-01-25\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-02/total_sales=51__data=2024-06-02__processing-time=2024-12-05T07:00:00.246759-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-19/total_sales=16__data=2024-10-19__processing-time=2024-12-05T07:00:00.310075-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-29/total_sales=39__data=2024-11-29__processing-time=2024-12-05T07:01:01.795639-03:00.json\n",
      "*** Finished processing all data for date 2024-03-02. 18 sales ***\n",
      "Processing date: 2024-03-18\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-07/total_sales=15__data=2024-01-07__processing-time=2024-12-05T07:00:00.436588-03:00.json\n",
      "*** Finished processing all data for date 2024-05-05. 20 sales ***\n",
      "Processing date: 2023-12-27\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-26/total_sales=10__data=2024-04-26__processing-time=2024-12-05T07:00:00.899521-03:00.json\n",
      "*** Finished processing all data for date 2024-05-19. 13 sales ***\n",
      "Processing date: 2023-11-26\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-30/total_sales=26__data=2024-08-30__processing-time=2024-12-05T07:00:00.422316-03:00.json\n",
      "Error processing date 2023-10-24: No objects to concatenate\n",
      "Processing date: 2024-02-03\n",
      "*** Finished processing all data for date 2024-08-14. 49 sales ***\n",
      "Processing date: 2024-01-02\n",
      "*** Finished processing all data for date 2024-05-22. 21 sales ***\n",
      "Processing date: 2024-11-26\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-25/total_sales=8__data=2024-01-25__processing-time=2024-12-05T07:00:00.161870-03:00.json\n",
      "*** Finished processing all data for date 2024-11-10. 26 sales ***\n",
      "Processing date: 2024-03-10\n",
      "*** Finished processing all data for date 2024-07-19. 27 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-18/total_sales=20__data=2024-03-18__processing-time=2024-12-05T07:00:00.359758-03:00.json\n",
      "Processing date: 2023-11-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-27/total_sales=44__data=2023-12-27__processing-time=2024-12-05T07:00:00.511268-03:00.json\n",
      "*** Finished processing all data for date 2024-05-02. 16 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-22/total_sales=32__data=2024-07-22__processing-time=2024-12-05T07:00:00.673035-03:00.json\n",
      "Processing date: 2024-02-19\n",
      "*** Finished processing all data for date 2024-11-03. 20 sales ***\n",
      "Processing date: 2023-11-18\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-03/total_sales=7__data=2024-02-03__processing-time=2024-12-05T07:00:00.563527-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-02/total_sales=15__data=2024-01-02__processing-time=2024-12-05T07:00:00.911933-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-26/total_sales=29__data=2024-11-26__processing-time=2024-12-05T07:01:01.765023-03:00.json\n",
      "*** Finished processing all data for date 2023-12-18. 50 sales ***\n",
      "Processing date: 2024-10-27\n",
      "*** Finished processing all data for date 2024-04-26. 10 sales ***\n",
      "Processing date: 2024-08-18\n",
      "Error processing date 2023-11-07: No objects to concatenate\n",
      "Processing date: 2024-09-06\n",
      "*** Finished processing all data for date 2024-11-29. 39 sales ***\n",
      "Processing date: 2023-10-16\n",
      "Error processing date 2023-11-26: No objects to concatenate\n",
      "Processing date: 2023-09-24\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-19/total_sales=17__data=2024-02-19__processing-time=2024-12-05T07:00:00.304233-03:00.json\n",
      "Error processing date 2023-11-18: No objects to concatenate\n",
      "Processing date: 2024-05-10\n",
      "*** Finished processing all data for date 2024-01-15. 24 sales ***\n",
      "Processing date: 2024-01-19\n",
      "*** Finished processing all data for date 2024-10-19. 16 sales ***\n",
      "Processing date: 2023-10-18\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-10/total_sales=21__data=2024-03-10__processing-time=2024-12-05T07:00:00.901872-03:00.json\n",
      "*** Finished processing all data for date 2024-01-07. 15 sales ***\n",
      "Processing date: 2023-11-30\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-27/total_sales=15__data=2024-10-27__processing-time=2024-12-05T07:00:00.089678-03:00.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Finished processing all data for date 2024-06-02. 51 sales ***\n",
      "Processing date: 2024-05-14\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-06/total_sales=20__data=2024-09-06__processing-time=2024-12-05T07:00:00.483803-03:00.json\n",
      "*** Finished processing all data for date 2024-01-25. 8 sales ***\n",
      "Processing date: 2024-07-03\n",
      "*** Finished processing all data for date 2024-08-30. 26 sales ***\n",
      "Processing date: 2024-04-25\n",
      "Error processing date 2023-09-24: No objects to concatenate\n",
      "Processing date: 2024-05-03\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-10/total_sales=11__data=2024-05-10__processing-time=2024-12-05T07:00:00.204282-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-19/total_sales=12__data=2024-01-19__processing-time=2024-12-05T07:00:00.385581-03:00.json\n",
      "*** Finished processing all data for date 2024-03-18. 20 sales ***\n",
      "Processing date: 2024-07-05\n",
      "*** Finished processing all data for date 2023-12-27. 44 sales ***\n",
      "Processing date: 2024-04-14\n",
      "*** Finished processing all data for date 2024-11-26. 29 sales ***\n",
      "Processing date: 2024-02-26\n",
      "*** Finished processing all data for date 2024-02-03. 7 sales ***\n",
      "Processing date: 2023-12-19\n",
      "Error processing date 2023-10-16: No objects to concatenate\n",
      "Processing date: 2024-08-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-18/total_sales=24__data=2024-08-18__processing-time=2024-12-05T07:00:00.632364-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-03/total_sales=69__data=2024-07-03__processing-time=2024-12-05T07:00:00.058952-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-14/total_sales=9__data=2024-05-14__processing-time=2024-12-05T07:00:00.626586-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-03/total_sales=12__data=2024-05-03__processing-time=2024-12-05T07:00:00.404751-03:00.json\n",
      "*** Finished processing all data for date 2024-07-22. 32 sales ***\n",
      "Processing date: 2023-10-15\n",
      "Error processing date 2023-10-18: No objects to concatenate\n",
      "Processing date: 2024-01-23\n",
      "*** Finished processing all data for date 2024-01-02. 15 sales ***\n",
      "Processing date: 2024-11-20\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-25/total_sales=12__data=2024-04-25__processing-time=2024-12-05T07:00:00.895437-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-14/total_sales=14__data=2024-04-14__processing-time=2024-12-05T07:00:00.932185-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-26/total_sales=19__data=2024-02-26__processing-time=2024-12-05T07:00:00.704910-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-19/total_sales=53__data=2023-12-19__processing-time=2024-12-05T07:00:00.637600-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-05/total_sales=42__data=2024-07-05__processing-time=2024-12-05T07:00:00.857097-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-07/total_sales=25__data=2024-08-07__processing-time=2024-12-05T07:00:00.432171-03:00.json\n",
      "*** Finished processing all data for date 2024-02-19. 17 sales ***\n",
      "Processing date: 2024-06-08\n",
      "*** Finished processing all data for date 2024-09-06. 20 sales ***\n",
      "Processing date: 2024-05-30\n",
      "*** Finished processing all data for date 2024-10-27. 15 sales ***\n",
      "Processing date: 2024-12-06\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-23/total_sales=10__data=2024-01-23__processing-time=2024-12-05T07:00:00.801104-03:00.json\n",
      "Error processing date 2023-11-30: No objects to concatenate\n",
      "Processing date: 2023-10-11\n",
      "*** Finished processing all data for date 2024-03-10. 21 sales ***\n",
      "Processing date: 2024-08-16\n",
      "*** Finished processing all data for date 2024-01-19. 12 sales ***\n",
      "Processing date: 2023-10-26\n",
      "Error processing date 2023-10-15: No objects to concatenate\n",
      "Processing date: 2024-08-19\n",
      "*** Finished processing all data for date 2024-05-10. 11 sales ***\n",
      "Processing date: 2023-09-26\n",
      "*** Finished processing all data for date 2024-04-25. 12 sales ***\n",
      "Processing date: 2024-10-22\n",
      "*** Finished processing all data for date 2024-05-03. 12 sales ***\n",
      "Processing date: 2024-04-09\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-08/total_sales=37__data=2024-06-08__processing-time=2024-12-05T07:00:00.143729-03:00.json\n",
      "*** Finished processing all data for date 2024-05-14. 9 sales ***\n",
      "Processing date: 2023-12-06\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-12-06/total_sales=22__data=2024-12-06__processing-time=2024-12-07T07:00:00.741069-03:00.json\n",
      "*** Finished processing all data for date 2024-02-26. 19 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-20/total_sales=39__data=2024-11-20__processing-time=2024-12-05T07:01:01.324294-03:00.json\n",
      "Processing date: 2024-08-21\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-30/total_sales=43__data=2024-05-30__processing-time=2024-12-05T07:00:00.159145-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-16/total_sales=21__data=2024-08-16__processing-time=2024-12-05T07:00:00.925064-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-19/total_sales=34__data=2024-08-19__processing-time=2024-12-05T07:00:00.642482-03:00.json\n",
      "Error processing date 2023-10-26: No objects to concatenate\n",
      "Processing date: 2024-02-04\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-22/total_sales=23__data=2024-10-22__processing-time=2024-12-05T07:00:00.724549-03:00.json\n",
      "*** Finished processing all data for date 2023-12-19. 53 sales ***\n",
      "Processing date: 2023-12-13\n",
      "*** Finished processing all data for date 2024-08-18. 24 sales ***\n",
      "Processing date: 2024-09-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\2281585555.py:114: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_blob = pd.concat(df_list, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Finished processing all data for date 2024-04-14. 14 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-09/total_sales=23__data=2024-04-09__processing-time=2024-12-05T07:00:00.741138-03:00.json\n",
      "Processing date: 2024-11-05\n",
      "*** Finished processing all data for date 2024-07-05. 42 sales ***\n",
      "Processing date: 2024-03-22\n",
      "*** Finished processing all data for date 2024-08-07. 25 sales ***\n",
      "Processing date: 2024-01-04\n",
      "Error processing date 2023-12-06: No objects to concatenate\n",
      "Processing date: 2024-04-15\n",
      "Error processing date 2023-09-26: No objects to concatenate\n",
      "Processing date: 2024-03-11\n",
      "Error processing date 2023-10-11: No objects to concatenate\n",
      "Processing date: 2024-05-09\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-13/total_sales=17__data=2023-12-13__processing-time=2024-12-05T07:00:00.049084-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-21/total_sales=31__data=2024-08-21__processing-time=2024-12-05T07:00:00.612138-03:00.json\n",
      "*** Finished processing all data for date 2024-07-03. 69 sales ***\n",
      "Processing date: 2024-10-12\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-04/total_sales=10__data=2024-02-04__processing-time=2024-12-05T07:00:00.003838-03:00.json\n",
      "*** Finished processing all data for date 2024-12-06. 22 sales ***\n",
      "Processing date: 2023-11-22\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-13/total_sales=17__data=2024-09-13__processing-time=2024-12-05T07:00:00.916524-03:00.json\n",
      "*** Finished processing all data for date 2024-05-30. 43 sales ***\n",
      "Processing date: 2023-12-10\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-05/total_sales=24__data=2024-11-05__processing-time=2024-12-05T07:00:00.950755-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-15/total_sales=16__data=2024-04-15__processing-time=2024-12-05T07:00:00.955654-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-11/total_sales=28__data=2024-03-11__processing-time=2024-12-05T07:00:00.933186-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-04/total_sales=19__data=2024-01-04__processing-time=2024-12-05T07:00:00.985788-03:00.json\n",
      "*** Finished processing all data for date 2024-11-20. 39 sales ***\n",
      "Processing date: 2023-11-25\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-22/total_sales=11__data=2024-03-22__processing-time=2024-12-05T07:00:00.773847-03:00.json\n",
      "*** Finished processing all data for date 2024-08-19. 34 sales ***\n",
      "Processing date: 2024-08-29\n",
      "*** Finished processing all data for date 2024-10-22. 23 sales ***\n",
      "Processing date: 2024-10-16\n",
      "*** Finished processing all data for date 2024-01-23. 10 sales ***\n",
      "Processing date: 2024-10-14\n",
      "*** Finished processing all data for date 2024-06-08. 37 sales ***\n",
      "Processing date: 2024-01-20\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-10/total_sales=6__data=2023-12-10__processing-time=2024-12-05T07:00:00.104958-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-09/total_sales=23__data=2024-05-09__processing-time=2024-12-05T07:00:00.186554-03:00.json\n",
      "Error processing date 2023-11-22: No objects to concatenate\n",
      "Processing date: 2024-11-02\n",
      "*** Finished processing all data for date 2024-02-04. 10 sales ***\n",
      "Processing date: 2024-10-09\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-12/total_sales=13__data=2024-10-12__processing-time=2024-12-05T07:00:00.693229-03:00.json\n",
      "*** Finished processing all data for date 2023-12-13. 17 sales ***\n",
      "Processing date: 2024-09-21\n",
      "*** Finished processing all data for date 2024-08-16. 21 sales ***\n",
      "Processing date: 2024-11-14\n",
      "*** Finished processing all data for date 2024-04-09. 23 sales ***\n",
      "Processing date: 2024-09-12\n",
      "*** Finished processing all data for date 2024-08-21. 31 sales ***\n",
      "Processing date: 2024-11-18\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-16/total_sales=16__data=2024-10-16__processing-time=2024-12-05T07:00:00.404610-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-29/total_sales=44__data=2024-08-29__processing-time=2024-12-05T07:00:00.439758-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-14/total_sales=25__data=2024-10-14__processing-time=2024-12-05T07:00:00.859692-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-20/total_sales=12__data=2024-01-20__processing-time=2024-12-05T07:00:00.816615-03:00.json\n",
      "*** Finished processing all data for date 2024-09-13. 17 sales ***\n",
      "Processing date: 2024-01-11\n",
      "*** Finished processing all data for date 2024-03-22. 11 sales ***\n",
      "Processing date: 2024-10-08\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-02/total_sales=21__data=2024-11-02__processing-time=2024-12-05T07:00:00.594366-03:00.json\n",
      "*** Finished processing all data for date 2024-03-11. 28 sales ***\n",
      "Processing date: 2023-10-30\n",
      "Error processing date 2023-11-25: No objects to concatenate\n",
      "Processing date: 2024-11-23\n",
      "*** Finished processing all data for date 2024-04-15. 16 sales ***\n",
      "Processing date: 2024-01-12\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-21/total_sales=28__data=2024-09-21__processing-time=2024-12-05T07:00:00.822926-03:00.json\n",
      "*** Finished processing all data for date 2024-11-05. 24 sales ***\n",
      "Processing date: 2024-10-30\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-14/total_sales=22__data=2024-11-14__processing-time=2024-12-05T07:00:00.522281-03:00.json\n",
      "*** Finished processing all data for date 2023-12-10. 6 sales ***\n",
      "Processing date: 2023-11-15\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-18/total_sales=26__data=2024-11-18__processing-time=2024-12-05T07:00:00.976509-03:00.json\n",
      "*** Finished processing all data for date 2024-01-04. 19 sales ***\n",
      "Processing date: 2023-10-14\n",
      "Error processing date 2023-10-30: No objects to concatenate\n",
      "Processing date: 2024-05-21\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-09/total_sales=26__data=2024-10-09__processing-time=2024-12-05T07:00:00.329933-03:00.json\n",
      "*** Finished processing all data for date 2024-01-20. 12 sales ***\n",
      "Processing date: 2024-02-27\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-11-23/total_sales=29__data=2024-11-23__processing-time=2024-12-05T07:01:01.366428-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-08/total_sales=27__data=2024-10-08__processing-time=2024-12-05T07:00:00.308395-03:00.json\n",
      "*** Finished processing all data for date 2024-05-09. 23 sales ***\n",
      "Processing date: 2024-04-12\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-12/total_sales=43__data=2024-09-12__processing-time=2024-12-05T07:00:00.925361-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-12/total_sales=17__data=2024-01-12__processing-time=2024-12-05T07:00:00.829457-03:00.json\n",
      "*** Finished processing all data for date 2024-10-14. 25 sales ***\n",
      "Processing date: 2024-02-09\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-11/total_sales=24__data=2024-01-11__processing-time=2024-12-05T07:00:00.852022-03:00.json\n",
      "Error processing date 2023-11-15: No objects to concatenate\n",
      "Processing date: 2024-03-30\n",
      "*** Finished processing all data for date 2024-10-16. 16 sales ***\n",
      "Processing date: 2023-11-17\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-21/total_sales=17__data=2024-05-21__processing-time=2024-12-05T07:00:00.254348-03:00.json\n",
      "*** Finished processing all data for date 2024-10-12. 13 sales ***\n",
      "Processing date: 2024-04-05\n",
      "Error processing date 2023-10-14: No objects to concatenate\n",
      "Processing date: 2024-04-20\n",
      "*** Finished processing all data for date 2024-08-29. 44 sales ***\n",
      "Processing date: 2024-04-02\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-12/total_sales=15__data=2024-04-12__processing-time=2024-12-05T07:00:00.558938-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-27/total_sales=18__data=2024-02-27__processing-time=2024-12-05T07:00:00.714220-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-30/total_sales=22__data=2024-10-30__processing-time=2024-12-05T07:00:00.160226-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-09/total_sales=8__data=2024-02-09__processing-time=2024-12-05T07:00:00.402371-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-30/total_sales=12__data=2024-03-30__processing-time=2024-12-05T07:00:00.559492-03:00.json\n",
      "*** Finished processing all data for date 2024-11-02. 21 sales ***\n",
      "Processing date: 2024-09-08\n",
      "Error processing date 2023-11-17: No objects to concatenate\n",
      "Processing date: 2024-09-19\n",
      "*** Finished processing all data for date 2024-11-18. 26 sales ***\n",
      "Processing date: 2024-03-06\n",
      "*** Finished processing all data for date 2024-10-09. 26 sales ***\n",
      "Processing date: 2024-08-03\n",
      "*** Finished processing all data for date 2024-11-14. 22 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-05/total_sales=16__data=2024-04-05__processing-time=2024-12-05T07:00:00.150562-03:00.json\n",
      "Processing date: 2024-03-15\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-20/total_sales=10__data=2024-04-20__processing-time=2024-12-05T07:00:00.536379-03:00.json\n",
      "*** Finished processing all data for date 2024-09-21. 28 sales ***\n",
      "Processing date: 2024-07-18\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-02/total_sales=12__data=2024-04-02__processing-time=2024-12-05T07:00:00.608103-03:00.json\n",
      "*** Finished processing all data for date 2024-11-23. 29 sales ***\n",
      "Processing date: 2024-09-18\n",
      "*** Finished processing all data for date 2024-01-12. 17 sales ***\n",
      "Processing date: 2024-08-09\n",
      "*** Finished processing all data for date 2024-01-11. 24 sales ***\n",
      "Processing date: 2023-12-29\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-19/total_sales=34__data=2024-09-19__processing-time=2024-12-05T07:00:00.477654-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-06/total_sales=20__data=2024-03-06__processing-time=2024-12-05T07:00:00.554749-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-03/total_sales=19__data=2024-08-03__processing-time=2024-12-05T07:00:00.066231-03:00.json\n",
      "*** Finished processing all data for date 2024-05-21. 17 sales ***\n",
      "Processing date: 2024-07-30\n",
      "*** Finished processing all data for date 2024-04-12. 15 sales ***\n",
      "Processing date: 2024-04-11\n",
      "*** Finished processing all data for date 2024-03-30. 12 sales ***\n",
      "Processing date: 2024-09-26\n",
      "*** Finished processing all data for date 2024-09-12. 43 sales ***\n",
      "Processing date: 2023-12-11\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-15/total_sales=16__data=2024-03-15__processing-time=2024-12-05T07:00:00.279439-03:00.json\n",
      "*** Finished processing all data for date 2024-10-08. 27 sales ***\n",
      "Processing date: 2024-04-22\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-18/total_sales=53__data=2024-07-18__processing-time=2024-12-05T07:00:00.853080-03:00.json\n",
      "*** Finished processing all data for date 2024-02-27. 18 sales ***\n",
      "Processing date: 2023-11-11\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-09/total_sales=27__data=2024-08-09__processing-time=2024-12-05T07:00:00.533424-03:00.json\n",
      "*** Finished processing all data for date 2024-10-30. 22 sales ***\n",
      "Processing date: 2024-03-01\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-08/total_sales=21__data=2024-09-08__processing-time=2024-12-05T07:00:00.503484-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-18/total_sales=31__data=2024-09-18__processing-time=2024-12-05T07:00:00.488564-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-11/total_sales=20__data=2024-04-11__processing-time=2024-12-05T07:00:00.543220-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-26/total_sales=17__data=2024-09-26__processing-time=2024-12-05T07:00:00.228627-03:00.json\n",
      "*** Finished processing all data for date 2024-04-20. 10 sales ***\n",
      "Processing date: 2024-01-29\n",
      "*** Finished processing all data for date 2024-02-09. 8 sales ***\n",
      "Processing date: 2023-12-07\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-29/total_sales=4__data=2023-12-29__processing-time=2024-12-05T07:00:00.578849-03:00.json\n",
      "Error processing date 2023-11-11: No objects to concatenate\n",
      "Processing date: 2024-08-22\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2023-12-11/total_sales=13__data=2023-12-11__processing-time=2024-12-05T07:00:00.310106-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-22/total_sales=18__data=2024-04-22__processing-time=2024-12-05T07:00:00.553179-03:00.json\n",
      "*** Finished processing all data for date 2024-04-02. 12 sales ***\n",
      "Processing date: 2023-10-05\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-01/total_sales=21__data=2024-03-01__processing-time=2024-12-05T07:00:00.031844-03:00.json\n",
      "*** Finished processing all data for date 2024-08-03. 19 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-30/total_sales=20__data=2024-07-30__processing-time=2024-12-05T07:00:00.494857-03:00.json\n",
      "Processing date: 2023-11-12\n",
      "*** Finished processing all data for date 2024-04-05. 16 sales ***\n",
      "Processing date: 2024-03-19\n",
      "*** Finished processing all data for date 2024-09-19. 34 sales ***\n",
      "Processing date: 2024-05-23\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-01-29/total_sales=17__data=2024-01-29__processing-time=2024-12-05T07:00:00.187969-03:00.json\n",
      "*** Finished processing all data for date 2024-08-09. 27 sales ***\n",
      "Processing date: 2024-06-26\n",
      "Error processing date 2023-12-07: No objects to concatenate\n",
      "Processing date: 2024-09-14\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-08-22/total_sales=36__data=2024-08-22__processing-time=2024-12-05T07:00:00.997743-03:00.json\n",
      "*** Finished processing all data for date 2023-12-29. 4 sales ***\n",
      "Processing date: 2024-04-19\n",
      "*** Finished processing all data for date 2024-03-06. 20 sales ***\n",
      "Processing date: 2024-07-10\n",
      "Error processing date 2023-10-05: No objects to concatenate\n",
      "*** Finished processing all data for date 2024-04-11. 20 sales ***\n",
      "Processing date: 2024-05-26\n",
      "Processing date: 2024-10-06\n",
      "*** Finished processing all data for date 2024-09-08. 21 sales ***\n",
      "Processing date: 2024-02-21\n",
      "*** Finished processing all data for date 2024-07-18. 53 sales ***\n",
      "Processing date: 2024-12-08\n",
      "Error processing date 2023-11-12: No objects to concatenate\n",
      "*** Finished processing all data for date 2024-03-15. 16 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-23/total_sales=17__data=2024-05-23__processing-time=2024-12-05T07:00:00.295394-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-06-26/total_sales=47__data=2024-06-26__processing-time=2024-12-05T07:00:00.510767-03:00.json\n",
      "*** Finished processing all data for date 2024-09-18. 31 sales ***\n",
      "*** Finished processing all data for date 2024-04-22. 18 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-03-19/total_sales=22__data=2024-03-19__processing-time=2024-12-05T07:00:00.337493-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-05-26/total_sales=37__data=2024-05-26__processing-time=2024-12-05T07:00:00.633733-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-04-19/total_sales=8__data=2024-04-19__processing-time=2024-12-05T07:00:00.514655-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-10-06/total_sales=26__data=2024-10-06__processing-time=2024-12-05T07:00:00.289636-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-07-10/total_sales=58__data=2024-07-10__processing-time=2024-12-05T07:00:00.697516-03:00.json\n",
      "*** Finished processing all data for date 2024-09-26. 17 sales ***\n",
      "*** Finished processing all data for date 2023-12-11. 13 sales ***\n",
      "*** Finished processing all data for date 2024-01-29. 17 sales ***\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-12-08/total_sales=56__data=2024-12-08__processing-time=2024-12-09T13:57:57.330869-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-09-14/total_sales=25__data=2024-09-14__processing-time=2024-12-05T07:00:00.948016-03:00.json\n",
      "Reading file: xela malhas/meli/api_response/orders/date=2024-02-21/total_sales=11__data=2024-02-21__processing-time=2024-12-05T07:00:00.300508-03:00.json\n",
      "*** Finished processing all data for date 2024-07-30. 20 sales ***\n",
      "*** Finished processing all data for date 2024-03-01. 21 sales ***\n",
      "*** Finished processing all data for date 2024-08-22. 36 sales ***\n",
      "*** Finished processing all data for date 2024-04-19. 8 sales ***\n",
      "*** Finished processing all data for date 2024-05-23. 17 sales ***\n",
      "*** Finished processing all data for date 2024-05-26. 37 sales ***\n",
      "*** Finished processing all data for date 2024-02-21. 11 sales ***\n",
      "*** Finished processing all data for date 2024-03-19. 22 sales ***\n",
      "*** Finished processing all data for date 2024-10-06. 26 sales ***\n",
      "*** Finished processing all data for date 2024-12-08. 56 sales ***\n",
      "*** Finished processing all data for date 2024-09-14. 25 sales ***\n",
      "*** Finished processing all data for date 2024-07-10. 58 sales ***\n",
      "*** Finished processing all data for date 2024-06-26. 47 sales ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19680\\3009689308.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all_processed_data = pd.concat(results, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Deleting existing data **\n",
      "Existing data deleted from datalake-v2-424516.datalake_v2.orders for dates ['2023-10-22', '2024-10-21', '2024-04-10', '2024-06-11', '2024-01-18', '2023-11-19', '2024-04-29', '2024-01-01', '2024-11-21', '2024-03-23', '2024-07-28', '2023-09-28', '2023-11-23', '2024-05-24', '2024-10-15', '2024-10-28', '2024-03-31', '2023-10-17', '2024-03-03', '2024-04-27', '2024-06-25', '2024-03-26', '2024-07-26', '2024-02-13', '2024-11-11', '2024-12-02', '2024-07-07', '2024-06-18', '2024-05-15', '2023-10-27', '2023-10-01', '2024-08-25', '2023-12-12', '2024-11-01', '2024-12-05', '2024-09-02', '2023-11-20', '2024-06-09', '2024-01-31', '2024-05-13', '2024-07-24', '2023-11-04', '2024-02-01', '2024-03-05', '2024-08-04', '2024-08-24', '2023-12-26', '2024-09-28', '2023-10-02', '2024-06-01', '2024-01-30', '2023-09-25', '2024-09-20', '2024-10-29', '2024-11-19', '2023-10-21', '2024-09-23', '2023-11-08', '2024-06-29', '2023-11-02', '2024-02-16', '2023-10-19', '2024-03-29', '2024-03-16', '2024-09-22', '2024-01-13', '2024-06-07', '2023-12-05', '2024-06-23', '2024-02-29', '2024-06-20', '2024-06-05', '2023-09-30', '2023-10-25', '2024-09-05', '2024-03-28', '2023-11-27', '2024-06-16', '2023-09-22', '2024-09-03', '2024-07-11', '2023-10-08', '2024-11-25', '2024-07-04', '2024-10-23', '2024-06-24', '2023-09-21', '2024-09-29', '2024-05-08', '2024-06-04', '2023-12-31', '2024-02-07', '2024-09-15', '2024-09-04', '2023-11-09', '2023-12-15', '2024-06-06', '2024-08-23', '2024-05-01', '2024-10-01', '2024-06-28', '2024-06-15', '2024-05-27', '2023-12-21', '2024-07-25', '2024-11-12', '2023-12-24', '2023-11-03', '2024-10-10', '2023-12-17', '2024-03-14', '2024-05-20', '2023-12-14', '2024-07-15', '2024-05-29', '2024-03-12', '2024-02-11', '2023-12-04', '2024-11-30', '2024-09-30', '2024-02-15', '2024-03-08', '2024-02-24', '2024-06-19', '2024-10-04', '2024-07-16', '2023-12-08', '2023-10-29', '2024-04-13', '2023-10-12', '2024-09-27', '2024-03-13', '2024-08-08', '2023-09-27', '2024-01-08', '2023-11-29', '2024-10-31', '2024-10-17', '2024-10-05', '2024-05-04', '2024-10-24', '2024-01-05', '2023-09-23', '2024-10-18', '2024-07-23', '2023-12-16', '2024-06-21', '2024-04-23', '2024-08-31', '2024-11-16', '2024-11-13', '2024-03-07', '2024-07-14', '2024-05-16', '2024-08-17', '2024-11-06', '2024-02-25', '2024-05-06', '2024-05-17', '2023-11-24', '2023-11-21', '2024-03-21', '2024-02-05', '2024-04-01', '2024-01-14', '2024-01-06', '2024-08-27', '2024-04-21', '2024-10-26', '2024-05-12', '2023-10-09', '2024-04-24', '2024-09-11', '2024-04-30', '2024-01-09', '2024-08-10', '2024-08-20', '2024-04-04', '2024-06-27', '2024-02-08', '2024-07-12', '2024-09-01', '2023-12-23', '2024-12-07', '2024-08-13', '2024-09-17', '2024-10-07', '2023-11-16', '2024-09-24', '2023-12-09', '2024-11-17', '2024-07-01', '2024-02-18', '2024-02-22', '2023-10-03', '2024-01-26', '2024-12-03', '2024-02-10', '2024-07-31', '2024-01-27', '2024-02-02', '2024-10-02', '2024-08-26', '2024-03-04', '2024-11-04', '2024-07-20', '2024-02-14', '2024-01-03', '2024-06-17', '2023-10-28', '2024-03-17', '2023-10-07', '2024-10-13', '2023-11-10', '2024-07-08', '2024-01-28', '2024-03-09', '2024-02-23', '2024-02-20', '2024-01-22', '2024-06-12', '2024-04-18', '2024-05-18', '2024-04-07', '2024-04-06', '2023-10-13', '2024-12-01', '2024-08-02', '2024-08-11', '2024-10-11', '2023-10-23', '2024-04-08', '2024-04-16', '2024-07-02', '2024-11-27', '2024-09-09', '2024-12-04', '2024-06-13', '2024-01-24', '2024-03-20', '2024-06-22', '2024-06-10', '2024-03-25', '2024-11-08', '2023-11-28', '2023-12-22', '2024-06-30', '2023-12-20', '2024-06-14', '2024-03-24', '2024-11-15', '2024-07-17', '2023-11-01', '2024-02-17', '2023-12-25', '2024-11-09', '2023-11-13', '2024-11-28', '2023-10-04', '2024-08-12', '2024-01-10', '2024-06-03', '2024-07-29', '2024-05-07', '2024-02-06', '2023-11-05', '2023-10-20', '2024-05-28', '2024-09-16', '2024-10-20', '2024-04-17', '2023-12-01', '2023-12-03', '2024-07-06', '2024-09-07', '2024-04-28', '2023-12-02', '2024-02-28', '2023-11-14', '2024-08-01', '2024-11-24', '2024-11-22', '2024-01-21', '2024-09-25', '2024-08-06', '2024-10-25', '2024-02-12', '2024-07-13', '2024-05-31', '2024-03-27', '2024-07-21', '2024-10-03', '2023-10-31', '2023-12-28', '2024-11-07', '2023-12-30', '2024-05-11', '2024-01-16', '2024-07-09', '2024-08-05', '2024-08-28', '2023-09-29', '2024-08-15', '2024-04-03', '2023-11-06', '2024-07-19', '2024-05-25', '2024-01-17', '2024-07-27', '2023-10-06', '2023-10-10', '2024-09-10', '2024-08-14', '2024-03-02', '2024-05-19', '2024-11-03', '2024-05-05', '2024-05-22', '2024-05-02', '2024-11-10', '2023-12-18', '2024-10-19', '2024-06-02', '2024-01-15', '2024-01-07', '2024-11-29', '2024-04-26', '2024-07-22', '2024-08-30', '2023-10-24', '2024-01-25', '2024-03-18', '2023-12-27', '2023-11-26', '2024-02-03', '2024-01-02', '2024-11-26', '2024-03-10', '2023-11-07', '2024-02-19', '2023-11-18', '2024-10-27', '2024-08-18', '2024-09-06', '2023-10-16', '2023-09-24', '2024-05-10', '2024-01-19', '2023-10-18', '2023-11-30', '2024-05-14', '2024-07-03', '2024-04-25', '2024-05-03', '2024-07-05', '2024-04-14', '2024-02-26', '2023-12-19', '2024-08-07', '2023-10-15', '2024-01-23', '2024-11-20', '2024-06-08', '2024-05-30', '2024-12-06', '2023-10-11', '2024-08-16', '2023-10-26', '2024-08-19', '2023-09-26', '2024-10-22', '2024-04-09', '2023-12-06', '2024-08-21', '2024-02-04', '2023-12-13', '2024-09-13', '2024-11-05', '2024-03-22', '2024-01-04', '2024-04-15', '2024-03-11', '2024-05-09', '2024-10-12', '2023-11-22', '2023-12-10', '2023-11-25', '2024-08-29', '2024-10-16', '2024-10-14', '2024-01-20', '2024-11-02', '2024-10-09', '2024-09-21', '2024-11-14', '2024-09-12', '2024-11-18', '2024-01-11', '2024-10-08', '2023-10-30', '2024-11-23', '2024-01-12', '2024-10-30', '2023-11-15', '2023-10-14', '2024-05-21', '2024-02-27', '2024-04-12', '2024-02-09', '2024-03-30', '2023-11-17', '2024-04-05', '2024-04-20', '2024-04-02', '2024-09-08', '2024-09-19', '2024-03-06', '2024-08-03', '2024-03-15', '2024-07-18', '2024-09-18', '2024-08-09', '2023-12-29', '2024-07-30', '2024-04-11', '2024-09-26', '2023-12-11', '2024-04-22', '2023-11-11', '2024-03-01', '2024-01-29', '2023-12-07', '2024-08-22', '2023-10-05', '2023-11-12', '2024-03-19', '2024-05-23', '2024-06-26', '2024-09-14', '2024-04-19', '2024-07-10', '2024-05-26', '2024-10-06', '2024-02-21', '2024-12-08'] and seller_id 189643563.\n",
      "** Correcting dataframe schema **\n",
      "Schema adjusted to match BigQuery table.\n",
      "** Inserting data into BigQuery **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into datalake-v2-424516.datalake_v2.orders.\n",
      "** Updating log table **\n",
      "Logs table datalake-v2-424516.datalake_v2.datalake_management updated for seller_id 189643563 and dates ['2023-10-22', '2024-10-21', '2024-04-10', '2024-06-11', '2024-01-18', '2023-11-19', '2024-04-29', '2024-01-01', '2024-11-21', '2024-03-23', '2024-07-28', '2023-09-28', '2023-11-23', '2024-05-24', '2024-10-15', '2024-10-28', '2024-03-31', '2023-10-17', '2024-03-03', '2024-04-27', '2024-06-25', '2024-03-26', '2024-07-26', '2024-02-13', '2024-11-11', '2024-12-02', '2024-07-07', '2024-06-18', '2024-05-15', '2023-10-27', '2023-10-01', '2024-08-25', '2023-12-12', '2024-11-01', '2024-12-05', '2024-09-02', '2023-11-20', '2024-06-09', '2024-01-31', '2024-05-13', '2024-07-24', '2023-11-04', '2024-02-01', '2024-03-05', '2024-08-04', '2024-08-24', '2023-12-26', '2024-09-28', '2023-10-02', '2024-06-01', '2024-01-30', '2023-09-25', '2024-09-20', '2024-10-29', '2024-11-19', '2023-10-21', '2024-09-23', '2023-11-08', '2024-06-29', '2023-11-02', '2024-02-16', '2023-10-19', '2024-03-29', '2024-03-16', '2024-09-22', '2024-01-13', '2024-06-07', '2023-12-05', '2024-06-23', '2024-02-29', '2024-06-20', '2024-06-05', '2023-09-30', '2023-10-25', '2024-09-05', '2024-03-28', '2023-11-27', '2024-06-16', '2023-09-22', '2024-09-03', '2024-07-11', '2023-10-08', '2024-11-25', '2024-07-04', '2024-10-23', '2024-06-24', '2023-09-21', '2024-09-29', '2024-05-08', '2024-06-04', '2023-12-31', '2024-02-07', '2024-09-15', '2024-09-04', '2023-11-09', '2023-12-15', '2024-06-06', '2024-08-23', '2024-05-01', '2024-10-01', '2024-06-28', '2024-06-15', '2024-05-27', '2023-12-21', '2024-07-25', '2024-11-12', '2023-12-24', '2023-11-03', '2024-10-10', '2023-12-17', '2024-03-14', '2024-05-20', '2023-12-14', '2024-07-15', '2024-05-29', '2024-03-12', '2024-02-11', '2023-12-04', '2024-11-30', '2024-09-30', '2024-02-15', '2024-03-08', '2024-02-24', '2024-06-19', '2024-10-04', '2024-07-16', '2023-12-08', '2023-10-29', '2024-04-13', '2023-10-12', '2024-09-27', '2024-03-13', '2024-08-08', '2023-09-27', '2024-01-08', '2023-11-29', '2024-10-31', '2024-10-17', '2024-10-05', '2024-05-04', '2024-10-24', '2024-01-05', '2023-09-23', '2024-10-18', '2024-07-23', '2023-12-16', '2024-06-21', '2024-04-23', '2024-08-31', '2024-11-16', '2024-11-13', '2024-03-07', '2024-07-14', '2024-05-16', '2024-08-17', '2024-11-06', '2024-02-25', '2024-05-06', '2024-05-17', '2023-11-24', '2023-11-21', '2024-03-21', '2024-02-05', '2024-04-01', '2024-01-14', '2024-01-06', '2024-08-27', '2024-04-21', '2024-10-26', '2024-05-12', '2023-10-09', '2024-04-24', '2024-09-11', '2024-04-30', '2024-01-09', '2024-08-10', '2024-08-20', '2024-04-04', '2024-06-27', '2024-02-08', '2024-07-12', '2024-09-01', '2023-12-23', '2024-12-07', '2024-08-13', '2024-09-17', '2024-10-07', '2023-11-16', '2024-09-24', '2023-12-09', '2024-11-17', '2024-07-01', '2024-02-18', '2024-02-22', '2023-10-03', '2024-01-26', '2024-12-03', '2024-02-10', '2024-07-31', '2024-01-27', '2024-02-02', '2024-10-02', '2024-08-26', '2024-03-04', '2024-11-04', '2024-07-20', '2024-02-14', '2024-01-03', '2024-06-17', '2023-10-28', '2024-03-17', '2023-10-07', '2024-10-13', '2023-11-10', '2024-07-08', '2024-01-28', '2024-03-09', '2024-02-23', '2024-02-20', '2024-01-22', '2024-06-12', '2024-04-18', '2024-05-18', '2024-04-07', '2024-04-06', '2023-10-13', '2024-12-01', '2024-08-02', '2024-08-11', '2024-10-11', '2023-10-23', '2024-04-08', '2024-04-16', '2024-07-02', '2024-11-27', '2024-09-09', '2024-12-04', '2024-06-13', '2024-01-24', '2024-03-20', '2024-06-22', '2024-06-10', '2024-03-25', '2024-11-08', '2023-11-28', '2023-12-22', '2024-06-30', '2023-12-20', '2024-06-14', '2024-03-24', '2024-11-15', '2024-07-17', '2023-11-01', '2024-02-17', '2023-12-25', '2024-11-09', '2023-11-13', '2024-11-28', '2023-10-04', '2024-08-12', '2024-01-10', '2024-06-03', '2024-07-29', '2024-05-07', '2024-02-06', '2023-11-05', '2023-10-20', '2024-05-28', '2024-09-16', '2024-10-20', '2024-04-17', '2023-12-01', '2023-12-03', '2024-07-06', '2024-09-07', '2024-04-28', '2023-12-02', '2024-02-28', '2023-11-14', '2024-08-01', '2024-11-24', '2024-11-22', '2024-01-21', '2024-09-25', '2024-08-06', '2024-10-25', '2024-02-12', '2024-07-13', '2024-05-31', '2024-03-27', '2024-07-21', '2024-10-03', '2023-10-31', '2023-12-28', '2024-11-07', '2023-12-30', '2024-05-11', '2024-01-16', '2024-07-09', '2024-08-05', '2024-08-28', '2023-09-29', '2024-08-15', '2024-04-03', '2023-11-06', '2024-07-19', '2024-05-25', '2024-01-17', '2024-07-27', '2023-10-06', '2023-10-10', '2024-09-10', '2024-08-14', '2024-03-02', '2024-05-19', '2024-11-03', '2024-05-05', '2024-05-22', '2024-05-02', '2024-11-10', '2023-12-18', '2024-10-19', '2024-06-02', '2024-01-15', '2024-01-07', '2024-11-29', '2024-04-26', '2024-07-22', '2024-08-30', '2023-10-24', '2024-01-25', '2024-03-18', '2023-12-27', '2023-11-26', '2024-02-03', '2024-01-02', '2024-11-26', '2024-03-10', '2023-11-07', '2024-02-19', '2023-11-18', '2024-10-27', '2024-08-18', '2024-09-06', '2023-10-16', '2023-09-24', '2024-05-10', '2024-01-19', '2023-10-18', '2023-11-30', '2024-05-14', '2024-07-03', '2024-04-25', '2024-05-03', '2024-07-05', '2024-04-14', '2024-02-26', '2023-12-19', '2024-08-07', '2023-10-15', '2024-01-23', '2024-11-20', '2024-06-08', '2024-05-30', '2024-12-06', '2023-10-11', '2024-08-16', '2023-10-26', '2024-08-19', '2023-09-26', '2024-10-22', '2024-04-09', '2023-12-06', '2024-08-21', '2024-02-04', '2023-12-13', '2024-09-13', '2024-11-05', '2024-03-22', '2024-01-04', '2024-04-15', '2024-03-11', '2024-05-09', '2024-10-12', '2023-11-22', '2023-12-10', '2023-11-25', '2024-08-29', '2024-10-16', '2024-10-14', '2024-01-20', '2024-11-02', '2024-10-09', '2024-09-21', '2024-11-14', '2024-09-12', '2024-11-18', '2024-01-11', '2024-10-08', '2023-10-30', '2024-11-23', '2024-01-12', '2024-10-30', '2023-11-15', '2023-10-14', '2024-05-21', '2024-02-27', '2024-04-12', '2024-02-09', '2024-03-30', '2023-11-17', '2024-04-05', '2024-04-20', '2024-04-02', '2024-09-08', '2024-09-19', '2024-03-06', '2024-08-03', '2024-03-15', '2024-07-18', '2024-09-18', '2024-08-09', '2023-12-29', '2024-07-30', '2024-04-11', '2024-09-26', '2023-12-11', '2024-04-22', '2023-11-11', '2024-03-01', '2024-01-29', '2023-12-07', '2024-08-22', '2023-10-05', '2023-11-12', '2024-03-19', '2024-05-23', '2024-06-26', '2024-09-14', '2024-04-19', '2024-07-10', '2024-05-26', '2024-10-06', '2024-02-21', '2024-12-08'].\n"
     ]
    }
   ],
   "source": [
    "data = request\n",
    "store_name = data.get('store_name')\n",
    "seller_id = data.get('seller_id')\n",
    "print('** Connecting to storage and BigQuery... **')\n",
    "# Initialize storage and BigQuery\n",
    "storage = CloudStorage(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "bigquery = BigQueryManager(credentials_path=settings.PATH_SERVICE_ACCOUNT)\n",
    "# Define paths and table names from the config\n",
    "bucket_name = settings.BUCKET_STORES\n",
    "table_management = settings.TABLE_MANAGEMENT\n",
    "destiny_table = settings.TABLE_ORDERS\n",
    "blob_shipping_cost = settings.BLOB_ORDERS(store_name)\n",
    "# Get dates to process\n",
    "loop = asyncio.get_event_loop()\n",
    "list_dates_to_process = await loop.run_in_executor(\n",
    "    None,\n",
    "    bigquery.get_list_dates_to_process,\n",
    "    seller_id,\n",
    "    table_management,\n",
    "    destiny_table\n",
    ")\n",
    "\n",
    "list_dates_to_process = [date.strftime('%Y-%m-%d') for date in list_dates_to_process]\n",
    "\n",
    "print(f'*** Starting to process dates: {len(list_dates_to_process)} dates to process ***')\n",
    "# Create a semaphore to limit concurrency\n",
    "semaphore = asyncio.Semaphore(20)  # Adjust the value as needed\n",
    "if len(list_dates_to_process) != 0:\n",
    "    # Use asyncio.gather to process dates asynchronously\n",
    "    tasks = [process_date(date, storage, bucket_name, blob_shipping_cost, semaphore) for date in list_dates_to_process]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    df_all_processed_data = pd.concat(results, ignore_index=True)\n",
    "\n",
    "else:\n",
    "    print('** 0 dates to process**')\n",
    "\n",
    "# The following steps are synchronous and don't need to be async\n",
    "print('** Deleting existing data **')\n",
    "bigquery.delete_existing_data(destiny_table, seller_id, list_dates_to_process, 'processed_json')\n",
    "print('** Correcting dataframe schema **')\n",
    "bigquery.match_dataframe_schema(df_all_processed_data, destiny_table)\n",
    "print('** Inserting data into BigQuery **')\n",
    "bigquery.insert_dataframe(df_all_processed_data, destiny_table)\n",
    "print('** Updating log table **')\n",
    "bigquery.update_logs_table(seller_id, list_dates_to_process, destiny_table, table_management)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 75)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2024-12-06T23:15:10.000-04:00\n",
       "1     2024-12-06T23:15:11.000-04:00\n",
       "2     2024-12-07T07:04:53.000-04:00\n",
       "3     2024-12-07T07:34:55.000-04:00\n",
       "4     2024-12-07T07:34:56.000-04:00\n",
       "5     2024-12-07T07:35:27.000-04:00\n",
       "6     2024-12-07T07:36:17.000-04:00\n",
       "7     2024-12-07T07:47:10.000-04:00\n",
       "8     2024-12-07T07:48:51.000-04:00\n",
       "9     2024-12-07T07:49:50.000-04:00\n",
       "10    2024-12-07T08:18:26.000-04:00\n",
       "11    2024-12-07T08:19:19.000-04:00\n",
       "12    2024-12-07T08:48:39.000-04:00\n",
       "13    2024-12-07T08:49:23.000-04:00\n",
       "14    2024-12-07T09:43:10.000-04:00\n",
       "15    2024-12-07T10:37:44.000-04:00\n",
       "16    2024-12-07T10:49:02.000-04:00\n",
       "17    2024-12-07T11:42:55.000-04:00\n",
       "18    2024-12-07T12:18:50.000-04:00\n",
       "19    2024-12-07T12:29:42.000-04:00\n",
       "20    2024-12-07T12:45:49.000-04:00\n",
       "21    2024-12-07T12:50:20.000-04:00\n",
       "22    2024-12-07T13:09:44.000-04:00\n",
       "23    2024-12-07T13:46:03.000-04:00\n",
       "24    2024-12-07T14:07:17.000-04:00\n",
       "25    2024-12-07T14:45:47.000-04:00\n",
       "26    2024-12-07T14:45:52.000-04:00\n",
       "27    2024-12-07T15:21:15.000-04:00\n",
       "28                             None\n",
       "29    2024-12-07T15:23:02.000-04:00\n",
       "30    2024-12-07T15:31:21.000-04:00\n",
       "31    2024-12-07T15:31:57.000-04:00\n",
       "32    2024-12-07T15:39:30.000-04:00\n",
       "33    2024-12-07T15:40:33.000-04:00\n",
       "34    2024-12-07T15:43:08.000-04:00\n",
       "35    2024-12-07T15:45:47.000-04:00\n",
       "36                             None\n",
       "37    2024-12-07T16:03:53.000-04:00\n",
       "38    2024-12-07T17:44:06.000-04:00\n",
       "39    2024-12-07T19:20:58.000-04:00\n",
       "40    2024-12-07T19:54:51.000-04:00\n",
       "41    2024-12-07T20:26:13.000-04:00\n",
       "42    2024-12-07T20:42:19.000-04:00\n",
       "43    2024-12-07T21:07:53.000-04:00\n",
       "44    2024-12-07T21:31:34.000-04:00\n",
       "45    2024-12-07T21:31:37.000-04:00\n",
       "46    2024-12-07T22:41:38.000-04:00\n",
       "47    2024-12-07T22:50:43.000-04:00\n",
       "48    2024-12-07T23:59:40.000-04:00\n",
       "Name: date_approved, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results[0])['date_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
